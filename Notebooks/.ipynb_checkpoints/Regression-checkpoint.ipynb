{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "552a4913-bc91-4418-86b4-763342393417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import validation_curve, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "from sklearn.model_selection import learning_curve, validation_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c93b980-c7ff-4fef-b6fe-494d49681cb9",
   "metadata": {},
   "source": [
    "- raw4_3 with raw features all without std and norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e6befbe0-582e-4649-8930-f1662ba3e8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-06-2012</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-06-2012</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-06-2012</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  day  month  year  Temperature  RH  Ws  Rain  FFMC  DMC   DC  \\\n",
       "0  01-06-2012    1      6  2012           29  57  18   0.0  65.7  3.4  7.6   \n",
       "1  02-06-2012    2      6  2012           29  61  13   1.3  64.4  4.1  7.6   \n",
       "2  03-06-2012    3      6  2012           26  82  22  13.1  47.1  2.5  7.1   \n",
       "\n",
       "   ISI  BUI  FWI   Classes  \n",
       "0  1.3  3.4  0.5  not fire  \n",
       "1  1.0  3.9  0.4  not fire  \n",
       "2  0.3  2.7  0.1  not fire  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_csv('../DataSet/DataSet_Clean.csv')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fafcd138-0bdf-4cf4-b27a-f040f0d2c47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  RH  Ws  Rain  FFMC  DMC    DC  ISI  BUI  FWI\n",
       "0           29  57  18   0.0  65.7  3.4   7.6  1.3  3.4  0.5\n",
       "1           29  61  13   1.3  64.4  4.1   7.6  1.0  3.9  0.4\n",
       "2           26  82  22  13.1  47.1  2.5   7.1  0.3  2.7  0.1\n",
       "3           25  89  13   2.5  28.6  1.3   6.9  0.0  1.7  0.0\n",
       "4           27  77  16   0.0  64.8  3.0  14.2  1.2  3.9  0.5"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Date','day','year','month','Classes'], axis=1)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ad7778f6-1554-4314-93be-97c6a75d83c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>ISI/FFMC</th>\n",
       "      <th>ISI/DMC*BUI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>0.112457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.062539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  RH  Ws  Rain  FFMC  DMC    DC  ISI  BUI  FWI  ISI/FFMC  \\\n",
       "0           29  57  18   0.0  65.7  3.4   7.6  1.3  3.4  0.5  0.019787   \n",
       "1           29  61  13   1.3  64.4  4.1   7.6  1.0  3.9  0.4  0.015528   \n",
       "2           26  82  22  13.1  47.1  2.5   7.1  0.3  2.7  0.1  0.006369   \n",
       "3           25  89  13   2.5  28.6  1.3   6.9  0.0  1.7  0.0  0.000000   \n",
       "4           27  77  16   0.0  64.8  3.0  14.2  1.2  3.9  0.5  0.018519   \n",
       "\n",
       "   ISI/DMC*BUI  \n",
       "0     0.112457  \n",
       "1     0.062539  \n",
       "2     0.044444  \n",
       "3     0.000000  \n",
       "4     0.102564  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ISI/FFMC'] = df['ISI']/df['FFMC']\n",
    "df['ISI/DMC*BUI'] = df['ISI']/df['DMC']/df['BUI']\n",
    "#df_feature['ISI/FWI'] = df_feature['ISI']/df_feature['FWI']\n",
    "#df['ISI/BUI'] = df['ISI']/df['BUI']\n",
    "\n",
    "##############################\n",
    "\n",
    "###################################\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bcb1d7ba-8af5-4a6f-987d-062334059bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['FWI','FFMC','DMC','DC','ISI','BUI'],axis=1)   ########### Raw4_4\n",
    "\n",
    "#X = df.drop(['FWI','FFMC','DMC','DC','ISI','BUI','Ws','Rain'],axis=1)   ########### Raw4_6\n",
    "\n",
    "#X = df.drop(['FWI','FFMC','DMC','ISI','BUI'],axis=1)       ############### raw4_5\n",
    "\n",
    "y= df['FWI']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87be6a7f-5a99-4b5e-9e8a-4da7bd22d0f8",
   "metadata": {},
   "source": [
    "X = df.drop(['FWI'],axis=1)\n",
    "y= df['FWI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9fd2eb19-a998-4d72-8fc0-aa54c9f2bbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>ISI/FFMC</th>\n",
       "      <th>ISI/DMC*BUI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>0.112457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.062539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  RH  Ws  Rain  ISI/FFMC  ISI/DMC*BUI\n",
       "0           29  57  18   0.0  0.019787     0.112457\n",
       "1           29  61  13   1.3  0.015528     0.062539\n",
       "2           26  82  22  13.1  0.006369     0.044444\n",
       "3           25  89  13   2.5  0.000000     0.000000\n",
       "4           27  77  16   0.0  0.018519     0.102564"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "047edd2d-9904-4b72-b7d5-69a31e2d320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=100)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "be8da2a9-d512-4f74-9027-0e8bbcab9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "fitted_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "\n",
    "#fitted_scaler = Normalizer().fit(X_train_dropped)\n",
    "\n",
    "\n",
    "X_train_scaled = fitted_scaler.transform(X_train)\n",
    "X_test_scaled = fitted_scaler.transform(X_test)\n",
    "\n",
    "#############################\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns= X_train.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8b20d9d5-8539-419a-8d7b-b497abba4664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>ISI/FFMC</th>\n",
       "      <th>ISI/DMC*BUI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521402</td>\n",
       "      <td>-1.345393</td>\n",
       "      <td>-0.173301</td>\n",
       "      <td>0.381169</td>\n",
       "      <td>-0.599412</td>\n",
       "      <td>-0.526956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.317554</td>\n",
       "      <td>-0.406104</td>\n",
       "      <td>-1.527837</td>\n",
       "      <td>-0.386481</td>\n",
       "      <td>0.126347</td>\n",
       "      <td>0.051823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.786786</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.165333</td>\n",
       "      <td>-0.386481</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.212399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.256018</td>\n",
       "      <td>0.264816</td>\n",
       "      <td>-0.511935</td>\n",
       "      <td>-0.386481</td>\n",
       "      <td>0.263354</td>\n",
       "      <td>-0.665448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.786786</td>\n",
       "      <td>-1.882129</td>\n",
       "      <td>0.503967</td>\n",
       "      <td>-0.386481</td>\n",
       "      <td>2.178441</td>\n",
       "      <td>-0.439976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature        RH        Ws      Rain  ISI/FFMC  ISI/DMC*BUI\n",
       "0     0.521402 -1.345393 -0.173301  0.381169 -0.599412    -0.526956\n",
       "1     1.317554 -0.406104 -1.527837 -0.386481  0.126347     0.051823\n",
       "2     0.786786  0.399000  0.165333 -0.386481  0.079646     0.212399\n",
       "3     0.256018  0.264816 -0.511935 -0.386481  0.263354    -0.665448\n",
       "4     0.786786 -1.882129  0.503967 -0.386481  2.178441    -0.439976"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled_df.head()\n",
    "#y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "397b168d-6f06-4c58-b11c-58c079b4942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='ISI/FFMC', ylabel='Density'>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(X_train_scaled_df,x='ISI/FFMC',fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cf475583-448d-4dab-9f84-acce68ceeb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.3f}",
         "type": "heatmap",
         "x": [
          "Temperature",
          "RH",
          "Ws",
          "Rain",
          "ISI/FFMC",
          "ISI/DMC*BUI"
         ],
         "xaxis": "x",
         "y": [
          "Temperature",
          "RH",
          "Ws",
          "Rain",
          "ISI/FFMC",
          "ISI/DMC*BUI"
         ],
         "yaxis": "y",
         "z": [
          [
           1,
           -0.6258031164954618,
           -0.26655433804477885,
           -0.36199473054181064,
           0.6796786673246272,
           -0.26306524646322565
          ],
          [
           -0.6258031164954618,
           1,
           0.283655925582598,
           0.24040564388635627,
           -0.6503892872790109,
           0.10006725790928185
          ],
          [
           -0.26655433804477885,
           0.283655925582598,
           1,
           0.06117103871532854,
           -0.0408700533843875,
           0.017583341224866107
          ],
          [
           -0.36199473054181064,
           0.24040564388635627,
           0.06117103871532854,
           1,
           -0.7671703171328567,
           0.13068082612879003
          ],
          [
           0.6796786673246272,
           -0.6503892872790109,
           -0.0408700533843875,
           -0.7671703171328567,
           1,
           -0.2683191642421729
          ],
          [
           -0.26306524646322565,
           0.10006725790928185,
           0.017583341224866107,
           0.13068082612879003,
           -0.2683191642421729,
           1
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "#00224e"
          ],
          [
           0.1111111111111111,
           "#123570"
          ],
          [
           0.2222222222222222,
           "#3b496c"
          ],
          [
           0.3333333333333333,
           "#575d6d"
          ],
          [
           0.4444444444444444,
           "#707173"
          ],
          [
           0.5555555555555556,
           "#8a8678"
          ],
          [
           0.6666666666666666,
           "#a59c74"
          ],
          [
           0.7777777777777778,
           "#c3b369"
          ],
          [
           0.8888888888888888,
           "#e1cc55"
          ],
          [
           1,
           "#fee838"
          ]
         ],
         "showscale": false
        },
        "font": {
         "size": 12
        },
        "height": 700,
        "margin": {
         "autoexpand": true,
         "pad": 0,
         "t": 40
        },
        "paper_bgcolor": "rgba(0, 0, 0, 0)",
        "plot_bgcolor": "rgba(0, 0, 0, 0)",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Spearman Correlation",
         "x": 0.5
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          -0.5,
          5.5
         ],
         "scaleanchor": "y",
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "automargin": true,
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.04655172413793107,
          0.9534482758620689
         ],
         "range": [
          5.5,
          -0.5
         ],
         "type": "category"
        }
       }
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJAAAAK8CAYAAACwbkVeAAAAAXNSR0IArs4c6QAAIABJREFUeF7s3XmcVNWd9/FfNY00IKBRwDBBIyCLo4hs7kg0IzEaBx2NS0RNjExM1InGRx1JzDLBqEM0URMybjFg3EcYozE4miCSoGwqMYIoGsUhIi4sAt3Q3fW8zm3uze3Lraru6v5WHahP/zNC3zp17vu0ncfPc+6pjPGFAAIIIIAAAggggAACCCCAAAIIIIBAHoEMOggggAACCCCAAAIIIIAAAggggAACCOQTICDx84EAAggggAACCCCAAAIIIIAAAgggkFeAgMQPCAIIIIAAAggggAACCCCAAAIIIIAAAYmfAQQQQAABBBBAAAEEEEAAAQQQQACB4gXYgVS8Ha9EAAEEEEAAAQQQQAABBBBAAAEEKkKAgFQRy8xNIoAAAggggAACCCCAAAIIIIAAAsULEJCKt+OVCCCAAAIIIICAdwIDx565Z4fGjo+Z2eylc6Zd5d0EmRACCCCAAAII7JACBKQdctmYNAIIIIBAJQrsP+acr1gmc2fy3hsbG8cue3b6M5VoUop7HnzUhKOrqqpm7yjubQlI+42ZMKQ6k3kik7UfvDJn2l3xew5//vh5K8VPHe+BAAIIIICAfwIEJP/WhBkhgAACCCDQTKDPiIlddutae3s2Y0fUZ7PHvzZn+tLwgiFjzrkuk8lcadns+cn/4IexbQKhu2UyZyWjSRiVstns9b7t8iEgtW3deTUCCCCAAAIIpAsQkPjJQAABBBBAwHOBMFbk2vnhdo10zNgBrzwz/SHPb2WHmp6Lc5axM5LRLrwJF2qqsx3PfOWZabf4dGOqgOTTPTIXBBBAAAEEECi9AAGp9Oa8IwIIIIAAAq0ScI8OZTN2Ta6QkRwsvL4xkz21Q2PmUreDxl2TzWafb6jaeuLy2fe9H39N8hGt5HXxnTjN3iubvXftxpoLVi26bVP490F0MRubach+0TpkfuTeO2vZt9zcO1rmsKzZxIaqqvM6NDbenclkDonPK9tY3TN4fMoy+6TNt5h5JN/LUuacthjho1yWtftbs8Nou8cMizHattbVljk32F1mZvF4WOg90gJSSx7Dix5f2+YfuoS7rHL9HCZfF653fKdca38mW/UvCBcjgAACCCCAQEkECEglYeZNEEAAAQQQKF4g+o//FsaPMDAk/0M+jDvxiJS2yyYZCly46bFr3ZT6bOMtYRSIYo6ZxSNS+EhdrojgznCKB6owdriYlPb38YOgi5pHLJq1ZmdOMef9JH2jRw/N+ifNXRjKZ5SMRu7P+cZz0S58j1wBKZPJHB+PYWk72wqdgZQMmWljpNml/Uzm+hkq/t8UXokAAggggAACSgECklKXsRFAAAEEEGgngbQDtNMChHu7gjtFth2QHMaCbGP23Pgh3C0NLS4eZKoyv4rvjEqLVCFBMK9gB1LzXVCt/fskaWvmkeu9kmO2dtdXrscM0ywLGuXYbZZ2n27eyejT0vWLBamVYVhqTUDK9z7Je8zlmeue2ulfG4ZBAAEEEEAAgXYUICC1IyZDIYAAAgggoBZIe8woGZJy/cd68j/488WUYCeRWd/47qKWRKyCcaQdAlJb5tHSMNTS6wrFsbRdNgWNcgSktDVx758MQbnCTny3V/znNH4QeGsCUq4AmRYx8wUk9wl3fLKb+jcH4yOAAAIIINB2AQJS2w0ZAQEEEEAAgbIJxP6D/49h7Mn1H+vJ0BB9gluu2W97ZG7Xbhu6dGjs+JhlbK/4bqPW7PyJokIbAlIURtowj5aGodY+wpYvCiW/V0xAynn+U2ztwhCUFpCiR8hinxrX1h1I+Q53T36PgFS2XxG8MQIIIIAAAu0mQEBqN0oGQgABBBBAoDwCLX1cqDU7kOJ30prHjwrGkTYEpPaYR0sDUmsP0c61m6sUO5CSP3XJdc61I6mtAYkdSOX59513RQABBBBAoFwCBKRyyfO+CCCAAAIItFBg/6MnnLY1ay/HP9UqfGlaoCh0BlJ45lG+HSTxqeWKQqXegdQe82hpQHL3n3bAeNwlsN918wmvPDP9oVKcgdTSuSeDUa7H0tICUvSYm9ltr8yZdle+kNheZyDxCFsLfxFwGQIIIIAAAmUWICCVeQF4ewQQQAABBAoJRGf+JD6FLQoAGTsi/mhZWmiIhYEVaZ+aljyDJohD2z61Ky2OhH/Xkk96C++vtYdlJ69vj3m0NMK4OccfG0vzceEjfn5QMji19FPT8kWa7YJV19rbs4n1dtcEPyNm5qJPMuykRcb4vcXvId8no6XZxT4h8PwwOKU9/scjbIX+Lef7CCCAAAII+C9AQPJ/jZghAggggAACFv2HesIi/h//8VBjmcydSba0a901aWMnw1DyGjdWNpt9otSfwtbWebQmIIV+uezTDn7e7oDvRPRzYxZ8zC/HIdr51jebzT4ffrpd2s6g5BlKbn0bM9lTOzRmLs2aRZ/C5t4jedh2+HNTaGdbxjL7uNenfTogAYlfYggggAACCOz4AgSkHX8NuQMEEEAAAQSaCRQTSSBEAAEEEEAAAQQQQCCfAAGJnw8EEEAAAQR2MgEC0k62oNwOAggggAACCCDggQAByYNFYAoIIIAAAgi0pwABqT01GQsBBBBAAAEEEEDACRCQ+DlAAAEEEEAAAQQQQAABBBBAAAEEEMgrQEDiBwQBBBBAAAEEEEAAAQQQQAABBBBAgIDEzwACCCCAAAIIIIAAAggggAACCCCAQPEC7EAq3o5XIoAAAggggAACCCCAAAIIIIAAAhUhQECqiGXmJhFAAAEEEEAAAQQQQAABBBBAAIHiBQhIxdvxSgQQQAABBBBAAAEEEEAAAQQQQKAiBAhIFbHM3CQCCCCAAAIIIIAAAggggAACCCBQvAABqXg7XokAAggggAACCCCAAAIIIIAAAghUhAABqSKWmZtEAAEEEEAAAQQQQAABBBBAAAEEihcgIBVvxysRQAABBBBAAAEEEEAAAQQQQACBihAgIFXEMnOTCCCAAAIIIIAAAggggAACCCCAQPECBKTi7XglAggggAACCCCAAAIIIIAAAgggUBECBKSKWGZuEgEEEEAAAQQQQAABBBBAAAEEEChegIBUvB2vRAABBBBAAAEEEEAAAQQQQAABBCpCgIBUEcvMTSKAAAIIIIAAAggggAACCCCAAALFCxCQirfjlQgggAACCCCAAAIIIIAAAggggEBFCBCQKmKZuUkEEEAAAQQQQAABBBBAAAEEEECgeAECUvF2vBIBBBBAAAEEEEAAAQQQQAABBBCoCAECUkUsMzeJAAIIIIAAAggggAACCCCAAAIIFC9AQCrejlcigAACCCCAAAIIIIAAAggggAACFSFAQKqIZeYmEUAAAQQQQAABBBBAAAEEEEAAgeIFCEjF2/FKBBBAAAEEEEAAAQQQQAABBBBAoCIECEgVsczcJAIIIIAAAggggAACCCCAAAIIIFC8AAGpeDteiQACCCCAAAIIIIAAAggggAACCFSEAAGpIpaZm0QAAQQQQAABBBBAAAEEEEAAAQSKFyAgFW/HKxFAAAEEEEAAAQQQQAABBBBAAIGKECAgVcQyc5MIIIAAAggggAACCCCAAAIIIIBA8QIEpOLteCUCCCCAAAIIIIAAAggggAACCCBQEQIEpIpYZm4SAQQQQAABBBBAAAEEEEAAAQQQKF6AgFS8Ha9EAAEEEEAAAQQQQAABBBBAAAEEKkKAgFQRy8xNIoAAAggggAACCCCAAAIIIIAAAsULEJCKt+OVCCCAAAIIIIAAAggggAACCCCAQEUIEJAqYpm5SQQQQAABBBBAAAEEEEAAAQQQQKB4AQJS8Xa8EgEEEEAAAQQQQAABBBBAAAEEEKgIAQJSRSwzN4kAAggggAACCCCAAAIIIIAAAggUL0BAKt6OVyKAAAIIIIAAAggggAACCCCAAAIVIUBAqohl5iYRQAABBBBAAAEEEEAAAQQQQACB4gUISMXb8UoEEEAAAQQQQAABBBBAAAEEEECgIgQISBWxzNwkAggggAACCCCAAAIIIIAAAgggULwAAal4O16JAAIIIIAAAggggAACCCCAAAIIVIQAAakilpmbRAABBBBAAAEEEEAAAQQQQAABBIoXICAVb8crEUAAAQQQQAABBBBAAAEEEEAAgYoQICBVxDJzkwgggAACCCCAAAIIIIAAAggggEDxAgSk4u14JQIIIIAAAggggAACCCCAAAIIIFARAgSkilhmbhIBBHIJNL57aBYdnUCPzw3VDV7hIx81oFOFC2hvf8MmfjUohX962Sbl8BU99nd+0bWi7199848/fAv//aRGZnwEEPBWgF+A3i4NE0MAgVIIEJC0ygQknS8BSWfrRiYgaX0JSDpfApLO1o1MQNL6MjoCCPgtQEDye32YHQIIiAUISFpgApLOl4CksyUgaW3d6AQknTEBSWdLQNLaMjoCCPgvQEDyf42YIQIICAUISEJcMyMg6XwJSDpbApLWloCk9SUgaX3ZgaT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SHQYoH9xkwYUp3JPJGxzD5pL2psbBy77Nnpz7R4QA8u3H/MOV8xs2PXbqy5YNWi2zYpplSOgPTROrPv/6TGLj6vzvrvk817WwuXdLCrb+gcXNO3T4NNmbTZdu/x95fMmFVtU6fXBH8x+qB6+/YltVbTqen77n0un9zZVq7qEPz52is228ihDQrGnGOWMyA9+otLbewhg4O5rXpvrU389l02Z8GrOec6ZtQgu+2HX7E+vXYLrpn9/DI76Ws3Bf88/7+/Z4P7fTJ6bfx74V/Gr1n2xt9s9L98T2pdzoA0+Zpv2LADBwX398GHa23KLdNtycuvpd7vJV8708Yde1j0vbTrzz7983ba+M9adXW11dfX20Mzn7J7Hvitxd8nPviLf37VJv3gZ1LfDZvy/7upfPObJl9kI4Y1+a75YK1NnjLdFi9ZnvqW5599gp112metY3V1zuvj12ytr7d7H3rK7rzncUu+dtPmWrvx5w/ak79foLy9YOyfXib5lZ5z3q++sdnufHBN8P2ee1Tb187qbd26Nv1uzPX1yKwP7bkXPg6+fejBu9op4z4RXRr/XnK8DRsb7Bf3rrY1H9QH15//xZ42qF/T7/FSfJUzIP0w8bvhxwV+NxyX+N2QvP5LKb8bfv3Ab+0zY0bZ1796mnXu3PS/f5s319rP73jI/jBH/7NLQCrFTzHvgQACvgoQkHxdGeaFQBsEXEzqaJm7t1r2vNfmTF/ahqHK+tKdLSDV1pn98OYam/9StXXv1mjXX7U5b0Ba8VbGJt9aY5Muqg2uc7Fo0ZLqKBK5uDT1nl2iqHTzL3cJ1uuSL2+x8L1GDK23k8fVW3KsUi1suQLSrddMsJOPG2nf+tG9dv/jzwcByH3lijphPFr+5rtRNAqN3PemXHWm3XjXE8FYky48yS798ji7/7Hn7KIfTA8uKzS+wrtcAckFoTGHHxz8x9rv5yywqTddHdzehZdem3qbLgKtfu9Du/kX99nQA/azyy+eYBs31UbXu3g0/oSxNvPx2UE0yvd1zJhRdsG5J9vjT84teG1bzcsVkK645Cw7ZszBUciZNnVScCvnXDg59ZZcbPrb6g/thpvvDb6fvN5FotPGj7WHZs4OolH8y73XJ3t/wi6ddGv02q5da/IGq7a6hq8vZUBatXqL/fp/3rcv/fOe1qf3LjZ34Xpb/matnf3Pe9ouu1Sl3pILRO4rHo3CC5Ovj//ZXXPP/7xvA/etsSNHdrfke7eXX75xyhWQ3O+Go7b9bnAh5+fbfjd8PcfvBheb3ov9bvjWtt8N4fUuHoW/G1w0in+59+rV6xP27W0h2Y3V9x96W75g1V72BKT2kmQcBBDYEQUISDviqjFnBAoIpAWkgWPP3LNDY8fHMpnMIe7l4Y6k8O/dhotMJnNlMHQ2e29DVfamqmzm4WBHUzZ7b7gLKBzbMplfu/9P5KbLs9cvnTPtqnBaQfjJZO4MxwpfO2TMOddZJtM9k832sEzmLMtmz99q2XnxnVPhWMkdVdls9vmGqq0ndmjseLkbN3y/wUdNOLoqk5no3qNr1837uHAWzi18jbs+7d4Dh3cPLfk2g5buQHLBaOWqqiAIua9kBHLBqG+fxiAQua94UPpwbcZuubuTffebtcGOpWRQKtW/ROUKSC7ovLtmXRSDkkEpef9ut9JePXu0aNdQMja5sT97xAEFdzi1t3m5ApILRh9+tC7aAZQMSoXu0wUl9x96bteS+3JBaeELS4PAVOjLvfYTu/fIGasKvb413y9XQHIB6IMP10VRJxmUCt2DC0p79+0dRCD3NenyCfb8wqVRYMr3+ta+V6G55Pt+KQOSCzzvfVAfxaBCUcftVvrjog05A1MyLrnrH336o2BX04aPG2zGkx/aOaf0DHY4bdnS2CwotcWspa8tV0Bywcj9bgijTjIoFZp/PAK5a11QWtTC3w2tfa9Cc8n3fQJSW/R4LQII7OgCBKQdfQWZPwIpAsmAFMUjs9temTPtriDOWGZKQ9XWc93LXVxxAclFmdi1K1yU2bXbhi7u+9ls9kr3CFwYdixr98evD7/v4lHWbKKLPctn3/e+i0YZs+XufZsCkp1Rn80eH+6M2v/oCadtzdrL7s/h2NnG7LnuvdJ2IAVj5AlILkaFc3PX5bt3Nz+fA1J8R5G7l/CRtAvP3mIHDGoIdjOFO4zc9+OB6aN1Vc12J7nvJ8crxb885QhIabuJ3K6hr3/pWPv5r5+2yVMf3e7Wk4+obdlabzf9clbqtWeccIj9+N/PshlPLgx2IMUflQsHnjZjbrQ7SeVcjoAU7iBa+X+ro4DUmh1EziK+Y8ntKIo/huK+n+uRuFLuPnLzKEdAGj50YBB83l65OgpI+XYQJX+2wtdv3Fgb7Fg67phRdtnXv2hdtj3m467P90hcPD7lemSuvX6eSxmQksEnfMTspGN3T320zAWnR59a2+xW44+huQB12/3v2dDBXYIo5cbvtUd1sOMoHpPCR+Ty7WZqL8/4OOUISO53gws+7ndDGJDy7SBKu+/4jqXkI2rh74ZcO4zca7t2qWEHkuIHijERQACBmAABiR8HBHZCgWRAcrt0MpnM9WHU6TNiYpfdutbe3pjN3tbYof4v8UAUfs/MnnbRJ/nntN1NYdRZt7HmB27c8LWONr5DqEfX2mvi8SdJn3yvYgJS8tG9fPfuIpXvASm+wygtII0ftzU61ygZkGbO6tjsTKRKC0hP/fHlKOLkC0hhcIpf76LQiAM+HT0CF/9ZTT6ulrbb6YwTD80ZoNrrV045A1J8x1BrAlJyt5J77QnHHWm3/2pG8Dhc2iNuoVcpdx+VOyDFdwy1NCC5nUuf3nuvZoHIvXb8CUfaLbc/EpxrlAxM8Z/Flr5Pe/38ljoghYEnWNttZxTlCkjxIOSud1Hovt98YBPP6BU8AhfuKtq0udHeXrWl2ZlKabuXKikgxXcMtSYgJXcQudeGvxvc43BhoHKPv8YfiQvPXOIMpPb6N5NxEEAAgfwCBCR+QhDYCQXSAlJVVdXs5K26x9jaIyBt23U0MApI7vG0+Ne2R+DSAlIUjeKvyWbPd/GqvQJSrnvfEQKSYwwfYWMH0vb/srrHx845+cjoG27nz4NPzA8Ow46fZ9TagJTcZRS+gYtF3Xft3OxxtWRAyneeUnv+ulEHpOTh17Oenmez5y4MHjkrZgeSG+/Yo0dFB2Q7i2RACn7eE2cshde19Jyk9jJW70Byj4udOO7vh4s/NmuePTV7YZt2ILl7j+8iOnjofs0Ckvt+2mNq4WHas55e0KJH3drDuNQByc05PM+otQEp+RhaMjC5HUvzXvg4eITN7U4KH2fbWXcguX9H44dfP7ntd0OxO5DceMds+90QnnWUDEjh74b4GUvxn0MeYWuPfysZAwEEECgsQEAqbMQVCOxwAqkBads5QclPMwsf8QofQWuPHUhuZ1PaJ74lHz8L3ytrttI9DqfagRSekZT2SW4+70DiDKTi/9Vr7RlIyetdQPrRt75odzz0TPQYW1o8cjNMnp+UtqOp+DvJ/Up1QMr1zsWcgZQWj9z4aY+luWtHHjyk2Se7FTqoW+GrDki55tzWM5Diu47ce1x8wSk28/G50QHaLiAdMnJIdFB2OeKRm1cpA1Jrz0BKXh8GpCNGdLN9P9UpONPI/XP4yWrxM5XcvXEGUtMnJLYk6qTFI/da9whbeGB+GJXctSMOHpL6mFra9YrfC25MzkBSyTIuAgjsCAIEpB1hlZgjAq0UKHQGkhvOPdrl/m9bdyAl3yt5BlIQhXat++rajzvdkdyBlAxGyfOKko+fufnGdyW5P297ZM7ih2jHP30uOWb83n3bgeQeQbvyus521YV1wWNpfApbK3/wY5cX+hS25CNq7vr4Y2fu+wP33SvaaZTvU9aSn8pW6MDu4u+q+SvLFZAKfQqbe9Rs0IB9ok9pK3TItotD7uyS+KHaxexwai/XcJxyBaRCn8LmdhgNGbRP9Cltd/z0Cpu34C9RIHIBKv5JavE/u3uLn7FU6sfW4mtUyoBU6FPYwjONzvzCHkEUSv45ea6R24G0dn19dMh2fAdSp44ZPoXtjocs7VPY3ONm4e8G9/1CgSl+rpH72YnvcIp/gpv7XnLs9v59EB+PgKTUZWwEEPBdgIDk+woxPwSKEGjJp7AlP6GsNTuQ4p+aFkSoxsax8R1HzT6FzV2w7ZG05A6kMOaEj5hlLftWJmurzey/mp2/lMmcFc734w3dNgXRyP2du94yN1o2e0iugOTeI/kJdOFYpT5EO/wktPkvVUerOvqg+uicomRAche5T1a7+obOwfV9+zTYlEmbg09VC7/cLqWp02uCP8bHcn8OH3lbuapD8P1rr9gcnZdUxI9VUS8pxyHa4UTjh1uvem9ts8fO0s44il+/YWNtdP5R+Dhbt65NzuFXfMz4o3RrqfW1AAAgAElEQVT5DuAuCjHHi8oVkNx0XCQaduCgYGbJQ6+TAckFor0/tVezu6ivr48eZQvPPdrjE7sF17z9zrvRp6ylHdrdnob5xipXQHJzcpFoxLAm3+Sh18mAlHwULnl9eO5Rzz2afP/69rvBAdvJ94lbuMfpbrj5Xil1KQOSuxEXge58cE1wTz33qA4eNwsfMUsGo+T1XTpXRecfue+FO5KWrahNHS98RG7NB02fkBk/gFuKum3wchyiHd5XeCZR+Lshfuh1MvK4QJTrd4PbdRSeexT/3RCef+QecTtt/Geturrpf085A6kUP1m8BwIIIGBGQOKnAAEEWiWQFqdaNYBnF5fjETbPCKTTKWdAkt6YB4OXMyB5cPvyKZQzIMlvzoM3KHVA8uCWSzaFcgakkt1kGd+IHUhlxOetEUCg7AIEpLIvARNAYMcSICDtWOtV7tkSkHQrQEDS2bqRCUhaXwKSzpeApLN1IxOQtL6MjgACfgsQkPxeH2aHAAJiAXYgaYEJSDpfApLOloCktXWjE5B0xgQknS0BSWvL6Agg4L8AAcn/NWKGCCAgFCAgCXHNjICk8yUg6WwJSFpbApLWl4Ck9WUHktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQC3YZNzIrfoqKHX/e7JRV9/8qb/9m9RyuHr/ixt26teAIpwHfuWSMdv5IH/+YX9qjk25ff++Rr/5P/fpIr8wYIIOCrAL8AfV0Z5oUAAiURICBpmQlIOl8Cks7WjUxA0voSkHS+BCSdrRuZgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0tq60QlIOmMCks6WgKS1ZXQEEPBfgIDk/xoxQwQQEAoQkIS4ZkZA0vkSkHS2BCStLQFJ60tA0vqyA0nry+gIIOC3AAHJ7/VhdgggIBYgIGmBCUg6XwKSzpaApLUlIGl9CUhaXwKS1pfREUDAbwECkt/rw+wQQEAsQEDSAhOQdL4EJJ0tAUlrS0DS+hKQtL4EJK0voyOAgN8CBCS/14fZIYCAWICApAUmIOl8CUg6WwKS1paApPUlIGl9CUhaX0ZHAAG/BQhIfq8Ps0MAAbEAAUkLTEDS+RKQdLYEJK0tAUnrS0DS+hKQtL6MjgACfgsQkPxeH2aHAAJiAQKSFpiApPMlIOlsCUhaWwKS1peApPUlIGl9GR0BBPwWICD5vT7MDgEExAIEJC0wAUnnS0DS2RKQtLYEJK0vAUnrS0DS+jI6Agj4LUBA8nt9mB0CCIgFCEhaYAKSzpeApLMlIGltCUhaXwKS1peApPVldAQQ8FuAgOT3+jA7BBAQCxCQtMAEJJ0vAUlnS0DS2hKQtL4EJK0vAUnry+gIIOC3AAHJ7/VhdgggIBYgIGmBCUg6XwKSzpaApLUlIGl9CUhaXwKS1pfREUDAbwECkt/rw+wQQEAsQEDSAhOQdL4EJJ0tAUlrS0DS+hKQtL4EJK0voyOAgN8CBCS/14fZIYCAWICApAUmIOl8CUg6WwKS1paApPUlIGl9CUhaX0ZHAAG/BQhIfq8Ps0MAAbEAAUkLTEDS+RKQdLYEJK0tAUnrS0DS+hKQtL6MjgACfgsQkPxeH2aHAAJiAQKSFpiApPMlIOlsCUhaWwKS1peApPUlIGl9GR0BBPwWICD5vT7MDgEExAIEJC0wAUnnS0DS2RKQtLYEJK0vAUnrS0DS+jI6Agj4LUBA8nt9mB0CCIgFCEhaYAKSzpeApLMlIGltCUhaXwKS1peApPVldAQQ8FuAgOT3+jA7BBAQCxCQtMAEJJ0vAUlnS0DS2hKQtL4EJK0vAUnry+gIIOC3AAHJ7/VhdgggIBYgIGmBCUg6XwKSzpaApLUlIGl9CUhaXwKS1pfREUDAbwECkt/rw+wQQEAsQEDSAhOQdL4EJJ0tAUlrS0DS+hKQtL4EJK0voyOAgN8CBCS/14fZIYCAWICApAUmIOl8CUg6WwKS1paApPUlIGl9CUhaX0ZHAAG/BQhIfq8Ps0MAAbEAAUkLTEDS+RKQdLYEJK0tAUnrS0DS+hKQtL6MjgACfgsQkPxeH2aHAAJiAQKSFpiApPMlIOlsCUhaWwKS1peApPUlIGl9GR0BBPwWICD5vT7MDgEExAIEJC0wAUnnS0DS2RKQtLYEJK0vAUnrS0DS+jI6Agj4LUBA8nt9mB0CCIgFCEhaYAKSzpeApLMlIGltCUhaXwKS1peApPVldAQQ8FuAgOT3+jA7BBAQCxCQtMAEJJ0vAUlnS0DS2hKQtL4EJK0vAUnry+gIIOC3AAHJ7/VhdgggIBYgIGmBCUg6XwKSzpaApLUlIGl9CUhaXwKS1pfREUDAbwECkt/rw+wQQEAsQEDSAhOQdL4EJJ0tAUlrS0DS+hKQtL4EJK0voyOAgN8CBCS/14fZIYCAWICApAUmIOl8CUg6WwKS1paApPUlIGl9CUhaX0ZHAAG/BQhIfq8Ps0MAAbEAAUkLTEDS+RKQdLYEJK0tAUnrS0DS+hKQtL6MjgACfgsQkPxeH2aHAAJiAQKSFpiApPMlIOlsCUhaWwKS1peApPUlIGl9GR0BBPwWICD5vT7MDgEExAIEJC0wAUnnS0DS2RKQtLYEJK0vAUnrS0DS+jI6Agj4LUBA8nt9mB0CCIgFCEhaYAKSzpeApLMlIGltCUhaXwKS1peApPVldAQQ8FuAgOT3+jA7BBAQCxCQtMAEJJ0vAUlnS0DS2hKQtL4EJK0vAUnry+gIIOC3AAHJ7/VhdgggIBYgIGmBCUg6XwKSzpaApLUlIGl9CUhaXwKS1pfREUDAbwECkt/rw+wQQEAsQEDSAhOQdL4EJJ0tAUlrS0DS+hKQtL4EJK0voyOAgN8CBCS/14fZIYCAWICApAUmIOl8CUg6WwKS1paApPUlIGl9CUhaX0ZHAAG/BQhIfq8Ps0MAgRwCA8eeuWeHxo6PZTKZQ6JLstl7126suWDVots29RkxsctuXWtvN7OnX5kz7a7wmv3HnPMVMzs2vK6cAenRX1xqYw8ZHExt1XtrbeK377I5C17NueZjRg2y2374FevTa7fgmtnPL7OTvnZT8M/z//t7NrjfJ6PXxr8X/mX8mmVv/M1G/8v35D9f5QhIH60z+/5Pauzi8+qs/z7ZvPe4cEkHu/qGzsE1ffs02JRJm233Hn9/yYxZ1TZ1ek3wF6MPqrdvX1JrNZ2avu/e5/LJnW3lqg7Bn6+9YrONHNogNw3foNQB6b0162zegteDt9+1a40dcehAq+nUMfV+163bZH+av9y2bG3ySLv+pZffsr++/X7e8errG2zhC28E14w8uJ9VVzdZl+Jr69ZSvMvf32PNB+tsweIm365dauzQkQOtUy7f9Zts/uLltnWbb77rw3FHDR9gPfdo+uGuq9tqzy1cbhs31QZ/jn+vVHf9nXvWlOqttnuf39x2uX3m0CHB369a/ZFdMOkOe2b+spzzOXr0YLt98letT+/dg2v+8NxS+8LEKcE/x8cKB1i6YpWNOvk7wR9/9r3z7NxTjgr+ecPGWrts8j1232PzpPde6oB08smn2oiRo7f9bNXZbx6dYS++uDjvPQ4bNtw+f8IX7Pnn59nTTz3Z7Novf2Wi9e8/IPi79evX2cMP3W9vvLEi+LN73RdOOtk6dWr6Rbxo4XybMeNhqWdycAJSSbl5MwQQ8EyAgOTZgjAdBBBomUAYkLLZ7JXLnp3+TBiMsmYrl86ZdpXvAenWaybYyceNtG/96F67//HngwDkvnJFnTAeLX/z3SgahVLue1OuOtNuvOuJYKxJF55kl355nN3/2HN20Q+mB5cVGr9l6q2/qpQBqbbO7Ic319j8l6qte7dGu/6qzXkD0oq3Mjb51hqbdFFtcJ2LRYuWVEeRyMWlqffsEkWlm3+5SwBwyZe3WPheI4bW28nj6i05VuulWv+KUgYkF4QWvPiGjRrWz3r06GIr3lxta95fnzPquNi04eNa679v7+DGXCzavHlLdH3y9WnjhfFo9Zr11rtn9506IK1bv8le/PMbNuzAftajexd78+3V9v4H6+3gof2susP20cxFoY831tq+ezf5vrz0Ldtcu2W76+NRKoxE9Q0N9sKSN2zPPboHr0++d+t/Eot7RbkCkgs6p4wbFYWcBTP+I7iBMPgk7yaMR6+++W4UjeLXuIA0aN+9UiPUt78x3r5x9j/Zz+75X/vhz2YGsSnXtcUppr+qlAHp2M8eZ4cffpT96U/PBiHIxZ+ePXs2iz7xWfbr199OPe0M6969hzU0NNicOX9oFpBcjDrgwIOiCHXJv30rePnNP/2xha9ds2aN/fKu2yz53u1pmG8sAlKppHkfBBDwUYCA5OOqMCcEECgokAxI7gXx3UXuzz7vQHJB590166IYlAxKSQC3W2mvnj1atGsoGZvc2J894oCCO5wKohdxQSkDUji9lu5AcsFo5aqqIAi5r2QEcsGob5/GIBC5r3hQ+nBtxm65u5N995u1wY6lZFAqgqrVLyllQHKBxwWLgw7YJ5hnMigVmrwLSn9+5Z1o15ILSu4rHC/5ffc9d43bueS+8sWqQu9d7PdLuQPJBaONG2vtgCHbfBNBqdA9uFD0yrJ3mu1acmHoL8vetgOG7G0vLHnT9h/8qWAHUvj3Iw7qH+xwSgalQu/VXt8vV0Bywcj97g13ECWDUvL+XPRxv3tzBaZ8USj52mRQai/L5DilDEguGHXr1i0IPO6rpVEn1w4kF4w2bNgQBCL3FQ9Ke+y5px1yyGH228d/E+xwSgYllWdyXAJSqaR5HwQQ8FGAgOTjqjAnBBAoKJBrB1L4yJrPO5DSdhO5XUNf/9Kx9vNfP22Tpz663f0nH1HbsrXebvrlrNRrzzjhEPvxv59lM55cGOxAij8qFw48bcbcaHdSQew2XOBzQIrvKHK3GD6SduHZW+yAQQ3BbqZwh5H7fjwwfbSuqtnuJPf95HhtYGvRS0sZkJLBp7Zuq/3xueV24P6fsl49Y8/85Zh5codR+Ihbn0/uHkSkMBbFdyy5odz3Cu12ahFWEReVMiC5HUTuKwxI4SNmYfQpNP3kjqX4riL3mKF7XC0cKy02Jd+/0Pu1x/fLEZDSdhMVijouOA3p3ye6Zfe71+32dDuK3FfyEbb442vJ3U1nnniY3TjpbHtk1gL7xvfubg/G1DFKGZDiO4TcZMJHzF7+80t5Hy1LC0hpQSgepLp3695sd5J7v+T7y1BjAxOQSqHMeyCAgK8CBCRfV4Z5IYBAXoG0M5AaGxvHusfZ3AujgJTJnLXdQLGzkspxBlIYkJ7648tRxMkXkNKud1FoxAGfjh6Bi99j8nG1tN1OZ5x4aM4A1Z4/er4HpPgOo7SANH7c1uhco2RAmjmrY7MzkXb2gOR2A4WBpzUBKW23Uvh4mjsj6aO1G5udkZTc7VQpAalr15rokbTWBKTkI2jutYteWmH/OHjv4HG45FguIP317feaPe5WaQHpf//4chRw8gWkMDjFr3fBaOSB+6aeZRQGooV/fjPY4ZTc7bSzBqT4jqH2CEivLX81ik/JgLTfwEHNHo8jILXn/2IzFgIIIFBYgIBU2IgrEEDAQ4HkDqQhY865zk3TnX/ULCCV+RBt9/jYOScfGQm6nT8PPjE/OAw7fp5RawNScpdR+AYuFnXftXOzx9WSASnfeUrtvdS+ByR3v+EjbOxAyr36xe5ACncajRi2b7OdSskdRy4SuQO13cHcr762KjpcOz6jUp+DtCPsQHLxyB2mPezAfaMDssO/Cw/Yjhu6c5DcV/Jxt50xIMUPr3b3/KtHnrUHf/tccBh2/Dyj1gakQhEo/tgaO5ByH27NDqT2/l9bxkMAAQRKI0BAKo0z74IAAu0skAxIhR5pC9/el09ha+0ZSMnrXUD60be+aHc89Ez0GFtaPHL3nTw/KW1HUzsvTzSczwGJM5BavurFnIGUKx6Fu4/6fbpXFJXynalUCTuQijkDKS0epa1ocgcSZyC17gyktF1EP/p/Z9gdD/4heowt7h4PSJyB1PzT1eJOnIHU8t+/XIkAAgj4JEBA8mk1mAsCCLRYIO0Q7cFHTTg6U5X5VX02e/zGjZ3f8vkQ7UKfwpZ8RM1dH3/szH1/4L57RTuN8n3KWvJT2Qod2N3iRWjBhT4FJPcI2pXXdbarLqwLHkvjU9hasIDbLin0KWzJWFTokO20T2ULdyC5M3viX5UQkAp9ClsyFrXmk9OSAYlPYcv/KWzJR9TcTqYzv3BYdO5R/NBs93P6nYtOtv+4dYY9M3+ZJXcn8SlsK4JDtceM+Yy9+MKiZmci5QpIfApby38vcyUCCCBQDgECUjnUeU8EEGizQFpAcoO6HUbZjF2zaYud3LWjXR4eqh2+oS87kNx84odbr3pvbbPHztLOOIpfv2FjbXT+Ufg4W7dtn1gV3mt8zPijdPkO4G7zwiQGKGVACj8Jbf5L1dEsRh9UH51TlAxI7iL3yWpX39A5uL5vnwabMmlz8Klq4ZfbpTR1etMngcXHcn8OH3lbuarpY9avvWJzdF5SezumjVfKQ7Td+7tPSpu34PVgKu48JPe4WRh7kgHJRZ+Xl76z3bQPGzUg2HUU7kJavWZ96njxF1ZCQHL3684mWrC4ybdrl5rtPlEt/qia27G09NXtfd0jau6T1uJfaecphX+3cVNtcGna69Q/w+U4RDu8p/jB16tWf2QXTLojCEDuK+2Mo/j17nfvZZPvsfsemxdcnzxk+w/PLY0+4c19P/4oXfK1KuNSHqLt7sFFnxEjRwe3U1dXZ795dEbwKWnuKxmQwoOyu3f/+8/p+vXrmp1r5D7ZrX//psctk98Lz1jq1KlT8P1FC+fnPaxbYcwh2gpVxkQAgR1FgIC0o6wU80QAAYlAOQ7RltyIp4OWMiB5SiCbVqkDkuxGPB24lGcgeUognVY5A5L0xjwYvNQByYNbLukUCEgl5ebNEEDAMwECkmcLwnQQQKC0AgQkrTcBSedLQNLZupEJSFpfApLOl4Cks3UjE5C0voyOAAJ+CxCQ/F4fZocAAmIBApIWmICk8yUg6WwJSFpbNzoBSWdMQNLZEpC0toyOAAL+CxCQ/F8jZogAAkIBApIQ18wISDpfApLOloCktSUgaX0JSFpfdiBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISF6iAqYAACAASURBVH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAW+PypF2fFb1HRwx9/eJeKvn/lzX/jrGeUw1f82FfdeGTFGygB1m9sUA5f0WPX7FJV0fevvvmf3PRj/vtJjcz4CCDgrQC/AL1dGiaGAAKlECAgaZUJSDpfApLO1o1MQNL6EpB0vgQkna0bmYCk9WV0BBDwW4CA5Pf6MDsEEBALEJC0wAQknS8BSWdLQNLautEJSDpjApLOloCktWV0BBDwX4CA5P8aMUMEEBAKEJCEuGZGQNL5EpB0tgQkrS0BSetLQNL6sgNJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAIEUgcFHTTg6k8lc31C19cTls+97310yZMw517n/u3TOtKvc/x049sw9OzR2/FW9ZS9/bc70pbkgyxmQJl/zDRt24KBgah98uNam3DLdlrz8WupUL/namTbu2MOi76Vdf/bpn7fTxn/Wqqurrb6+3h6a+ZTd88BvLf4+8cFf/POrNukHP5P+jJU6IL23Zp3NW/B6cE+7dq2xIw4daDWdOqbe47p1m+xP85fblq0NOa9/6eW37K9vBz9iOcerr2+whS+8EVwz8uB+Vl3dQWoaDl6OgPTROrPv/6TGLj6vzvrvk817nwuXdLCrb+gcXNO3T4NNmbTZdu/x95fMmFVtU6fXBH8x+qB6+/YltVbTqen77n0un9zZVq5qsrz2is02cmjTOpXq66objyzVWwXvc+qpp9moUaODf66rq7OZMx+xxYsX55xDoev79x9gp59+hvXo0YT++uuv2e2339ZsvMsuu9w2bFi/3d+X4sbXbyztesbv6d8uvtAGD9ov+Ku1a9fZ3dN+ba8ub/q9kfbV0uuvmXSF7b777nb/gw/b8/MXRUMdMnqEnXrKeJvz7B/tN4//Ts5b6oB0+umn2aGHHBL97D788CO2cNHf7z95wy25/vjPjbMjjjjcZs58tNlY7u+PPfYY69Ch6XfD8tdes6lT/0tuGn8DAlJJuXkzBBDwTICA5NmCMB0EECgskIxD2/78WMZsxdqNNResWnTbprTIlDZyuQKSC0JjDj/Yfn7HQ/b7OQts6k1XB9O78NJrUwFcBFr93od28y/us6EH7GeXXzzBNm6qja538Wj8CWNt5uOzg2iU7+uYMaPsgnNPtsefnFvw2sKrkf+KUgYkF4QWvPiGjRrWz3r06GIr3lxta95fnzPquNi04eNa679v7+AmXCzavHlLdH3y9WnjhfFo9Zr11rtn9502INXWmf3w5hqb/1K1de/WaNdftTlvQFrxVsYm31pjky6qDa5zsWjRkuooErm4NPWeXaKodPMvdwnW4JIvb7HwvUYMrbeTx9Vbcqy2/ky29PWlDEjHHTfOjjzyKJs791l78slZdsEFE61nz172wAP324oV24eNQteH8WjNmvdS45Abf8CApoCSFpZaatSW68oVkM4+63QbMXxYFHlc9HFfP5h8Q+rttPR6N84nP7mX1dbWRWMPGjjAzjvnS7bbbj3M/a548n+f3ukCkgs6Rx89xp55Zo498btZduGF/2q9e/WyX//6Pnvt9e1/dgtdP3LECDv11FOsU6dOQUiNx6jwey+8+KI98MBDlvxzW34eW/NaAlJrtLgWAQR2NgEC0s62otwPAhUg0GfExC67da29vTGbvW3Zs9Of2W/MhCHVljnXMpnu9dnGW9yOo/3HnPOVrNnAcEeS26GUyWSudDxZy75Vn80e764rV0BywejDj9ZFO4CSQanQMrqg1Pcfege7ltyXC0oLX1gaBKZCX+61n9i9R85YVej1rfl+KQOSCzwfb6y1gw7YJ5hiMigVmrcLSn9+5Z1o15ILSu4rHC/5ffc9d43b6eS+8sWqQu9dzPd93oHkgtHKVVVBEHJfyQjkglHfPo1BIHJf8aD04dqM3XJ3J/vuN2uDHUvJoFSMVTGvKWVAckGnW7fuduONU4KpJgNRcv6Frk9+P9f9V+IOJBd61q3fYD+9ZWrAkgxESauWXO92KPXo3s3eePOtZnEqHGtn3oHkglH3bt3t+hv+M7jdZCBKerb0+rQdSMmx9xswwL70pTNt9XvvlXQXEgGpmN+ovAYBBHYWAQLSzrKS3AcCFSYQD0Tun93tu2CUzWafcFEpCEZmy1+ZM+0utxupKpOZGN+d5K5315UjIIU7iFb+3+ooILVmB5Gbe3zHkttR9PWvnmadOzeFDPeV65G4Uu4+Cv5j4vAuJfvJTAaf2rqt9sfnltuB+3/KevWMPTuVY0bJHUbhI259Prl7EJHCWBTfseSGct8rtNtJgeBzQIrvKHL3Hj6SduHZW+yAQQ3BbqZwh5H7fjwwfbSuqtnuJPf95HgKz+SYpQxILuS4rzAgDR8+3MaPP8WWLHnJHn74oe1ut9D17vu9ezftrHNfDQ0NNnv2H4LdTfGvSgtI4Y6gd1e/FwWkL5zwOTvmM0fb7//wzHa7g1pyvYtHe/XuFTwGN2rkiIoLSFde8f+CH6kwIBXaFdTS63M9wuZe37Pnnvb0078P3jftMTf17wcCklqY8RFAwGcBApLPq8PcEEAgp0A8Cu22a+03t2azMzpkrVcmkzm+oWrrlPj5R9ti08T4mUnhwOUMSPEdQ60JSMndSu61Jxx3pN3+qxnB43Bpj7iF91vK3UfuPUsdkNxuoDDwtCYgpe1WCh9Pc2ckfbR2Y7MzkJK7nQhIzf9VTe4wSgtI48dtjc41SgakmbM6NjsTqRICUvwsopYEpFzXv/DCC8HZR8uXvxrFJ7cjqW/fvbc7V6lSA9JfXllm99z7QPBD25KAlOt6d77UP+4/ODpDKddupp15B5ILOus3rI92ALUkILXk+lwByZ2fdPCwYcFZf+4cJM5A4v+hiAACCJRWgIBUWm/eDQEE2kkgPAcpm83e4HYX1Vdt/bdsY3XP6kzVxY2ZxruqGjPfb6jaem78kO3wETbLZu8NdyOpA1Ly8OtZT8+z2XMXBo+cFbMDyY137NGjogOyHWcyILm/S3skrjWRqp2WqeQByc07fOSspQEp3Gk0Yti+zXYqJXccuUjkDtR2B3O/+tqq6HDtuFUpz0FiB1J7/ZSmj7Oj7kBKC0i5gtTOHJBczDni8KaDnd3XH//0vC1YuCg4k6i9diD167dvdBh3/Kcofg6S+/udPSC5eyzFDqRkVApj1Vtvv80jbNpfh4yOAAIIRAIEJH4YEEBghxQIz0GyTOZ5s+yurzwz7Vr3dz12rZuSMVuWzWb7hOcfxW8wep3Z0+7xNnVAyoVbzBlIafHIjZ/2WJq7duTBQ5p9sluhg7oVPwil3IFUzBlIueJRuPuo36d7RVEp35lK7EBq/tPDGUit+7ep0JlGydEKXZ8MQy4gnXjiSfbcc/OaPca2MwekXCvQkjON4q9tzfWVuAOppWcahaYtvT5tB5LbfTRk8OBmB3QnH4lr3b95xV3NI2zFufEqBBDYOQQISDvHOnIXCFSkQHD2USZzp2Wz57sY5BCiw7Jjf7f/0RNO25q1l92h2b4EpEKfwuYeNRs0YJ/oU9oKHbLt4lDXLjXNDtUuZodTe/8glTIgFfoUtmQsKnTIdtqnsoU7kGo6dWxGVekByT2CduV1ne2qC+uCx9L4FLbW/ZtU6FPV3PfHjv2MLV68KHgsrdD1p556mg0fPiI69yjXp7pVYkAq9Klq7kyjT++zd/RJaoWuj690JQakQp+q5r5/7LHH2IKFC4NPTit0feiZ6xDt+FjsQGrd7xmuRgABBNpDgIDUHoqMgQACZREIzkGqqprd2Ng41h2I7Sbh/i5TlflV+Clr4d+568JJZrPZ68PdSeXageTm4iLRsAMHBdNKHnqdDEguEO39qb2aOdfX10ePsoXnHu3xid2Ca95+593oU9bSDu0u1YKVMiC5e3KflDZvQdNHR7vzkNzjZmHsSQYkF31eXvrOdhSHjRoQ7DoKdyGtXrM+dbz4C3f2gBR+Etr8l6qj2x59UH10TlEyILmL3CerXX1D5+D6vn0abMqkzcGnqoVfbpfS1OlNB7/Hx3J/Ds9MWrmqQ/D9a6/YHJ2XVKqf3VI+wubuyUWfUaNGB7fnPr585sxHbPHixcGfkwGp0PXu+y4aDRiwX+p48e+5C3Idsq20Xr+xQTl83rFdJBo8qMlm7dp10RlG7s/JgBT+Xa7r42+UDEjhIdy77fb3H/zk+ykQanapUgybc0y3M+jQQ5oeF3Q/uw8//IgtXLQo+HMyILm/y3d9GIU6deoUvd+7766OHpGLv9ZdwBlIJV1q3gwBBBAwAhI/BAggUNEC5QxIlQBf6oBUCabhPZbjDKRK8i11QKokW3ev5QxIO7t1qQPSzu6ZvD8eYau0Fed+EUAgLkBA4ucBAQQqWoCApF1+ApLOl4Cks3UjE5C0vgQknS8BSWfrRiYgaX0ZHQEE/BYgIPm9PswOAQTEAgQkLTABSedLQNLZEpC0tm50ApLOmICksyUgaW0ZHQEE/BcgIPm/RswQAQSEAgQkIa47/+LwLto3qODRCUjaxWcHktaXgKTzJSDpbAlIWltGRwAB/wUISP6vETNEAAGhAAFJiEtAkuISkKS8PMKm5WUHktCXgCTE5RE2LS6jI4CA9wIEJO+XiAkigIBSgICk1GUHklKXgKTU5QwkrS6PsCl9CUhKXc5A0uoyOgII+C5AQPJ9hZgfAghIBQhIUl4eYRPyEpCEuByircXlDCSpLwFJyssh2lpeRkcAAc8FCEieLxDTQwABrQABSevLGUg6XwKSztaNzBlIWl/OQNL5EpB0tm5kPoVN68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1daMTkHTGBCSdLQFJa8voCCDgvwAByf81YoYIICAUICAJcTlEW4pLQJLysgNJy0tAEvoSkIS47EDS4jI6Agh4L0BA8n6JmCACCCgFCEhKXQ7RVuoSkJS6PMKm1WUHktKXgKTU5RE2rS6jI4CA7wIEJN9XiPkhgIBUgIAk5eUQbSEvAUmIyxlIWlweYZP6EpCkvJyBpOVldAQQ8FyAgOT5AjE9BBDQChCQtL6cgaTzJSDpbN3IHKKt9eUMJJ0vAUln60bmEG2tL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktbWjU5A0hkTkHS2BCStLaMjgID/AgQk/9eIGSKAgFCAgCTE5RBtKS4BScrLDiQtLwFJ6EtAEuKyA0mLy+gIIOC9AAHJ+yViggggoBQgICl1OURbqUtAUuryCJtWlx1ISl8CklKXR9i0uoyOAAK+CxCQfF8h5ocAAlIBApKUl0O0hbwEJCEuZyBpcXmETepLQJLycgaSlpfREUDAcwECkucLxPQQQEArQEDS+nIGks6XgKSzdSNziLbWlzOQdL4EJJ2tG5lDtLW+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWls3OgFJZ0xA0tkSkLS2jI4AAv4LEJD8XyNmiAACQgECkhCXQ7SluAQkKS87kLS8BCShLwFJiMsOJC0uoyOAgPcCBCTvl4gJIoCAUoCApNTlEG2lLgFJqcsjbFpddiApfQlISl0eYdPqMjoCCPguQEDyfYWYHwIISAUISFJeDtEW8hKQhLicgaTF5RE2qS8BScrLGUhaXkZHAAHPBQhIni8Q00MAAa0AAUnryxlIOl8Cks7Wjcwh2lpfzkDS+RKQdLZuZA7R1voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbd3oBCSdMQFJZ0tA0toyOgII+C9AQPJ/jZghAggIBQhIQlwO0ZbiEpCkvOxA0vISkIS+BCQhLjuQtLiMjgAC3gsQkLxfIiaIAAJKAQKSUpdDtJW6BCSlLo+waXXZgaT0JSApdXmETavL6Agg4LsAAcn3FWJ+CCAgFSAgSXk5RFvIS0AS4nIGkhaXR9ikvgQkKS9nIGl5GR0BBDwXICB5vkBMDwEEtAIEJK0vZyDpfAlIOls3Modoa305A0nnS0DS2bqROURb68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1daMTkHTGBCSdLQFJa8voCCDgvwAByf81YoYIICAUICAJcTlEW4pLQJLysgNJy0tAEvoSkIS47EDS4jI6Agh4L0BA8n6JmCACCCgFCEhKXQ7RVuoSkJS6PMKm1WUHktKXgKTU5RE2rS6jI4CA7wIEJN9XiPkhgIBUgIAk5eUQbSEvAUmIyxlIWlweYZP6EpCkvJyBpOVldAQQ8FyAgOT5AjE9BBDQChCQtL6cgaTzJSDpbN3IHKKt9eUMJJ0vAUln60bmEG2tL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktbWjU5A0hkTkHS2BCStLaMjgID/AgQk/9eIGSKAgFCAgCTE5RBtKS4BScrLDiQtLwFJ6EtAEuKyA0mLy+gIIOC9AAHJ+yViggggoBQgICl1OURbqUtAUuryCJtWlx1ISl8CklKXR9i0uoyOAAK+CxCQfF8h5ocAAlIBApKUl0O0hbwEJCEuZyBpcXmETepLQJLycgaSlpfREUDAcwECkucLxPQQQEArQEDS+nIGks6XgKSzdSNziLbWlzOQdL4EJJ2tG5lDtLW+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWls3OgFJZ0xA0tkSkLS2jI4AAv4LEJD8XyNmiAACQgECkhCXQ7SluAQkKS87kLS8BCShLwFJiMsOJC0uoyOAgPcCBCTvl4gJIoCAUuCoz1+UVY5f6WOffHTXSieQ3f+7HzTIxmZgs+sumwuDUKDq8F7C0St76O9+aXBlA4jv/vv/cQP//SQ2ZngEEPBXgF+A/q4NM0MAgRIIEJC0yAQknS8BSWfrRiYgaX0JSDpfApLO1o1MQNL6MjoCCPgtQEDye32YHQIIiAUISFpgApLOl4CksyUgaW3d6AQknTEBSWdLQNLaMjoCCPgvQEDyf42YIQIICAUISEJcMyMg6XwJSDpbApLWloCk9SUgaX3ZgaT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUISH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEEBALEBA0gITkHS+BCSdLQFJa0tA0voSkLS+BCStL6MjgIDfAgQkv9eH2SGAgFiAgKQFJiDpfAlIOlsCktaWgKT1JSBpfQlIWl9GRwABvwUIiCjIzgAAIABJREFUSH6vD7NDAAGxAAFJC0xA0vkSkHS2BCStLQFJ60tA0voSkLS+jI4AAn4LEJD8Xh9mhwACYgECkhaYgKTzJSDpbAlIWlsCktaXgKT1JSBpfRkdAQT8FiAg+b0+zA4BBMQCBCQtMAFJ50tA0tkSkLS2BCStLwFJ60tA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbQlIWl8CktaXgKT1ZXQEEPBbgIDk9/owOwQQEAsQkLTABCSdLwFJZ0tA0toSkLS+BCStLwFJ68voCCDgtwABye/1YXYIICAWICBpgQlIOl8Cks6WgKS1JSBpfQlIWl8CktaX0RFAwG8BApLf68PsEECglQL7jZkwpKNl7t5q2fNemzN9aaGXE5AKCbXt+wSktvnlezUBSWdLQNLaEpC0vgQkrS8BSevL6Agg4LcAAcnv9WF2CFSkwMCxZ+7ZobHjY5lM5pAIIJu9d+3GmgtWLbptUz6UHSkg3TT5IhsxbFBwO2s+WGuTp0y3xUuWp97e+WefYGed9lnrWF2d8/r4NVvr6+3eh56yO+953JKv3bS51m78+YP25O8XyH++Sh2Q1nywzhYsfj24r65dauzQkQOtU6eOqfe5bv0mm794uW3d2lDw+nDcUcMHWM89egTX19VttecWLreNm2qDP8e/J4c1s1IHpFNPPc1GjRq97d7rbObMR2zx4sU5b7XQ9f37D7DTTz/DevRo8nz99dfs9ttvazbeZZddbhs2rN/u70vhe91lc0vxNs3e46N1Zt//SY1dfF6d9d8nm/f9Fy7pYFff0Dm4pm+fBpsyabPt3kQZfM2YVW1Tp9cE/zz6oHr79iW1VtOp6XvufS6f3NlWruoQ/PnaKzbbyKFN/x6U6qvq8F6leqvt3uep6T+wYw8/KPj7/3v3Azvn8pvs9/P+nDqfv/zuVtt/v77bfe/OB//XvvrvtwZ//4NvnmVX/uu/2C67VNuWLfV2/X/9t13zk3st/j7xAZ7+00v22QnXyO6/1AHppH8+1YaPGBXcT11dnT3+2Exb8lLu3w3uuqEHDbfPHX+iLZj/nP3h909GFp855jg78qix1qFD08/m+vXrbMZ/P2Bvvrmimdc3LrrMNny8wabdfbvMMdfABKSSk/OGCCDgkQAByaPFYCoIINAkEAakbDZ75bJnpz/TZ8TELrt1rb09a7Zy6ZxpV7WnU7l2IF1xyVl2zJiDo5Azbeqk4LbOuXBy6u252PS31R/aDTffG3w/eb2LRKeNH2sPzZwdRKP4l3uvT/b+hF06qek/dtxru3atyRus2su4lAHJBaEX//yGDTuwn/Xo3sXefHu1vf/Bejt4aD+r3vYfI/H7clHo4421tu/evYO/fnnpW7a5dst218ejVBiJ6hsa7IUlb9iee3QPXp987/byyzdOKQPScceNsyOPPMrmzn3Wnnxyll1wwUTr2bOXPfDA/bZiRVOwi38Vuj6MR2vWvJcah9z4AwbsFwyZFpZK4VvKgFRbZ/bDm2ts/kvV1r1bo11/1ea8AWnFWxmbfGuNTbqoNrjOxaJFS6qjSOTi0tR7domi0s2/3CUgu+TLWyx8rxFD6+3kcfWWHKsUtu49yhWQ7vjRRfbFzx9p3/juL2z6zNnmApH7+sfPXdSiW3ex6MIvHW+XTb4zeL378ze/fJL95JePBtEo39eE8WPtxknn29RfP1Hw2hZNJsdFpQxILvgcetiR9ty8uUEIOue8C2zPPXumRh833X337W8n/8vp1r17D2toaLC5z85uFpDc69d+9JE9+j8PB3fnQpH7+tmtNwb/132/X78BwT+/8cbrBKS2/KDwWgQQQKAIAQJSEWi8BAEEtALJgOTebf8x53zFzI4NdyEFf85k7gxn0tjYONbFpuQOpPB12UxmXcbsQnd9eK3753IFJBdxPvhwXRR1kkGpkLALSnv37R1EIPc16fIJ9vzCpVFgyvf61r5Xobnk+34pA5ILRhs31toBQ/YJptTaqONC0SvL3mm2a8mN8Zdlb9sBQ/a2F5a8afsP/lSwAyn8+xEH9Q92OCWDUlvMWvraUgYkF3S6detuN944JZheMhAl51zo+uT3c90zO5DSZVwwWrmqKghC7isZgVww6tunMQhE7iselD5cm7Fb7u5k3/1mbbBjKRmUWvrz19bryhWQXDD625oPox1AyaBU6L7irz/msANt2pRL7XdzFke7kfK93u1I+mTPT7Q4VhWaS67vlzIguaDTbdduUeBJBqVcc8y1Ayl5fa4gxQ6kYn86eB0CCCDQNgECUtv8eDUCCAgEcu1AMrOnX5kz7a5gR9KudV9d+3GnO9wjbS4SZc0mNlRtPTHbWN0zfgZSGJrCaDT4qAlHZzKZ6921y2ff9345AtLwoQOD4PP2ytVRQMq3gyhJHL7exRK3Y+m4Y0bZZV//onXp3PS4ivvK90hcPD7lemSuvZa1lAHJ7SByX2FACh8xC6NPoXtK7liKB6iaTh2Dx9XCsdJiU/L9C71fW79fyoDkQo77CgPS8OHDbfz4U2zJkpfs4Ycf2u5WCl3vvt+7d9POL/fldiLMnv2HYHdT/IuAlP5TEt9R5K4IH0m78OwtdsCghmA3U7jDyH0/Hpg+WlfVbHeS+35yvLb+bLbk9eUISGHwWfbGO1FAas0OouTuI7ej6Gff/5p127XpUUL3leuRuFLtPnJzKGVASu4QcmHohBPH219eXhLtIkr7eWhJQAp3K9XV1kaBKhyLgNSSf8u4BgEEEGh/AQJS+5syIgIItFEg7Qyk+K6h5PDxXUfue9sFpNjOJXdttWWmNFRtPbfcASm+Y6ilAcntXPr03ns1C0TuteNPONJuuf2R4FyjZGCKe7X0fdq4hNHLSx2Q3KN54SNprQlIyd1K7rWLXlph/zh47+BxuORYLiD99e33mj3utrMHpPhZRC0JSLmuf+GFF4Kzj5YvfzWKT25HUt++e293rhIBKXdAiu8wSgtI48dtjc41SgakmbM6NjsTqdICUnzHUGsCUnL3UjIohYFq3YZN2+0yKtXuo3IEpPhZRO0VkFwg6tmrN2cgtdf/GDMOAggg0E4CBKR2gmQYBBBoP4HkDqQhY865zo0eP/8oCEGZzBMZywTPK2Ut+1Z9Nnu8bwHJPS524rjDIpzHZs2zp2YvbNMOJDdYfBfRwUP3axaQ3PfTHlMLD9Oe9fSCFj3q1h4rWuqA5Obc2h1I4WHaww7cNzogO3nAdtzCnYPkvpKPu+3sAcndc3vsQEoLSLmCFAEpd0By3wkfYWMH0vZO7tG087/4T9E33KHX9z76TPDIWTE7kNIedUsGJPdmua5r6TlJ7fF7d2fZgeQseIStPX4iGAMBBBBoPwECUvtZMhICCLSTQDIgJf8cxqNsY/bc5LlHvgWkXCRtPQMpvuvIvcfFF5xiMx+fGx2g7QLSISOHRAdllyMeuXmVMiAVcwZSWjxKW7PkDiTOQGp+qHbSrNAZSMkw5ALSiSeeZM89N6/ZY2wEpPTfIJyBVPz/2BRzBlLao29uBmmPpbmA9Lkxw5t9sltrD+ou/u6aXlnKgKQ+A8mdqTRq9KH2uycea/bJbjzC1tafEl6PAAIIFCdAQCrOjVchgIBQIO0Q7eDsoqrMr9J2GeX7XvLwbR8eYXN0hT6Fze0wGjJon+hT2u746RU2b8FfokCU/CS1+J/d+PEzlkr92Fr8R6OUAanQp7AlY1FrDtlOBiQ+ha35p7C5Q7XHjv2MLV68KHgsrdCnsJ166mk2fPiI6NyjXJ/qRkBq+rfJPYJ25XWd7aoL64LH0vgUtuL/B6jQp7C5R81GDx0YfUqbe6d8B227ONSjW5cgGLmvYnc4FX9H27+ylAGp0Kewue8fedRYe+nFxc3ORMp1BtK/fu0SW758WfTJbC4Udaqp2e5T3QhI7fkTw1gIIIBAywUISC234koEECiRQFpAcm8dHJadsWtcRKq2zLmZTObKYErZ7Hz3f7Za9jz3f30/AylkdJFoxLBBwR+Th14nA1LyUbjk9eG5Rz332C0Y769vvxscsO2+4u8TX0L3ON0NN+f/2Om2LnkpA1KT4zpbsLjpY+W7dqnZ7hPV5i9ebuGjam7H0tJX39nuFt0jau6T1uJfaecphX+3cVNtcGna69rql+/1pTxE283DRZ9Ro0YHU6qrq2t2XlEyIBW63n3fRaMBA/ZLHS/+PXdBrkO2lb7XXTZXOXyzscNPQpv/UnX096MPqo/OKUoGJHeR+2S1q29oOry5b58GmzJpc/CpauGX26U0dXrTwfrxsdyfw0feVq7qEHz/2is2R+clleqmy3GIdnhvLhIde/hBwR+Th14nA1J4UPaDv52b+klr4e6kf9hrj2C8V15bGZ1/lGvnktq4lAHJ3ctJ/3yqDR8xKvp3+fHHZka7hZIBKTwYu3v3v/+wrl+/LgpE8bHcgPHvuT+7HU/9+jU9Rhz+bpj77OwoOKlt3fjf/48b+O+nUkDzHggg4KUAvwC9XBYmhQACpRIox6ewlerefHifUgckH+65VHModUAq1X358j6lDEi+3HMp51HOgFTK+yzHe5U6IJXjHsv5ngSkcurz3gggUG4BAlK5V4D3RwCBsgoQkLT8BCSdLwFJZ+tGJiBpfQlIOl8Cks7WjUxA0voyOgII+C1AQPJ7fZgdAgiIBQhIWmACks6XgKSzJSBpbd3oBCSdMQFJZ0tA0toyOgII+C9AQPJ/jZghAggIBQhIQtwSfwqb9k78G52ApF0TdiBpfQlIOl8Cks6WgKS1ZXQEEPBfgIDk/xoxQwQQEAr8//buPF7SqrDz/6lLIzuNCmpIDD9FRY07gtEooDga4xJ1JK6oiZEEt2xEjWTMxIlGHSaJWzRuUXHXCcQNNS6Au0BcYoRg0Jcx4ecuyNINvdS8TnU/16cf6i7d9PfW6dvv/ge6b9WpU+9TXXA/9zynBKQgroAUxRWQorwuYcvy2oEU9BWQgrguYcviGp0AgeYFBKTml8gECRBICghISd1SXMKW8xWQcrZ1ZDuQsr52IOV8BaScbR3ZGUhZX6MTINC2gIDU9vqYHQECYQEBKQssIOV8BaScrYCUta2jC0g5YwEpZysgZW2NToBA+wICUvtrZIYECAQFBKQgrkvYorgCUpTXDqQsr4AU9BWQgrh2IGVxjU6AQPMCAlLzS2SCBAgkBQSkpK5L2JK6AlJS1yVsWV07kJK+AlJS1yVsWV2jEyDQuoCA1PoKmR8BAlEBASnK6wykIK+AFMR1BlIW1yVsUV8BKcrrDKQsr9EJEGhcQEBqfIFMjwCBrICAlPV1BlLOV0DK2daRHaKd9XUGUs5XQMrZ1pEdop31NToBAm0LCEhtr4/ZESAQFhCQssACUs5XQMrZCkhZ2zq6gJQzFpBytgJS1tboBAi0LyAgtb9GZkiAQFBAQAriOkQ7iisgRXntQMryCkhBXwEpiGsHUhbX6AQINC8gIDW/RCZIgEBSQEBK6jpEO6krICV1XcKW1bUDKekrICV1XcKW1TU6AQKtCwhIra+Q+REgEBUQkKK8DtEO8gpIQVxnIGVxXcIW9RWQorzOQMryGp0AgcYFBKTGF8j0CBDICghIWV9nIOV8BaScbR3ZIdpZX2cg5XwFpJxtHdkh2llfoxMg0LaAgNT2+pgdAQJhAQEpCywg5XwFpJytgJS1raMLSDljASlnKyBlbY1OgED7AgJS+2tkhgQIBAUEpCCuQ7SjuAJSlNcOpCyvgBT0FZCCuHYgZXGNToBA8wICUvNLZIIECCQFBKSkrkO0k7oCUlLXJWxZXTuQkr4CUlLXJWxZXaMTINC6gIDU+gqZHwECUQEBKcrrEO0gr4AUxHUGUhbXJWxRXwEpyusMpCyv0QkQaFxAQGp8gUyPAIGsgICU9XUGUs5XQMrZ1pEdop31dQZSzldAytnWkR2infU1OgECbQsISG2vj9kRIBAWEJCywAJSzldAytkKSFnbOrqAlDMWkHK2AlLW1ugECLQvICC1v0ZmSIBAUEBACuI6RDuKKyBFee1AyvIKSEFfASmIawdSFtfoBAg0LyAgNb9EJkiAQFJAQErqOkQ7qSsgJXVdwpbVtQMp6SsgJXVdwpbVNToBAq0LCEitr5D5ESAQFRCQorwO0Q7yCkhBXGcgZXFdwhb1FZCivM5AyvIanQCBxgUEpMYXyPQIEMgKCEhZX2cg5XwFpJxtHdkh2llfZyDlfAWknG0d2SHaWV+jEyDQtoCA1Pb6mB0BAmEBASkLLCDlfAWknK2AlLWtowtIOWMBKWcrIGVtjU6AQPsCAlL7a2SGBAgEBQSkIK5DtKO4AlKU1w6kLK+AFPQVkIK4diBlcY1OgEDzAgJS80tkggQIJAUEpKSuQ7STugJSUtclbFldO5CSvgJSUtclbFldoxMg0LqAgNT6CpkfAQJRAQEpyusQ7SCvgBTEdQZSFtclbFFfASnK6wykLK/RCRBoXEBAanyBTI8AgayAgJT1dQZSzldAytnWkR2infV1BlLOV0DK2daRHaKd9TU6AQJtCwhIba+P2REgEBYQkLLAAlLOV0DK2QpIWds6uoCUMxaQcrYCUtbW6AQItC8gILW/RmZIgEBQQEAK4jpEO4orIEV57UDK8gpIQV8BKYhrB1IW1+gECDQvICA1v0QmSIBAUkBASuo6RDupKyAldV3CltW1AynpKyAldV3CltU1OgECrQsISK2vkPkRIBAVEJCivA7RDvIKSEFcZyBlcV3CFvUVkKK8zkDK8hqdAIHGBQSkxhfI9AgQyAoISFlfZyDlfAWknG0d2SHaWV9nIOV8BaScbR3ZIdpZX6MTINC2gIDU9vqYHQECYQEBKQssIOV8BaScrYCUta2jC0g5YwEpZysgZW2NToBA+wICUvtrZIYECAQFBKQgrkO0o7gCUpTXDqQsr4AU9BWQgrh2IGVxjU6AQPMCAlLzS2SCBAgkBQSkpK5DtJO6AlJS1yVsWV07kJK+AlJS1yVsWV2jEyDQuoCA1PoKmR8BAlEBASnK6xDtIK+AFMR1BlIW1yVsUV8BKcrrDKQsr9EJEGhcQEBqfIFMjwCBrMA/f+y3xtlH2L1Hv88f7N7PP/nsTzxmbXL43X7s15x1yW5vkATY/NnvJ4ffrcd+yDOO2q2ff/rJf+i9r/D9UxrZ+AQINCvgDbDZpTExAgRWQkBAyioLSDlfASlnW0cWkLK+AlLOV0DK2daRBaSsr9EJEGhbQEBqe33MjgCBsICAlAUWkHK+AlLOVkDK2tbRBaScsYCUsxWQsrZGJ0CgfQEBqf01MkMCBIICAlIQt5QiIOV8BaScrYCUtRWQsr4CUtbXDqSsr9EJEGhbQEBqe33MjgCBsICAlAUWkHK+AlLOVkDK2gpIWV8BKesrIGV9jU6AQNsCAlLb62N2BAiEBQSkLLCAlPMVkHK2AlLWVkDK+gpIWV8BKetrdAIE2hYQkNpeH7MjQCAsICBlgQWknK+AlLMVkLK2AlLWV0DK+gpIWV+jEyDQtoCA1Pb6mB0BAmEBASkLLCDlfAWknK2AlLUVkLK+AlLWV0DK+hqdAIG2BQSkttfH7AgQCAsISFlgASnnKyDlbAWkrK2AlPUVkLK+AlLW1+gECLQtICC1vT5mR4BAWEBAygILSDlfASlnKyBlbQWkrK+AlPUVkLK+RidAoG0BAant9TE7AgTCAgJSFlhAyvkKSDlbASlrKyBlfQWkrK+AlPU1OgECbQsISG2vj9kRIBAWEJCywAJSzldAytkKSFlbASnrKyBlfQWkrK/RCRBoW0BAant9zI4AgbCAgJQFFpByvgJSzlZAytoKSFlfASnrKyBlfY1OgEDbAgJS2+tjdgQIhAUEpCywgJTzFZBytgJS1lZAyvoKSFlfASnra3QCBNoWEJDaXh+zI0AgLCAgZYEFpJyvgJSzFZCytgJS1ldAyvoKSFlfoxMg0LaAgNT2+pgdAQJhAQEpCywg5XwFpJytgJS1FZCyvgJS1ldAyvoanQCBtgUEpLbXx+wIEAgLCEhZYAEp5ysg5WwFpKytgJT1FZCyvgJS1tfoBAi0LSAgtb0+ZkeAQFhAQMoCC0g5XwEpZysgZW0FpKyvgJT1FZCyvkYnQKBtAQGp7fUxOwIEwgICUhZYQMr5Ckg5WwEpaysgZX0FpKyvgJT1NToBAm0LCEhtr4/ZESAQFhCQssACUs5XQMrZCkhZWwEp6ysgZX0FpKyv0QkQaFtAQGp7fcyOAIGwgICUBRaQcr4CUs5WQMraCkhZXwEp6ysgZX2NToBA2wICUtvrY3YECIQFBKQssICU8xWQcrYCUtZWQMr6CkhZXwEp62t0AgTaFhCQ2l4fsyNAICwgIGWBBaScr4CUsxWQsrYCUtZXQMr6CkhZX6MTINC2gIDU9vqYHQECYQEBKQssIOV8BaScrYCUtRWQsr4CUtZXQMr6Gp0AgbYFBKS218fsCBAICwhIWWABKecrIOVsBaSsrYCU9RWQsr4CUtbX6AQItC0gILW9PmZHgEBYQEDKAgtIOV8BKWcrIGVtBaSsr4CU9RWQsr5GJ0CgbQEBqe31MTsCBMICAlIWWEDK+QpIOVsBKWsrIGV9BaSsr4CU9TU6AQJtCwhIba+P2REgEBYQkLLAAlLOV0DK2QpIWVsBKesrIGV9BaSsr9EJEGhbQEBqe33MjgCBsICAlAUWkHK+AlLOVkDK2gpIWV8BKesrIGV9jU6AQNsCAlLb62N2BAiEBQSkLLCAlPMVkHK2AlLWVkDK+gpIWV8BKetrdAIE2hYQkNpeH7MjQCAsICBlgQWknK+AlLMVkLK2AlLWV0DK+gpIWV+jEyDQtoCA1Pb6mB0BAmEBASkLLCDlfAWknK2AlLUVkLK+AlLWV0DK+hqdAIG2BQSkttfH7AgQCAsISFlgASnnKyDlbAWkrK2AlPUVkLK+AlLW1+gECLQtICC1vT5mR4BAWEBAygILSDlfASlnKyBlbQWkrK+AlPUVkLK+RidAoG0BAant9TE7AgTCAgJSFlhAyvkKSDlbASlrKyBlfQWkrK+AlPU1OgECbQsISG2vj9kRIBAWEJCywAJSzldAytkKSFlbASnrKyBlfQWkrK/RCRBoW0BAant9zI4AgbCAgJQFFpByvgJSzlZAytoKSFlfASnrKyBlfY1OgEDbAgJS2+tjdgQIhAUEpCywgJTzFZBytgJS1lZAyvoKSFlfASnra3QCBNoWEJDaXh+zI7DqBA498qR91+5/zWkbx5tf8Y1zT79w1k9QQMqugICU8xWQcrYCUtZWQMr6CkhZXwEp62t0AgTaFhCQ2l4fsyMwU4FbH3Pi7daMRmeNyuiwyf/wb9583EWfOv2c2xz32IP32LznB0aj0T3mJzgev/2yq/Z+av39Qfutf10ZjR5X/308Hr/kwnPf8tzudlvGnHvm5Vfudcr+B1yx73XG2XKnp2wejy+Zm5s7uw8wLuNvbxyPH7THuNxk8rXx+ClfP/ctb+xuc/tjnvhbZTR6w/DPb3fME188Go2eM5zrpRe89uqVDkj/9s115Q3v/sFkKofceE353cfdtByw3x6LrvM/fOTH5fNfunJym1++6/7lkQ+80fzt+18bjnfFVZvKa97+vfKDH22c3P4pv3FIOeKW+6zoa2qWAen9rz2l3PeXbzd5vpd+7yflqae+vpzzxYsWfP7HHn3b8roX/nY59KY3nNzmk5+/sDz0pNMm/94fqxvgwksuLUc94n9Mfvuq//nk8qRH3mfy71dctb784QvfWt7xgc9FrWcZkH7vmSeX2x5x68nzu+yyy8ub3vK28m8X//uCz3e5t3/+qc8uN7zhDcs73/3e8oUvXjA/3j2OPrI86pEPL+d+6jPl/R/8cNS1G/w1Z12yIo8z7UE+dvoLyvH3uvPkS//13R+VJ57y1+UTn/uXqfP51w+/stz+1je/ztfe8O5/Kr/9J6+c/PkLfv9x5Tm/89/LDW6wplx77cbykr/7v+X5f/P20n+c/gAf/+xXyv1PfH70+W/+7Pej408b/CeXl/Lnf7N3eeaTrymHHzZe9PHP/+oe5Xkv3fJ+efNDN5XTTl1Xbrj2Z3c54yNryqtP33vyB0ffeWP502etL3vvteXr9XFOeeE+5TuXbnlvf9Gz15W732nTij3fWQakFz7/6eUudzxi8lx/9OPLymmvOL189WvfmPrcn/W7jy0PPP6e81+bdvsnPPrXygkPv39Zs2ZN2bhxY3nPmR8rb33Xhyb36T/W8GtJbAEpqWtsAgRaFxCQWl8h8yMwY4EafPYsozdtKOMn1x1DdQfRJBCV8vFt4s2xT3zehvH4jMVuU5/KJPKUUup9uxA1Ho+fU8NU/6ne9j4nHjsajV6yaW7DQy4++x0/HH5tbjR66biUH26a2/Ck+vWtY715VMrBpZS/q+P35lpq3KrBqJtDDVT1MVcyIF36vWvL2/7xh+Xxv35wOfSmNyifPv+n5eJvrS9P+PWDyw1uMDd1pWsgqr/60ai74fD+/d/X27z1H39YbnOLvcu9735gGT72Sr2sZhWQatB55AOPmg85553xvyZPuQs+w+ffxaN/+9Z356NR/zY1IB1xi5tNjVB/+vSHl6c/4b+VV731n8pfvOrMSWxa6LY7031WAekJj3t0OfJud5mPPDX61F8veOFLpz695d6+jvNzP3ezsn79NfNjH3GbW5UnP/Hx5aCD1paNGzeVj/7Tx1d9QHr9Xz6j/Mav3bs8/c9eU04/8+xSA1H99Uu/+oxlvXxqLDr58Q8qf/jCN0zuX3//+7/5sPI3f/++STRa7NeJDz+u/NWpTymvfttZS952WZNZ5EYrGZDWX1PKX7x87/LFr6wpBx6wubzkuesWDUiXfHtUXvjKvcupz1g/uV2NRRd8dc18JKpx6dVvvcF8VHr5399g8kyf9ZvXlu6xjrx6KIpXAAAgAElEQVTTxvKIB24sw7Gur9ty7j+rgFSD0DH3umv529e/p3zi3PPKq//6eZPpnvwHL5o67RqAvvf9H5eXv+Yd5U53uHU55ZknlquuXj9/+xqPHv7g48qZHzx7Php1Aw0fa/j75Tjt6G0EpB2Vcz8CBFaDgIC0GlbRcyAQFBgGpOHvpz30QpFpePna9QxIJ5XR6AtlPL6yxqKtu4/2L+Nx3RU1iVuLRahu3isZkGrg+f6PNs7HoKWiTt2t9JkLrlgwMA3jUr39+z7+k8mupiuu3FTO+OiPyxMfechkh9O1127eJigFXzLbDD2rgFSD0Xd/cPl8DBoGpeHzr9HnZoesXTAwLRaFhvcdBqWU9awCUg09l//0ivKyV7x68tSGgWj4fJdz+7pDae2BB5Rvfuvb28SpbqzdaQdSDUb//w9+PL8DaBiUlno99e9/v3vesbzltD8oHz73n+d3Iy12/7oj6ecOudGyY9VSc1ns6ysZkLp5LHcHUg1G37l0bhKE6q9hBKrB6OaHbp4EovqrH5R+fNmovOJNe5U/+/31kx1Lw6B0fcyWe99ZBaQajH78k8vLqS941WSq2xt1alC6+c/fdLJrqf6qQen8L104CUzDX/3b1h1Oi8Wm5bot93YC0nKl3I4AgdUoICCtxlX1nAjsRIFhMJq/fK2US/q7evoPuVBA6l++VncDXe+AtGn8J2WP0V+WTeM/Ge8xetpo0/hvJ7/fGpDqpWt1Xv1L6IY0KxmQhsGnu8TsYcffcOqlZTU4ve9jl20z5f5laDVAvfad3y93uu2+kyhVx7/JjddMdhz1Y1J3idxiu5l24ktmm6FmEZCm7SZaKurU4HS7ww+dn/u1GzaWv3rjWZMdRfXX8BK2/uVrw91Nj33IPctfnfqE8g8fOa88/X++KUVbZhGQuh1B3/3e9+cD0kMf/Kvlfvc9tnzik+dcZ3fQcm5f49HNbnqTyWVwR939yN06IHXB56Jv/ud8QNqeHUTD3Ud1R9Gr/vx3ywH7/+zS1YUuiVvJ3Uf1L0XLAam/o6jOtbsk7eQnXFvucMSmyW6mbodR/Xo/MP3k8rltdifVrw/Hi70pbB14FgGp20H0nf/63nxA2t6o09+xdL9jjipP++0Tyj77bLlMsP7qX+LWff3qdesnwenRj3xAudEN1y6422lnmgtIO1PTWAQI7GoCAtKutmLmS2CFBabtOFrgDKT584gWCkiTs4hKubi79G2xs5QO3HfdUcMzkLqzjerOornR6KQasA7ab/1jymh0QhmP33PZVXu/s3953fDxptGtdEDqAk+dy1IBqR+E6u1rFHrH+39UTnrMTSaXwHW7iq5et7n8x6XXbnOm0rTdS7tbQPqnz3xtPuAsFpC64NS/fQ1Gd7/jLaaeZdQFovP/5VuTHU7D3U67Q0D6169fVN769ndN/kotJyAtdPu1a9eWX7r9befPUFpoN9PusgNp2o6h7QlIw91Lw6DUjX/5FVdfZ5fRSu4+2hUCUn+H0bSA9PAHbpg/12gYkM78yJ7bnIm0OwWk/o6h7QlIw91K9b4PfsC9y+vefMbkcrhpl7jV4HTQ2gPKgQfsd53zkZL/qyQgJXWNTYBA6wICUusrZH4EZiywnEvWJkFnbu7s7pDtaQGpO6NoYxmf0n362vXdgVQD0n77rTtsTRmdVs9CuvKKA64eBqTKt6vuQBoGpOFlaMOv1x1Ln/vSlZNL2OrupO5yttW8A6l/eHVd6zf/w6fKuz/0+clh2P3zjLY3IC0VgfqXra3WHUg15vzKvX52Tv5nPvuFct75F0zOJNpZO5BuectbzB/G3X+r65+DVP98NQakemnaU37jv80/7Xro9dvfd87kkrMd2YE07VK3YUCqD7bQ7ZZ7TtLO+k+SHUg7S/K646R3IA0Pv/7Ixz9Xzv70+ZNLznZkB1Id7/hjj9rmgOxhQKrPsh+Zjj/u6G12HE0bIyUsIKVkjUuAwK4gICDtCqtkjgRmKLCcgDQMRtMCUn/XUHeY9c4ISN1YlWj4uLv6GUjDM5O6gPQrRx5QbvELe03ONKr/3n2yWv9MperhDKTln4E0bRfRX/7xY8rr3/3J+cvY+n8N+wHJGUjbHqo9fLtazhlI3X129x1I1WFHzkCadulbHWvaZWk1IP3qMXfb5pPdtveg7p3xn6SWA5IzkHZshXfkDKSFwk+9RO2pT3pE+eBHPz1/gHa97d3vervJJWsnP+WEbc5b6i5pO/ezX5p6ZtKOPaPp9xKQdqamsQgQ2NUEBKRdbcXMl8AKC0w7RHvNaO6Zl1+51yldvFnOJ7VNu5wsHZB2tU9h6840euxDbzyJQsPfD881qjuQLvvpxvlDtvs7kPbac+RT2Bb5FLbhJWp1J9NjH3rP+XOP+odm179y/+MZjyj/65VnlHO+eFEZ7k7yKWzbfgpbPdPo/zvsF+c/SW25n8JWnQWk6+4QGsadeqnZ0Xe6zfyntFW3xQ7arvdfe8C+k2BUf+3oDqed/Z+elgJSvQTtOS/epzz35Gsml6X5FLYdW+2lPoWtHnx9xK0Om/+UtqUO2a5Bar99997mUO1uh9O0sYa7mHbsWSx9LwFpaSO3IEBg9QoISKt3bT0zAtdbYMuh16OzRmV0WB2sXqL206v3OW9ymdho9LjuAcZl/O2N4/GD6qVp89Fm69fH4/FLNs1tOG3N5j1ftnFuw+9dfPY7ftjdLx2QuseZxKvR6DnzIOPx27sDwFfyDKT6+DUCveHdP5hM5ZAbr5lcbtZdYjYMRsPb77vP3Pz5R/Vr3Y6kiy5ZP3W87oylH/xoyycF9Q/gvt4vjmUOMItDtLup9Q++vvR7PylPPfX1kwBUf00746h/+yuuWr/N+UfDQ7Y/+fkL5z/hrY7Xv5RueN9lUm33zWZxiHY3yRqJbnvErSe/veyyy+fPMKq/Hwak7s8Wun3/iQ8DUncI90EHrZ2/2fDxthtumXd4zVmXLPOWO/9mNRIdf687TwYeHno9DEjdQdnv/tCnp37SWrc76edvduPJeF//xnfmzz9aaOfSzn9G1x1xJQNS90loX/zKmvmJHH3njfPnFA0DUr1R/WS15710y+HjNz90Uznt1HWTT1XrftVdSq8+fcsBz/2x6u+7M5O+c+kek6+/6Nnr5s9LWgnb9CVsiz2HGnbucscjJjfpH3pdfz+MPjUQ/eIv3Gyb4TZu3Dh/KVt37tGNb3TQ5Db/8Z/f3eaQ7P79+/dLGwtIaWHjEyDQsoCA1PLqmBuBVSKw9VKyBy12FtGsnupKB6RZPc9ZPe4sA9KsnvNKPe4sA9JKPcdZPs4sA9Isn/dKPfZKBqSVek6tPM4sA1IrBsl5CEhJXWMTINC6gIDU+gqZH4FVIFB3AI3H47Mu+tTp57T2dASk7IoISDlfASlnW0cWkLK+AlLOV0DK2daRBaSsr9EJEGhbQEBqe33MjgCBsICAlAUWkHK+AlLOVkDK2tbRBaScsYCUsxWQsrZGJ0CgfQEBqf01MkMCBIICAlIQt5QiIOV8BaScrYCUtRWQsr4CUtbXDqSsr9EJEGhbQEBqe33MjgCBsICAlAUWkHK+AlLOVkDK2gpIWV8BKesrIGV9jU6AQNsCAlLb62N2BAiEBQSkLLCAlPMVkHK2AlLWVkDK+gpIWV8BKetrdAIE2hYQkNpeH7MjQCAsICBlgQWknK+AlLMVkLK2AlLWV0DK+gpIWV+jEyDQtoCA1Pb6mB0BAmEBASkLLCDlfAWknK2AlLUVkLK+AlLWV0DK+hqdAIG2BQSkttfH7AgQCAsISFlgASnnKyDlbAWkrK2AlPUVkLK+AlLW1+gECLQtICC1vT5mR4BAWEBAygILSDlfASlnKyBlbQWkrK+AlPUVkLK+RidAoG0BAant9TE7AgTCAgJSFlhAyvkKSDlbASlrKyBlfQWkrK+AlPU1OgECbQsISG2vj9kRIBAWEJCywAJSzldAytkKSFlbASnrKyBlfQWkrK/RCRBoW0BAant9zI4AgbCAgJQFFpByvgJSzlZAytoKSFlfASnrKyBlfY1OgEDbAgJS2+tjdgQIhAUEpCywgJTzFZBytgJS1lZAyvoKSFlfASnra3QCBNoWEJDaXh+zI0AgLCAgZYEFpJyvgJSzFZCytgJS1ldAyvoKSFlfoxMg0LaAgNT2+pgdAQJhAQEpCywg5XwFpJytgJS1FZCyvgJS1ldAyvoanQCBtgUEpLbXx+wIEAgLCEhZYAEp5ysg5WwFpKytgJT1FZCyvgJS1tfoBAi0LSAgtb0+ZkeAQFhAQMoCC0g5XwEpZysgZW0FpKyvgJT1FZCyvkYnQKBtAQGp7fUxOwIEwgICUhZYQMr5Ckg5WwEpaysgZX0FpKyvgJT1NToBAm0LCEhtr4/ZESAQFhCQssACUs5XQMrZCkhZWwEp6ysgZX0FpKyv0QkQaFtAQGp7fcyOAIGwgICUBRaQcr4CUs5WQMraCkhZXwEp6ysgZX2NToBA2wICUtvrY3YECIQFBKQssICU8xWQcrYCUtZWQMr6CkhZXwEp62t0AgTaFhCQ2l4fsyNAICwgIGWBBaScr4CUsxWQsrYCUtZXQMr6CkhZX6MTINC2gIDU9vqYHQECYQEBKQssIOV8BaScrYCUtRWQsr4CUtZXQMr6Gp0AgbYFBKS218fsCBAICwhIWWABKecrIOVsBaSsrYCU9RWQsr4CUtbX6AQItC0gILW9PmZHgEBYQEDKAgtIOV8BKWcrIGVtBaSsr4CU9RWQsr5GJ0CgbQEBqe31MTsCBMICAlIWWEDK+QpIOVsBKWsrIGV9BaSsr4CU9TU6AQJtCwhIba+P2REgEBYQkLLAAlLOV0DK2QpIWVsBKesrIGV9BaSsr9EJEGhbQEBqe33MjgCBsICAlAUWkHK+AlLOVkDK2gpIWV8BKesrIGV9jU6AQNsCAlLb62N2BAiEBQSkLLCAlPMVkHK2AlLWVkDK+gpIWV8BKetrdAIE2hYQkNpeH7MjQCAsICBlgQWknK+AlLMVkLK2AlLWV0DK+gpIWV+jEyDQtoCA1Pb6mB0BAmEBASkLLCDlfAWknK2AlLUVkLK+AlLWV0DK+hqdAIG2BQSkttfH7AgQCAsISFlgASnnKyDlbAWkrK2AlPUVkLK+AlLW1+gECLQtICC1vT5mR4BAWEBAygILSDlfASlnKyBlbQWkrK+AlPUVkLK+RidAoG0BAant9TE7AgTCAgJSFlhAyvkKSDlbASlrKyBlfQWkrK+AlPU1OgECbQsISG2vj9kRIBAWEJCywAJSzldAytkKSFlbASnrKyBlfQWkrK/RCRBoW0BAant9zI4AgbCAgJQFFpByvgJSzlZAytoKSFlfASnrKyBlfY1OgEDbAgJS2+tjdgQIhAUEpCywgJTzFZBytgJS1lZAyvoKSFlfASnra3QCBNoWEJDaXh+zI0AgLCAgZYEFpJyvgJSzFZCytgJS1ldAyvoKSFlfoxMg0LaAgNT2+pgdAQJhgQc/6pnj8EPs1sPf5TZ779bPP/nkr1q3OTn8bj/22v332O0NkgDnXbguOfxuPfYHXnnebv38009+7maf9/1TGtn4BAg0K+ANsNmlMTECBFZCQEDKKgtIOV8BKWdbRxaQsr4CUs5XQMrZ1pEFpKyv0QkQaFtAQGp7fcyOAIGwgICUBRaQcr4CUs5WQMra1tEFpJyxgJSzFZCytkYnQKB9AQGp/TUyQwIEggICUhC3lCIg5XwFpJytgJS1FZCyvgJS1tcOpKyv0QkQaFtAQGp7fcyOAIGwgICUBRaQcr4CUs5WQMraCkhZXwEp6ysgZX2NToBA2wICUtvrY3YECIQFBKQssICU8xWQcrYCUtZWQMr6CkhZXwEp62t0AgTaFhCQ2l4fsyNAICwgIGWBBaScr4CUsxWQsrYCUtZXQMr6CkhZX6MTINC2gIDU9vqYHQECYQEBKQssIOV8BaScrYCUtRWQsr4CUtZXQMr6Gp0AgbYFBKS218fsCBAICwhIWWABKecrIOVsBaSsrYCU9RWQsr4CUtbX6AQItC0gILW9PmZHgEBYQEDKAgtIOV8BKWcrIGVtBaSsr4CU9RWQsr5GJ0CgbQEBqe31MTsCBMICAlIWWEDK+QpIOVsBKWsrIGV9BaSsr4CU9TU6AQJtCwhIba+P2REgEBYQkLLAAlLOV0DK2QpIWVsBKesrIGV9BaSsr9EJEGhbQEBqe33MjgCBsICAlAUWkHK+AlLOVkDK2gpIWV8BKesrIGV9jU6AQNsCAlLb62N2BAiEBQSkLLCAlPMVkHK2AlLWVkDK+gpIWV8BKetrdAIE2hYQkNpeH7MjQCAsICBlgQWknK+AlLMVkLK2AlLWV0DK+gpIWV+jEyDQtoCA1Pb6mB0BAmEBASkLLCDlfAWknK2AlLUVkLK+AlLWV0DK+hqdAIG2BQSkttfH7AgQCAsISFlgASnnKyDlbAWkrK2AlPUVkLK+AlLW1+gECLQtICC1vT5mR4BAWEBAygILSDlfASlnKyBlbQWkrK+AlPUVkLK+RidAoG0BAant9TE7AgTCAgJSFlhAyvkKSDlbASlrKyBlfQWkrK+AlPU1OgECbQsISG2vj9kRIBAWEJCywAJSzldAytkKSFlbASnrKyBlfQWkrK/RCRBoW0BAant9zI4AgbCAgJQFFpByvgJSzlZAytoKSFlfASnrKyBlfY1OgEDbAgJS2+tjdgQIhAUEpCywgJTzFZBytgJS1lZAyvoKSFlfASnra3QCBNoWEJDaXh+zI0AgLCAgZYEFpJyvgJSzFZCytgJS1ldAyvoKSFlfoxMg0LaAgNT2+pgdAQJhAQEpCywg5XwFpJytgJS1FZCyvgJS1ldAyvoanQCBtgUEpLbXx+wIEAgLCEhZYAEp5ysg5WwFpKytgJT1FZCyvgJS1tfoBAi0LSAgtb0+ZkeAQFhAQMoCC0g5XwEpZysgZW0FpKyvgJT1FZCyvkYnQKBtAQGp7fUxOwIEwgICUhZYQMr5Ckg5WwEpaysgZX0FpKyvgJT1NToBAm0LCEhtr4/ZESAQFhCQssACUs5XQMrZCkhZWwEp6ysgZX0FpKyv0QkQaFtAQGp7fcyOAIGwgICUBRaQcr4CUs5WQMraCkhZXwEp6ysgZX2NToBA2wICUtvrY3YECIQFBKQssICU8xWQcrYCUtZWQMr6CkhZXwEp62t0AgTaFhCQ2l4fsyNAICwgIGWBBaScr4CUsxWQsrYCUtZXQMr6CkhZX6MTINC2gIDU9vqYHQECYQEBKQssIOV8BaScrYCUtRWQsr4CUtZXQMr6Gp0AgbYFBKS218fsCBAICwhIWWABKecrIOVsBaSsrYCU9RWQsr4CUtbX6AQItC0gILW9PmZHgEBYQEDKAgtIOV8BKWcrIGVtBaSsr4CU9RWQsr5GJ0CgbQEBqe31MTsCBMICAlIWWEDK+QpIOVsBKWsrIGV9BaSsr4CU9TU6AQJtCwhIba+P2REgEBYQkLLAAlLOV0DK2QpIWVsBKesrIGV9BaSsr9EJEGhbQEBqe33MjgCBsICAlAUWkHK+AlLOVkDK2gpIWV8BKesrIGV9jU6AQNsCAlLb62N2BAiEBQSkLLCAlPMVkHK2AlLWVkDK+gpIWV8BKetrdAIE2hYQkNpeH7MjsKICtz7mxNutGc098/Ir9zrl0gtee/WKPvjWB6tz2HNU7vD1c05/z0o8voCUVRaQcr4CUs5WQMraCkhZXwEp6ysgZX2NToBA2wICUtvrY3YEFhS47X1OPHZubu7seoNxGX9743j8oG+ce/qFWyLQ6KxRGR3W3Xk8Hr/kwnPf8tzh1zZv3nzcRZ86/Zzudrc/5om/Vf/96+e+5Y398ecnMR6//bKr9n5qF5duc9xjD95j854fGJVySf/P5x9nXD4z9c97c+vmcLtjnvjiMiqPGZXxH5cyt38Zj+8/LuXwTXMbHnLlFQdcfdB+619XRqPHzT+n3nOufza5fymlPs/uNpMYVUZv2lDGT65/1nfpHneWAekvnv/0cpc7HjGZ7o9+fFn5P684vXz1a9+YuubP+t3Hlgccf8/5r027/eMf/WvlhIffv6xZs6Zs3LixvOfMj5W3vetD5b7HHFWe9tsnlH322Xty/3Xr1pe/ff17yifPPS/+N2ylA9IjHvGocuTdj548r2uuuaa8/31nlC9/+Z8XfZ53ucvdyq89+KHlC1/4XPn4xz66zW1/87dOKocffqvJn/30p5eX977nneWb37xk8vt6v4c+7BFlr732mvz+gvO/WM44471x0+4BVjogPfrRJ5Rfvsc95m3f+95/KOdfcMGCz3c5t3/Qrz6w/Mqv3Kuceeb7thmr/vnxx9+v7LHHHpPxL/7GN8qrX/13K2ZbH2jt/lsee6V+PezXH1XuduRR874f/MCZ5atfWfy1e6c736386oMeUs774ufLJz/xs9fufe/3gHLv+xw371dfu2f833eVb31ry2u3+/X0Z/xhueLKK8pb3vS6lXqa849z3oXrVvwxuwd84eC997Ql3nsfOHjvHd7+CVPee9/6rg9NHq7/WN37cve1FMAsAtJPLi/lz/9m7/LMJ19TDj9svOhTO/+re5TnvXSfyW1ufuimctqp68oN1/7sLmd8ZE159elb/nt19J03lj991vqy95a32VIf55QX7lO+c+mWv58veva6cvc7bUpRTh1XQFpRbg9GgEBjAgJSYwtiOgS2R6BGntFo9JIaWS4++x0/7ILOeDx+TheGDj3ypH3X7rf++ZvmNpxWb9OPKjU4dY83ud3+15y2cbz5FfXPh2PX222NNMcNHu/No1IO3jweP7t7zHq70Wh05zIe/7gLSF2Q6kerrfM95fKr9n5BjVJ1DjUUjUflV7ogVh+3+/NSysdr3Kp/tjV2Hd+Nv1RA6uJaF5S65z6rgFSD0H3uddf5kPO3f/28yVI87Q9eNPUlUGPT97//4/Ly17yj3OkOty5/9MwTy1VXr5+/fY1HD3/wceXMD549iUb9X/WxbnKTG5U/fcGrJn9cx7r5z9900WC1Pa/DxW67kgHp+Ps/oNzrXvcpn/3spyYhqMafQw45ZJvo05/rLW95eHnUCY8pBx64tmzatKmce+4ntwlINUbd4Y53no9Qz/q9P5rc/eUv+z+lu+8PfvCD8vdvfG0ZPvbO8ltsnJUMSDXoHHvsMeWcc84tZ334I+Xkk3+n3PQmNylve9s7yjf+/d+vM82lbn/3I48sj3rUIyfxrYa+fozqvvalL3+5vOtd7ynD36+EbX2MlQxINfj88j3vXT7/uU9PQtATn/zUcvDBh0yNPnVut7jF4eUR//3R86/dT3/q7G0CUr3/ZT/5SXnfP24JmjUU1V+veuVfTf5Zv37LW24Jo9/85r/vVgGpvh8es/W99xPnnldevfW99+QF3ntrAPpe7733lK3vvd3tazzq3nuHYWj4WMPfp17LKxmQ1l9Tyl+8fO/yxa+sKQcesLm85LnrFg1Il3x7VF74yr3Lqc9YP7ldjUUXfHXNfCSqcenVb73BfFR6+d/fYML0rN+8tnSPdeSdNpZHPHBjGY6V8hyOKyCtlLTHIUCgRQEBqcVVMScCyxQYRp5p0Wc41EIBaXj52kJj9UPN1gD05tFo/KZxmbtvvfRtv/3WHVYvgxuVclEZj+9RA0+dw2QHUS8ADee1rB1IvfsP57erBaQajH78k8vno84wKC31EuhHoHrbGpQu+NKFk8C01K/tfaylxlvs6ysZkGowOuCAAyaBp/5abtRZaAdSDUZXXHHFJBDVX/2gdOODDy73uMc9y4c++P7JDqdhULo+Zsu970oGpBqMDjzgwPKSl/7vyfSGgWg45+XeftoOpOHYt77VrcrjH//Y8r3vf39FdyGtZECqQeeA/Q+YDzzDoLTQa2KhHUjD2y8UpHbHHUg1GNX33lO3BvXtjTo1KNUAX3ch1V81KJ2/wHtv/7Z1d+lisWm5f++Xc7uVDEjdfJa7A6kGo+9cOjcJQvXXMALVYHTzQzdPAlH91Q9KP75sVF7xpr3Kn/3++smOpWFQWo7NzriNgLQzFI1BgMCuKiAg7aorZ94ESinDiNJdOlbG5Z39S7n6WAsFpP7la/X2CwWk/p/X2+2xec83byzjU9aU0ZPG4/FZc6PR4ZvH40vqP+v38DUg1ag03Pmz0AJOOwNpoR1I41Ju0z3PXSkgdTuIvvNf35sPSIvtIJpm1d+xNLxErd5+sUvi6n3323fvVbcDqb9DqBp0l5h97V++suilZdMC0rQg1A9SNab0dyfVxxs+fvpNaiUD0nOe/ceTp9MFpKV2BS339gtdwlbvf8ghB5ePf/wTk8eddplb2nclA9Jwh1ANQw9+yMPLv37tq/O7iKY93+UEpG630jXr188Hqm6s3S0g1ffeGnzqe28XkLY36vR3LN1vcHlw997bXeLWff3qdesnwenRj3xAudEN15aFdjvtrNd0ywGpv6OoPt/ukrSTn3BtucMRmya7mbodRsPA9JPL57bZnVS/PhxvZxkuNo6AtBLKHoMAgVYFBKRWV8a8CCxDYFrkmXYGUv+ysWkBqdtJVENQd2nXQgFpMn4ZnbZpbsOT+gGp/vueo7m/GpfyrboT6aD91j+mH5C6+9TL6Jbx1La5yXxA6p2BVG/Qne1U/31XDEj9HUPbE5CGO4jqfR/8gHuX1735jMm5RtMucatG3ZlLq/UMpOGOoZ0RkL5x8b/Nx6dhQLr1bY7Y5vK41R6QfnrFT+d3AC0nIC3n9gsFpHp+0l3vcpfJeV71HKTVfgbSMOTsrIBUxz3kJjednN/lDKQyeW8c7hjanoA03K1U79u999bL4brx6+XFXSSqwemgtQeUAw/Yb/5sut35DKThDqNpAenhD9wwf65Rf4dSDUhnfmTPbc5EEpC29/+o3J4AAQLXT0BAun5+7k1gpgYaFjMAAB+/SURBVALLuWSt7iwaj8rz+4dsD3cDTc4nGo1O6h94vb07kK66ap9v18vUNo/Hr61nIfXPKNqeHUjTQKftQBr+2UIBqR+upsWz9BlIw8OvP/rxz5WzP33+5JKzHdmBVMe737FHzR+QXb2GAan+2WKXqa3WS9jsQMq9HS13R1E3g+XefqFL2Po7jrpY9e3/+I9VewlbcgdSXZPd8RK2+j7XP/z6I1vfe3d0B1Id7/it771dABoGpO69tztj6fjjjt5mx9G0MRJ/a+1ASqj+bEw7kLK+RidAoG0BAant9TE7AosKLCcgDQ/WnhZRJodel3Jxd0B1fdDtOQOpv3Opm3A/INU/W+oMpMWe6LSAVG8/iWNbL2Pr/3s31rRL/Fo5RHtHzkCaFo/qc62XsD31SY8oH/zop+cP0K63PfKut5t6mdq026f+qjkDKSVbykpewrbcM426Z7vc208LSHX30e1ue9ttDugeBqmc6s9GXslL2NJnINUzlY46+pfLh8/6wDaf7La7XcJWV3dHzkBaKPzUS9S6994uKtXb3v2ut5tcsnbyU07Y5ryl7pK2cz/7pWWdV7ejr/OWA5IzkHZ0Vd2PAAECbQgISG2sg1kQ2CGBBQ7RflD//KOlIsq0y9cWCkgLfQrbUgGpfsLacj6FbSGE5exA6i7dG28eP6nugJr/RLdSvtN5zGIH0kLPaalPYauXmx1xq8PmP6VtqV1D/XON6mP2dzj1P8Gtfm049g69+JZ5p5UMSEt9Clv9+jHH3Ld8+UsXbHMm0kKHaPsUtp8t8lKfqla/fvzx9yvnnX/+5JPTlrp9N/JCO5D6Y+0OO5CW+hS2+vV73+e48pUv//M2ZyItdAbS7/zus8rFF180/8lsNRTttffe17mMbXcMSEt9Cls9+Lp7762XpS11yHYNUvVMuf6h2t0ZS9PGGu5iWuZb6XbdrKWAVC9Be86L9ynPPfmayWVpPoVtu5bSjQkQINCcgIDU3JKYEIHlCXRBpt56XMbfrpeojeY2/mCPzXt+YDQa3aMbZTwef2HT3IaH1LOHhucj1bOR6u1Go9E20akLSHNzc2dvM5vx+O39y9wWik/1Pv0dSDUg1T9b6nymJQPS4AykMh4/Zbhrqj/n/hlJ0557DU3pS9gWW83uTKJ6m+Gh18PIUwPRL/7CzbYZbuPGjfOXsnXnHt34RgdNbvMf//nd8rStH0tdL3E74eH3n5wnU3+t1jOQ6nOr0efIux89eZ714+Hf/74zJp+SVn8NA1J3UPaBB66dd61nxbz3Pe8s3/zmJZM/q5/sdvjhWz7ufPi17oyl+lH09dcF539x0cO6l/c3e/m3WskdSHVWdWfQL99jy1tLtX3ve/+hnH/BBZPfDwPSUrfvolBnV2//3e9+b/6Q7v5j1a+t9jOQ6nN82K8/qtztyKPmfT/4gTPndwsNA1J3MPbwtdudc9Qfq3vt9s9AqjuebnnLLa/r+mvTpk3l0586ez44Lf9VuOO3PO/CdTt+5+t5zxp27nLHIyaj1Pfe7tDr+vth9KmBaKH33rrrqDv3qP/e2z8ku3//7j17NZ2B1H0S2he/suW/L/XX0XfeOH9O0TAg1a/XT1Z73kv3mdz25oduKqedum7yqWrdr7pL6dWn732dseofdGcmfefSPSZff9Gz182fl3Q9XxbLvrtL2JZN5YYECKxCAQFpFS6qp0RgewTqrqL66Wk1pmzP/VbLbWcZkFaL4WLPYyV3IO0Onv3nuNIBaXfzXclL2HY32/p8ZxmQVrv3LHYgrXbT/vMTkHan1fZcCRAYCghIXhMEdmOBuoNozeY9X7ZxbsPv7cino60GOgEpu4oCUs5XQMrZ1pEFpKyvgJTzFZBytnVkASnra3QCBNoWEJDaXh+zI0AgLCAgZYEFpJyvgJSzFZCytnV0ASlnLCDlbAWkrK3RCRBoX0BAan+NzJAAgaCAgBTELaUISDlfASlnKyBlbQWkrK+AlPW1Aynra3QCBNoWEJDaXh+zI0AgLCAgZYEFpJyvgJSzFZCytgJS1ldAyvoKSFlfoxMg0LaAgNT2+pgdAQJhAQEpCywg5XwFpJytgJS1FZCyvgJS1ldAyvoanQCBtgUEpLbXx+wIEAgLCEhZYAEp5ysg5WwFpKytgJT1FZCyvgJS1tfoBAi0LSAgtb0+ZkeAQFhAQMoCC0g5XwEpZysgZW0FpKyvgJT1FZCyvkYnQKBtAQGp7fUxOwIEwgICUhZYQMr5Ckg5WwEpaysgZX0FpKyvgJT1NToBAm0LCEhtr4/ZESAQFhCQssACUs5XQMrZCkhZWwEp6ysgZX0FpKyv0QkQaFtAQGp7fcyOAIGwgICUBRaQcr4CUs5WQMraCkhZXwEp6ysgZX2NToBA2wICUtvrY3YECIQFBKQssICU8xWQcrYCUtZWQMr6CkhZXwEp62t0AgTaFhCQ2l4fsyNAICwgIGWBBaScr4CUsxWQsrYCUtZXQMr6CkhZX6MTINC2gIDU9vqYHQECYQEBKQssIOV8BaScrYCUtRWQsr4CUtZXQMr6Gp0AgbYFBKS218fsCBAICwhIWWABKecrIOVsBaSsrYCU9RWQsr4CUtbX6AQItC0gILW9PmZHgEBYQEDKAgtIOV8BKWcrIGVtBaSsr4CU9RWQsr5GJ0CgbQEBqe31MTsCBMICAlIWWEDK+QpIOVsBKWsrIGV9BaSsr4CU9TU6AQJtCwhIba+P2REgEBYQkLLAAlLOV0DK2QpIWVsBKesrIGV9BaSsr9EJEGhbQEBqe33MjgCBsICAlAUWkHK+AlLOVkDK2gpIWV8BKesrIGV9jU6AQNsCAlLb62N2BAiEBQSkLLCAlPMVkHK2AlLWVkDK+gpIWV8BKetrdAIE2hYQkNpeH7MjQCAsICBlgQWknK+AlLMVkLK2AlLWV0DK+gpIWV+jEyDQtoCA1Pb6mB0BAmEBASkLLCDlfAWknK2AlLUVkLK+AlLWV0DK+hqdAIG2BQSkttfH7AgQCAsISFlgASnnKyDlbAWkrK2AlPUVkLK+AlLW1+gECLQtICC1vT5mR4BAWEBAygILSDlfASlnKyBlbQWkrK+AlPUVkLK+RidAoG0BAant9TE7AgTCAgJSFlhAyvkKSDlbASlrKyBlfQWkrK+AlPU1OgECbQsISG2vj9kRIBAWEJCywAJSzldAytkKSFlbASnrKyBlfQWkrK/RCRBoW0BAant9zI4AgbCAgJQFFpByvgJSzlZAytoKSFlfASnrKyBlfY1OgEDbAgJS2+tjdgQIhAUEpCywgJTzFZBytgJS1lZAyvoKSFlfASnra3QCBNoWEJDaXh+zI0AgLCAgZYEFpJyvgJSzFZCytgJS1ldAyvoKSFlfoxMg0LaAgNT2+pgdAQJhAQEpCywg5XwFpJytgJS1FZCyvgJS1ldAyvoanQCBtgUEpLbXx+wIEAgLCEhZYAEp5ysg5WwFpKytgJT1FZCyvgJS1tfoBAi0LSAgtb0+ZkeAQFhAQMoCC0g5XwEpZysgZW0FpKyvgJT1FZCyvkYnQKBtAQGp7fUxOwIEwgICUhZYQMr5Ckg5WwEpaysgZX0FpKyvgJT1NToBAm0LCEhtr4/ZESAQFhCQssACUs5XQMrZCkhZWwEp6ysgZX0FpKyv0QkQaFtAQGp7fcyOAIGwgICUBRaQcr4CUs5WQMraCkhZXwEp6ysgZX2NToBA2wICUtvrY3YECIQFBKQssICU8xWQcrYCUtZWQMr6CkhZXwEp62t0AgTaFhCQ2l4fsyNAICwgIGWBBaScr4CUsxWQsrYCUtZXQMr6CkhZX6MTINC2gIDU9vqYHQECYQEBKQssIOV8BaScrYCUtRWQsr4CUtZXQMr6Gp0AgbYFBKS218fsCBAICwhIWWABKecrIOVsBaSsrYCU9RWQsr4CUtbX6AQItC0gILW9PmZHgEBYQEDKAgtIOV8BKWcrIGVtBaSsr4CU9RWQsr5GJ0CgbQEBqe31MTsCBAgQIECAAAECBAgQIECAwMwFBKSZL4EJECBAgAABAgQIECBAgAABAgTaFhCQ2l4fsyNAgAABAgQIECBAgAABAgQIzFxAQJr5EpgAAQIECBAgQGDnCNz6mBNvt2cZvWlDGT/5G+eefuHOGXX3GOW29znx2NFo9KALz33Lc3ePZ7zjz7K+ztaM5p55+ZV7nXLpBa+9esdH2vF73v7YE0/YMC5f8zrfcUP3JECAwPYKCEjbK+b2BAiseoEt/2M8OmtURodNe7KbN28+7qJPnX7OrgRxu2Oe+OI63935G6PbHPfYg/fYvOcHRqPRPebXbjx++2VX7f3U7hug2x/zxN8qpRzf/zPfkC/9St/6jfdLNs1teMjFZ7/jh/Uew9fcVv83byzjU3zDt7jpcl6rC42wu7xe6+trNBo9Z+LQ+3s8+Ts8Gr2h79O9Z9fX6dzc3NmTu5TxtzeOxw/qvxbrmOPx+Kz6/j5tnPF4/IX6Gl+zec+HDR+jfu3yddeecNA+N3jxuJTD+38XuvWsj9v/80OPPGnfg/Zb/7oyGj2um+94PH7Jzn6fXshq2n/rusdfymrre2X5+rlveeMCVts8j/nxxuOn1Pt0z3f+voM/7z9+f71Gcxt/MHkfL+WSMhp9rJTNV47L6H+XcXlndZv2d6dbt/re1H19PB4/p//f8f57/4H7rjtqsdfJ0u+IbkGAAIHVKyAgrd619cwIENgJAqvlmzEBqZThNw7dN2/jUr7TfcMmIO3YX5phHJr/Jq6US7oYNy0y7dijrf57Lee1uvoVln6Gw/e1aa+xyXv4aPSIr5/zlhfVERd6HVbzNZv3fNnGuQ2/V0PDtPeCbaLHIDTXr/WC0I3KePyeLpRsjSQnjMfjG3YBqReVzu4Ho9sf+8TnbRiPz9jZkXWBoPuBfkip81+73/rnb5rbcFo1WMhqcrv9rzlt43jzK+o8h1bzDqWU/t//udHopeNSfrhpbsOTejHnzaNSDi6l/F3fazwqz+8HvuE6zsevcflMP/hPC0T9576cgFR/oOD9aum/f25BgMDuKSAg7Z7r7lkTILBMgWkBafgTzu6n2/1vCPo/Gd80N/7rufHovZMdTb2flHdjl9HobaWUl01+ytr76fN1fjrd+wnt5H+IR6MDR+Px2slPr8fjp2wo48/1d05N+0ny5GnXOay79rlr97nBe/rfPEx+Sl3KxfV/4odz636CW+/e38WzK+3GmvaNw/AbHwFpmX8xBjfrXqubx+PX1p/qT765K6Mn1ddo/5vMcSm32SbW9XaK7EqvpR1TWv69lvNa7e8q6e+mGb5nDd8rpu28Wf7M2rrlMIosJ5QvFAaGl69dv4A0PrOMRw+vMaqK1TBVRuMzx+PRH3UBabHxE8rLiW3Dx13Ianj52rTn0otIH6//TZnsKBqNTiqj0RfKeHxlb+fS/mU8rrtCJ7dbKPB0c+vH6cV2IPX/29af3/4HXLFv/W/YYjuQBKTEK9CYBAisFgEBabWspOdBgEBEYPjNWO9/Xl/bhZY1ZXRa/YlqF1dKKZOfKA93YQz/x7X7Cepw6339H9ufXr3PefXShm53zHCHx5ZvCstj+j+h7Z8H0Y093jx+Uv2Gfjk/fR4GpBqjurnV57bYc+8uW4oswk4adKFdHd03LvVhBKQdx652XSDqLm+pv+8uCbrO62vr35v62tmyu6Dc4evnnP6eHZ/B6rnnUq/VyW6Z8Z6P/fo5b3lFfdZbbW9ed2Lst9+6w/pnIA3fK1Y6XCRXZfi+1l0OtViMXCiK9C9fW+i9oHsuCxn2Q+rcaHR4vf3m8fiS+u/1n6PRaHKZ55VXHHD15NK1rdEkadSNPbQa/vdn2hwWsupfvraY1XUuC6sBadP4T8oeo7+s/xzvMXraaNP4bye/32qxPTt/pp2BtNAOpO6HI3YgrcSrzWMQILCaBQSk1by6nhsBAtdbYBiQhv9z2/+GYfMeG/+1/5PN4U9gh7+ftrup+5/8jWX85uFBuP1vwJf6SfvwsXYkIA0ff7HnviucCTXtbIzhN5rTzvKoL6LVtGvjev+lWGCAbodBjRgH7b/+9+tlOHuMy03qocT1kpg9Nu85f/7R5LU0N3rz8Aya1Nx2tXGX81rtP6f+383x5jWHXCcg9c4/66/TrA4/3lnrMe19cPh3uH/+TX3chS5z634Q0MXwxc5SWuhrXfivO/G2/vegXp51Wd2JNLdpzS8NA1K3Y29neSw2zjSraWcg9d8Tp1lNO8tsoaDWf61NzhUajU6avD/st/4xZTQ6oV7md9lVe7+zH9Ou7+tz6vlhkzfxLWcvCUgr8WrzGAQIrGYBAWk1r67nRoDA9RaYFpC6wzX7g9f/6d4ZAanbxVED0tSDvLf+T/C0bwamHcja/U/zzgpICz33XSkgdZcuLPjNp0O0d+jvTfeN5Xg8fmn9RrF+01xjRv2kps2jzW+c2zz68+7sk/oA/W/Ch9/k79AEVtGdht/kTnutXueQ4a0HPO/uAan/MljoLJ4u5PRjUf/yyvnX55Rzjhb72vBSzn7078eYFnYgTfvrMvnvT+/soWkBaVrgWSggTduB1O2S64Ld0GJ7diBNew7TAlH/z4b/ne7G6O+gXCg0rqK3GE+FAAECOywgIO0wnTsSILA7CEwNSFt/ijr86f1Sl51s7w6k4U/E+97DbyiHB0KndiB1P0HeFXcuDNdnOefMVPPVcpB6+u9rL2B+oZTx/vXQ4u6w3VEpF43H40MX+nSppXbUpefe2vhLvVaHO7jsQHrLcxdaw2GQWO5OyutzBtK0nUXDx13pSwmX83ds+LqbFnP6UawfX4afXrnQGUj9A6/r/Ye3W+oMpKX+ri50/27e3Y6n4RrtyBlRS83F1wkQILAaBQSk1biqnhMBAjtNYKkzkLqfVNZ/Xt8dSP3Huuqqfb7dPwNpPmRsPSdmoYA0PIh0VMrkrKZFPiVncnBp7xNtXtA/RHtDGT+5+zSg4RlI/ee+K+5A6ubfv5TKGUjX76/O/K6iwYHvk0Ple39WvzGtj9S9bpbzze31m9mude9p3wT3o9HWSwMn5+l0nxg2LuWk+vvdeQfS8ByjuupLhYGtB75PzrHrn+WWDkj9D12YxaewDQ8Nn38/3HpO07RPYZt2+Vq933Z8CtvkErb+DyCGAakbb6lPYVvob/RSO5Dqe87W3UaTvy/dGWx1x293ZuA0i13rHcRsCRAgkBMQkHK2RiZAYBUILOdT2IafUNZdIrWcM5CGl6n1z58YXpLWP4dnqUta6m1H4/K97qORtzkXYusnwdXDducffzx++3g0unw0Hp+/UECqyzk8X2JXuvRosbMvum9W9iyjew5/km4H0vL/IneXVV3nHJXBeUfXOXul9+mEy3+01XvLpV6rV19bHrHfnuWUyScwbvn14e4j4neXgDTZUVLDZP219fUzOWdnbu7s/iuj/8mW/cv+uvfTrX/nS/cR8t190wGpPs60y477891Zr/BpVt2HOoxGo/oJaFsZx1/ooso0q+5Ms+FOwmlnQg2fx0JnG00LSF3A6a/lcs+hW+gMpOF5d9uY1B8Abd58XBe0pz337gcpO2tNjEOAAIFdVUBA2lVXzrwJENjlBYSJXX4JPQECBHZhge4Sy43jza8QCJZeyGk7vJa+l1sQIECAwGoSEJBW02p6LgQI7FICAtIutVwmS4DAKhPYshNu7pmXX7nXKbviuW4ruRx1Z8+azXu+rB6O37/UbyXn4LEIECBAYPYCAtLs18AMCBAgQIAAAQIECBAgQIAAAQJNCwhITS+PyREgQIAAAQIECBAgQIAAAQIEZi8gIM1+DcyAAAECBAgQIECAAAECBAgQINC0gIDU9PKYHAECBAgQIECAAAECBAgQIEBg9gIC0uzXwAwIECBAgAABAgQIECBAgAABAk0LCEhNL4/JESBAgAABAgQIECBAgAABAgRmLyAgzX4NzIAAAQIECBAgQIAAAQIECBAg0LSAgNT08pgcAQIECBAgQIAAAQIECBAgQGD2AgLS7NfADAgQIECAAAECBAgQIECAAAECTQsISE0vj8kRIECAAAECBAgQIECAAAECBGYvICDNfg3MgAABAgQIECBAgAABAgQIECDQtICA1PTymBwBAgQIECBAgAABAgQIECBAYPYCAtLs18AMCBAgQIAAAQIECBAgQIAAAQJNCwhITS+PyREgQIAAAQIECBAgQIAAAQIEZi8gIM1+DcyAAAECBAgQIECAAAECBAgQINC0gIDU9PKYHAECBAgQIECAAAECBAgQIEBg9gIC0uzXwAwIECBAgAABAgQIECBAgAABAk0LCEhNL4/JESBAgAABAgQIECBAgAABAgRmLyAgzX4NzIAAAQIECBAgQIAAAQIECBAg0LSAgNT08pgcAQIECBAgQIAAAQIECBAgQGD2AgLS7NfADAgQIECAAAECBAgQIECAAAECTQsISE0vj8kRIECAAAECBAgQIECAAAECBGYvICDNfg3MgAABAgQIECBAgAABAgQIECDQtICA1PTymBwBAgQIECBAgAABAgQIECBAYPYCAtLs18AMCBAgQIAAAQIECBAgQIAAAQJNCwhITS+PyREgQIAAAQIECBAgQIAAAQIEZi8gIM1+DcyAAAECBAgQIECAAAECBAgQINC0gIDU9PKYHAECBAgQIECAAAECBAgQIEBg9gIC0uzXwAwIECBAgAABAgQIECBAgAABAk0LCEhNL4/JESBAgAABAgQIECBAgAABAgRmLyAgzX4NzIAAAQIECBAgQIAAAQIECBAg0LSAgNT08pgcAQIECBAgQIAAAQIECBAgQGD2AgLS7NfADAgQIECAAAECBAgQIECAAAECTQsISE0vj8kRIECAAAECBAgQIECAAAECBGYvICDNfg3MgAABAgQIECBAgAABAgQIECDQtICA1PTymBwBAgQIECBAgAABAgQIECBAYPYCAtLs18AMCBAgQIAAAQIECBAgQIAAAQJNCwhITS+PyREgQIAAAQIECBAgQIAAAQIEZi8gIM1+DcyAAAECBAgQIECAAAECBAgQINC0gIDU9PKYHAECBAgQIECAAAECBAgQIEBg9gIC0uzXwAwIECBAgAABAgQIECBAgAABAk0LCEhNL4/JESBAgAABAgQIECBAgAABAgRmLyAgzX4NzIAAAQIECBAgQIAAAQIECBAg0LSAgNT08pgcAQIECBAgQIAAAQIECBAgQGD2AgLS7NfADAgQIECAAAECBAgQIECAAAECTQsISE0vj8kRIECAAAECBAgQIECAAAECBGYvICDNfg3MgAABAgQIECBAgAABAgQIECDQtICA1PTymBwBAgQIECBAgAABAgQIECBAYPYCAtLs18AMCBAgQIAAAQIECBAgQIAAAQJNCwhITS+PyREgQIAAAQIECBAgQIAAAQIEZi8gIM1+DcyAAAECBAgQIECAAAECBAgQINC0gIDU9PKYHAECBAgQIECAAAECBAgQIEBg9gIC0uzXwAwIECBAgAABAgQIECBAgAABAk0LCEhNL4/JESBAgAABAgQIECBAgAABAgRmLyAgzX4NzIAAAQIECBAgQIAAAQIECBAg0LSAgNT08pgcAQIECBAgQIAAAQIECBAgQGD2AgLS7NfADAgQIECAAAECBAgQIECAAAECTQsISE0vj8kRIECAAAECBAgQIECAAAECBGYvICDNfg3MgAABAgQIECBAgAABAgQIECDQtICA1PTymBwBAgQIECBAgAABAgQIECBAYPYCAtLs18AMCBAgQIAAAQIECBAgQIAAAQJNCwhITS+PyREgQIAAAQIECBAgQIAAAQIEZi8gIM1+DcyAAAECBAgQIECAAAECBAgQINC0gIDU9PKYHAECBAgQIECAAAECBAgQIEBg9gIC0uzXwAwIECBAgAABAgQIECBAgAABAk0LCEhNL4/JESBAgAABAgQIECBAgAABAgRmLyAgzX4NzIAAAQIECBAgQIAAAQIECBAg0LSAgNT08pgcAQIECBAgQIAAAQIECBAgQGD2AgLS7NfADAgQIECAAAECBAgQIECAAAECTQsISE0vj8kRIECAAAECBAgQIECAAAECBGYvICDNfg3MgAABAgQIECBAgAABAgQIECDQtICA1PTymBwBAgQIECBAgAABAgQIECBAYPYCAtLs18AMCBAgQIAAAQIECBAgQIAAAQJNCwhITS+PyREgQIAAAQIECBAgQIAAAQIEZi8gIM1+DcyAAAECBAgQIECAAAECBAgQINC0gIDU9PKYHAECBAgQIECAAAECBAgQIEBg9gIC0uzXwAwIECBAgAABAgQIECBAgAABAk0LCEhNL4/JESBAgAABAgQIECBAgAABAgRmLyAgzX4NzIAAAQIECBAgQIAAAQIECBAg0LSAgNT08pgcAQIECBAgQIAAAQIECBAgQGD2AgLS7NfADAgQIECAAAECBAgQIECAAAECTQsISE0vj8kRIECAAAECBAgQIECAAAECBGYvICDNfg3MgAABAgQIECBAgAABAgQIECDQtICA1PTymBwBAgQIECBAgAABAgQIECBAYPYCAtLs18AMCBAgQIAAAQIECBAgQIAAAQJNCwhITS+PyREgQIAAAQIECBAgQIAAAQIEZi8gIM1+DcyAAAECBAgQIECAAAECBAgQINC0gIDU9PKYHAECBAgQIECAAAECBAgQIEBg9gIC0uzXwAwIECBAgAABAgQIECBAgAABAk0LCEhNL4/JESBAgAABAgQIECBAgAABAgRmLyAgzX4NzIAAAQIECBAgQIAAAQIECBAg0LSAgNT08pgcAQIECBAgQIAAAQIECBAgQGD2Av8PkeD1qGMpSjYAAAAASUVORK5CYII=",
      "text/html": [
       "<div>                            <div id=\"1d515f8c-d311-4e88-a5cc-549f7fa169b8\" class=\"plotly-graph-div\" style=\"height:700px; width:700px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1d515f8c-d311-4e88-a5cc-549f7fa169b8\")) {                    Plotly.newPlot(                        \"1d515f8c-d311-4e88-a5cc-549f7fa169b8\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"texttemplate\":\"%{z:.3f}\",\"x\":[\"Temperature\",\"RH\",\"Ws\",\"Rain\",\"ISI/FFMC\",\"ISI/DMC*BUI\"],\"y\":[\"Temperature\",\"RH\",\"Ws\",\"Rain\",\"ISI/FFMC\",\"ISI/DMC*BUI\"],\"z\":[[1.0,-0.6258031164954618,-0.26655433804477885,-0.36199473054181064,0.6796786673246272,-0.26306524646322565],[-0.6258031164954618,1.0,0.283655925582598,0.24040564388635627,-0.6503892872790109,0.10006725790928185],[-0.26655433804477885,0.283655925582598,1.0,0.06117103871532854,-0.0408700533843875,0.017583341224866107],[-0.36199473054181064,0.24040564388635627,0.06117103871532854,1.0,-0.7671703171328567,0.13068082612879003],[0.6796786673246272,-0.6503892872790109,-0.0408700533843875,-0.7671703171328567,1.0,-0.2683191642421729],[-0.26306524646322565,0.10006725790928185,0.017583341224866107,0.13068082612879003,-0.2683191642421729,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"automargin\":true},\"coloraxis\":{\"colorscale\":[[0.0,\"#00224e\"],[0.1111111111111111,\"#123570\"],[0.2222222222222222,\"#3b496c\"],[0.3333333333333333,\"#575d6d\"],[0.4444444444444444,\"#707173\"],[0.5555555555555556,\"#8a8678\"],[0.6666666666666666,\"#a59c74\"],[0.7777777777777778,\"#c3b369\"],[0.8888888888888888,\"#e1cc55\"],[1.0,\"#fee838\"]],\"showscale\":false},\"title\":{\"text\":\"Spearman Correlation\",\"x\":0.5},\"margin\":{\"t\":40,\"pad\":0,\"autoexpand\":true},\"font\":{\"size\":12},\"height\":700,\"width\":700,\"paper_bgcolor\":\"rgba(0,0,0,0)\",\"plot_bgcolor\":\"rgba(0,0,0,0)\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1d515f8c-d311-4e88-a5cc-549f7fa169b8');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FWI is calculated from FFMC, DMC and ISI and is the world wide accepted indx for fire prediction\n",
    "\n",
    "df2=X_train_scaled_df.copy()\n",
    "\n",
    "#df2=X_train.copy()\n",
    "\n",
    "\n",
    "######################################################\n",
    "\n",
    "fig = px.imshow(df2.corr(method='spearman',numeric_only=True),text_auto='.3f',color_continuous_scale='Cividis',\n",
    "          title='Spearman Correlation')\n",
    "fig.update_coloraxes(showscale=False)\n",
    "fig.update_layout(margin=dict(t=40,pad=0),\n",
    "                  title_x=0.5,\n",
    "                  height=700,width=700,\n",
    "                  paper_bgcolor = \"rgba(0,0,0,0)\",\n",
    "                    plot_bgcolor = \"rgba(0,0,0,0)\",                  \n",
    "                    margin_autoexpand=True,\n",
    "                    font=dict(size = 12))\n",
    "\n",
    "fig.update_yaxes(automargin=True)\n",
    "\n",
    "\n",
    "fig.show()\n",
    "#######################\n",
    "pio.write_html(fig,file ='../Regression/tuned_models_raw4_4/Corerlation_engineered.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dffe6ec-c94c-4bc0-a069-948ee31b9389",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f4d465fa-8f3e-44f9-8d28-44383e846009",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "\n",
    "    'LinearReg': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'SVR': SVR(), \n",
    "    'DecisionTreeReg': DecisionTreeRegressor(),\n",
    "    'RandomForestReg': RandomForestRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3f7b2332-f1c4-4001-8f9a-624f5be353d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \n",
    "    'SVR': {'C':[10e-3,10e-2,10e-1,1.0,5,10],\n",
    "           'kernel':['linear','rbf','sigmoid','poly'],\n",
    "           #'gamma':['scale','auto']\n",
    "           },\n",
    "    \n",
    "    \n",
    "    'RandomForestReg': {'n_estimators':[100,300,500],\n",
    "                        'criterion':['squared_error','friedman_mse'],\n",
    "                        'max_depth':[2,4,5,6,8,10,15,20,None],\n",
    "                        'random_state':[100],\n",
    "                       },\n",
    "    \n",
    "    'DecisionTreeReg': {'criterion':['squared_error','friedman_mse'],\n",
    "                        'max_depth':[2,4,5,6,8,10,15,20,None],\n",
    "                        'random_state':[100],\n",
    "                       },\n",
    "    \n",
    "    'Ridge': {'alpha': [1,0.1,0.01,0.001,5],                \n",
    "                'fit_intercept': [True,False]                \n",
    "               },\n",
    "    \n",
    "    'LinearReg':{'fit_intercept': [True, False],\n",
    "              \n",
    "                },\n",
    "    \n",
    "    'Lasso':{'alpha':[1,0.1, 0.01, 0.001,5],\n",
    "              'max_iter':[1000,5000],               \n",
    "               'random_state':[100],\n",
    "             },\n",
    "    'ElasticNet': {'alpha': [0.001,0.01, 0.1, 1,0],\n",
    "              'l1_ratio': [0,0.2 ,0.3, 0.5, 0.8, 0.9,1],\n",
    "              'max_iter':[5000,6000,7000],\n",
    "              'fit_intercept':[True,False]\n",
    "             \n",
    "             }\n",
    "    \n",
    "    \n",
    "           \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7b99920e-bc32-401c-a69e-f3262a24fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf,parameters):\n",
    "    \n",
    "    gs = GridSearchCV(clf,param_grid=parameters, cv=5,refit='r2', verbose=3,\n",
    "                      scoring=['neg_mean_squared_error','r2'],\n",
    "                      error_score='raise').fit(X_train_scaled_df, y_train)\n",
    "    \n",
    "    #y_pred = gs.predict(X_test)    \n",
    "    \n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e9da45ea-c78b-4f0f-8487-11f28e12fed1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For  LinearReg\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END fit_intercept=True; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END fit_intercept=True; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END fit_intercept=True; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END fit_intercept=True; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END fit_intercept=True; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END fit_intercept=False; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END fit_intercept=False; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END fit_intercept=False; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END fit_intercept=False; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END fit_intercept=False; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "\n",
      "For  Ridge\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END alpha=1, fit_intercept=True; neg_mean_squared_error: (test=-3.368) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True; neg_mean_squared_error: (test=-8.475) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True; neg_mean_squared_error: (test=-8.818) r2: (test=0.870) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True; neg_mean_squared_error: (test=-4.679) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True; neg_mean_squared_error: (test=-4.403) r2: (test=0.862) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False; neg_mean_squared_error: (test=-56.384) r2: (test=-0.064) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False; neg_mean_squared_error: (test=-59.434) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False; neg_mean_squared_error: (test=-68.617) r2: (test=-0.014) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False; neg_mean_squared_error: (test=-55.468) r2: (test=-0.112) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False; neg_mean_squared_error: (test=-55.431) r2: (test=-0.742) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True; neg_mean_squared_error: (test=-3.410) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True; neg_mean_squared_error: (test=-8.428) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True; neg_mean_squared_error: (test=-8.680) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True; neg_mean_squared_error: (test=-4.710) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True; neg_mean_squared_error: (test=-4.455) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False; neg_mean_squared_error: (test=-56.502) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False; neg_mean_squared_error: (test=-59.260) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False; neg_mean_squared_error: (test=-68.411) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False; neg_mean_squared_error: (test=-55.888) r2: (test=-0.120) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False; neg_mean_squared_error: (test=-55.347) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True; neg_mean_squared_error: (test=-3.415) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True; neg_mean_squared_error: (test=-8.667) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True; neg_mean_squared_error: (test=-4.461) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False; neg_mean_squared_error: (test=-56.514) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False; neg_mean_squared_error: (test=-59.242) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False; neg_mean_squared_error: (test=-68.390) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False; neg_mean_squared_error: (test=-55.933) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False; neg_mean_squared_error: (test=-55.338) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True; neg_mean_squared_error: (test=-8.666) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False; neg_mean_squared_error: (test=-59.241) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False; neg_mean_squared_error: (test=-55.937) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False; neg_mean_squared_error: (test=-55.338) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=5, fit_intercept=True; neg_mean_squared_error: (test=-3.303) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=5, fit_intercept=True; neg_mean_squared_error: (test=-8.795) r2: (test=0.890) total time=   0.0s\n",
      "[CV 3/5] END alpha=5, fit_intercept=True; neg_mean_squared_error: (test=-9.507) r2: (test=0.860) total time=   0.0s\n",
      "[CV 4/5] END alpha=5, fit_intercept=True; neg_mean_squared_error: (test=-4.718) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=5, fit_intercept=True; neg_mean_squared_error: (test=-4.304) r2: (test=0.865) total time=   0.0s\n",
      "[CV 1/5] END alpha=5, fit_intercept=False; neg_mean_squared_error: (test=-56.054) r2: (test=-0.057) total time=   0.0s\n",
      "[CV 2/5] END alpha=5, fit_intercept=False; neg_mean_squared_error: (test=-60.252) r2: (test=0.249) total time=   0.0s\n",
      "[CV 3/5] END alpha=5, fit_intercept=False; neg_mean_squared_error: (test=-69.578) r2: (test=-0.028) total time=   0.0s\n",
      "[CV 4/5] END alpha=5, fit_intercept=False; neg_mean_squared_error: (test=-53.982) r2: (test=-0.082) total time=   0.0s\n",
      "[CV 5/5] END alpha=5, fit_intercept=False; neg_mean_squared_error: (test=-55.808) r2: (test=-0.754) total time=   0.0s\n",
      "\n",
      "For  Lasso\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END alpha=1, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-4.534) r2: (test=0.914) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-12.015) r2: (test=0.850) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-13.245) r2: (test=0.804) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-4.386) r2: (test=0.912) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-5.533) r2: (test=0.826) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-4.534) r2: (test=0.914) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-12.015) r2: (test=0.850) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-13.245) r2: (test=0.804) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-4.386) r2: (test=0.912) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-5.533) r2: (test=0.826) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-3.284) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-8.725) r2: (test=0.891) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-8.985) r2: (test=0.867) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-4.734) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-4.340) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-3.284) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-8.725) r2: (test=0.891) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-8.985) r2: (test=0.867) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-4.734) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-4.340) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-3.397) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-8.449) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-8.688) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-4.720) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-4.439) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-3.397) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-8.449) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-8.688) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-4.720) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-4.439) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-3.414) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-8.668) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-4.714) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-4.459) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-3.414) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-8.668) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-4.714) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-4.459) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=5, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-29.293) r2: (test=0.447) total time=   0.0s\n",
      "[CV 2/5] END alpha=5, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-51.002) r2: (test=0.364) total time=   0.0s\n",
      "[CV 3/5] END alpha=5, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-44.849) r2: (test=0.337) total time=   0.0s\n",
      "[CV 4/5] END alpha=5, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-25.133) r2: (test=0.496) total time=   0.0s\n",
      "[CV 5/5] END alpha=5, max_iter=1000, random_state=100; neg_mean_squared_error: (test=-18.423) r2: (test=0.421) total time=   0.0s\n",
      "[CV 1/5] END alpha=5, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-29.293) r2: (test=0.447) total time=   0.0s\n",
      "[CV 2/5] END alpha=5, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-51.002) r2: (test=0.364) total time=   0.0s\n",
      "[CV 3/5] END alpha=5, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-44.849) r2: (test=0.337) total time=   0.0s\n",
      "[CV 4/5] END alpha=5, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-25.133) r2: (test=0.496) total time=   0.0s\n",
      "[CV 5/5] END alpha=5, max_iter=5000, random_state=100; neg_mean_squared_error: (test=-18.423) r2: (test=0.421) total time=   0.0s\n",
      "\n",
      "For  ElasticNet\n",
      "Fitting 5 folds for each of 210 candidates, totalling 1050 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.081e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.245e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.253e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.932e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.940e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.081e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.245e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.253e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.932e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.940e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.081e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.245e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.253e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-3.408) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-8.429) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-8.686) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-4.708) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-4.453) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-3.408) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-8.429) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-8.686) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-4.708) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-4.453) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-3.408) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-8.429) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-8.686) r2: (test=0.872) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.932e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.940e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-4.708) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-4.453) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-3.409) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-8.428) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-8.682) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-4.709) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-4.454) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-3.409) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-8.428) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-8.682) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-4.709) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-4.454) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-3.409) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-8.428) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-8.682) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-4.709) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-4.454) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-3.410) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-8.428) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-8.680) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-4.710) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-4.455) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-3.410) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-8.428) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-8.680) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-4.710) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-4.455) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-3.410) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-8.428) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-8.680) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-4.710) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-4.455) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-3.411) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-8.427) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-8.677) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-4.711) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-4.456) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-3.411) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-8.427) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-8.677) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-4.711) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-4.456) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-3.411) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-8.427) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-8.677) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-4.711) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-4.456) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-3.413) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-8.671) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-4.713) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-4.458) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-3.413) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-8.671) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-4.713) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-4.458) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-3.413) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-8.671) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-4.713) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-4.458) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-3.414) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-8.669) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-4.458) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-3.414) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-8.669) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-4.458) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-3.414) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-8.669) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-4.458) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-3.414) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-8.668) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-4.714) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-4.459) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-3.414) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-8.668) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-4.714) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-4.459) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-3.414) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-8.426) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-8.668) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-4.714) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-4.459) r2: (test=0.860) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.774e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.697e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.549e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.785e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.774e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.697e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.549e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.785e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-56.497) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-59.266) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-68.419) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-55.871) r2: (test=-0.120) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-55.350) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-56.497) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-59.266) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-68.419) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-55.871) r2: (test=-0.120) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-55.350) r2: (test=-0.739) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.774e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.697e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.549e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.785e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-56.497) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-59.266) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-68.419) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-55.871) r2: (test=-0.120) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-55.350) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-56.499) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-59.262) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-68.413) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-55.881) r2: (test=-0.120) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-55.348) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-56.499) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-59.262) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-68.413) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-55.881) r2: (test=-0.120) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-55.348) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-56.499) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-59.262) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-68.413) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-55.881) r2: (test=-0.120) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-55.348) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-56.500) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-59.260) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-68.410) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-55.886) r2: (test=-0.120) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-55.347) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-56.500) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-59.260) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-68.410) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-55.886) r2: (test=-0.120) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-55.347) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-56.500) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-59.260) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-68.410) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-55.886) r2: (test=-0.120) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-55.347) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-56.502) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-59.255) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-68.404) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-55.897) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-55.346) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-56.502) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-59.255) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-68.404) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-55.897) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-55.346) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-56.502) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-59.255) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-68.404) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-55.897) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-55.346) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-56.506) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-59.248) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-68.395) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-55.912) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-55.342) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-56.506) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-59.248) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-68.395) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-55.912) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-55.342) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-56.506) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-59.248) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-68.395) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-55.912) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-55.342) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-56.507) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-59.245) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-68.392) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-55.918) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-55.342) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-56.507) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-59.245) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-68.392) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-55.918) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-55.342) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-56.507) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-59.245) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-68.392) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-55.918) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-55.342) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-56.509) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-59.243) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-68.389) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-55.923) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-55.341) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-56.509) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-59.243) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-68.389) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-55.923) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-55.341) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-56.509) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-59.243) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-68.389) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-55.923) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-55.341) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-3.355) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-8.497) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-8.875) r2: (test=0.869) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-4.671) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-4.386) r2: (test=0.862) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-3.355) r2: (test=0.937) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.455e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.602e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.593e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.305e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.316e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.455e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.602e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.593e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.305e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.316e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.455e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.602e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.593e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.305e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.316e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-8.497) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-8.875) r2: (test=0.869) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-4.671) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-4.386) r2: (test=0.862) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-3.355) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-8.497) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-8.875) r2: (test=0.869) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-4.671) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-4.386) r2: (test=0.862) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-3.362) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-8.486) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-8.837) r2: (test=0.869) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-4.679) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-4.394) r2: (test=0.862) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-3.362) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-8.486) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-8.837) r2: (test=0.869) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-4.679) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-4.394) r2: (test=0.862) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-3.362) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-8.486) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-8.837) r2: (test=0.869) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-4.679) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-4.394) r2: (test=0.862) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-3.366) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-8.481) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-8.818) r2: (test=0.870) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-4.683) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-4.399) r2: (test=0.862) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-3.366) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-8.481) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-8.818) r2: (test=0.870) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-4.683) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-4.399) r2: (test=0.862) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-3.366) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-8.481) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-8.818) r2: (test=0.870) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-4.683) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-4.399) r2: (test=0.862) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-3.374) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-8.471) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-8.781) r2: (test=0.870) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-4.692) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-4.410) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-3.374) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-8.471) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-8.781) r2: (test=0.870) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-4.692) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-4.410) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-3.374) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-8.471) r2: (test=0.894) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-8.781) r2: (test=0.870) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-4.692) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-4.410) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-3.387) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-8.457) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-8.725) r2: (test=0.871) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-4.708) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-4.427) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-3.387) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-8.457) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-8.725) r2: (test=0.871) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-4.708) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-4.427) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-3.387) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-8.457) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-8.725) r2: (test=0.871) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-4.708) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-4.427) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-3.392) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-8.453) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-8.707) r2: (test=0.871) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-4.433) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-3.392) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-8.453) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-8.707) r2: (test=0.871) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-4.433) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-3.392) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-8.453) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-8.707) r2: (test=0.871) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-4.433) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-3.397) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-8.449) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-8.688) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-4.720) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-4.439) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-3.397) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-8.449) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-8.688) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-4.720) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-4.439) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-3.397) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-8.449) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-8.688) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-4.720) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-4.439) r2: (test=0.861) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.812e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.730e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.582e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.829e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.838e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.812e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.730e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.582e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.829e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-56.343) r2: (test=-0.063) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-59.505) r2: (test=0.258) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-68.701) r2: (test=-0.015) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-55.310) r2: (test=-0.109) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-55.465) r2: (test=-0.743) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-56.343) r2: (test=-0.063) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-59.505) r2: (test=0.258) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-68.701) r2: (test=-0.015) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-55.310) r2: (test=-0.109) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.838e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.812e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.730e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.582e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.829e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.838e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-55.465) r2: (test=-0.743) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-56.343) r2: (test=-0.063) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-59.505) r2: (test=0.258) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-68.701) r2: (test=-0.015) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-55.310) r2: (test=-0.109) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-55.465) r2: (test=-0.743) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-56.360) r2: (test=-0.063) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-59.456) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-68.641) r2: (test=-0.014) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-55.402) r2: (test=-0.111) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-55.449) r2: (test=-0.742) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-56.360) r2: (test=-0.063) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-59.456) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-68.641) r2: (test=-0.014) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-55.402) r2: (test=-0.111) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-55.449) r2: (test=-0.742) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-56.360) r2: (test=-0.063) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-59.456) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-68.641) r2: (test=-0.014) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-55.402) r2: (test=-0.111) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-55.449) r2: (test=-0.742) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-56.368) r2: (test=-0.063) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-59.431) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-68.612) r2: (test=-0.014) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-55.450) r2: (test=-0.112) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-55.442) r2: (test=-0.742) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-56.368) r2: (test=-0.063) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-59.431) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-68.612) r2: (test=-0.014) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-55.450) r2: (test=-0.112) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-55.442) r2: (test=-0.742) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-56.368) r2: (test=-0.063) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-59.431) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-68.612) r2: (test=-0.014) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-55.450) r2: (test=-0.112) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-55.442) r2: (test=-0.742) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-56.387) r2: (test=-0.064) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-59.382) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-68.553) r2: (test=-0.013) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-55.546) r2: (test=-0.113) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-55.428) r2: (test=-0.742) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-56.387) r2: (test=-0.064) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-59.382) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-68.553) r2: (test=-0.013) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-55.546) r2: (test=-0.113) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-55.428) r2: (test=-0.742) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-56.387) r2: (test=-0.064) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-59.382) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-68.553) r2: (test=-0.013) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-55.546) r2: (test=-0.113) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-55.428) r2: (test=-0.742) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-56.416) r2: (test=-0.064) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-59.308) r2: (test=0.260) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-68.464) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-55.693) r2: (test=-0.116) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-55.406) r2: (test=-0.741) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-56.416) r2: (test=-0.064) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-59.308) r2: (test=0.260) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-68.464) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-55.693) r2: (test=-0.116) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-55.406) r2: (test=-0.741) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-56.416) r2: (test=-0.064) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-59.308) r2: (test=0.260) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-68.464) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-55.693) r2: (test=-0.116) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-55.406) r2: (test=-0.741) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-56.427) r2: (test=-0.065) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-59.284) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-68.435) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-55.743) r2: (test=-0.117) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-55.398) r2: (test=-0.741) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-56.427) r2: (test=-0.065) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-59.284) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-68.435) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-55.743) r2: (test=-0.117) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-55.398) r2: (test=-0.741) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-56.427) r2: (test=-0.065) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-59.284) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-68.435) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-55.743) r2: (test=-0.117) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-55.398) r2: (test=-0.741) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-56.437) r2: (test=-0.065) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-59.260) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-68.406) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-55.794) r2: (test=-0.118) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-55.391) r2: (test=-0.741) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-56.437) r2: (test=-0.065) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-59.260) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-68.406) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-55.794) r2: (test=-0.118) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-55.391) r2: (test=-0.741) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-56.437) r2: (test=-0.065) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-59.260) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-68.406) r2: (test=-0.011) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-55.794) r2: (test=-0.118) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-55.391) r2: (test=-0.741) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.519e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.508e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.357e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.322e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.393e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.519e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.508e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.357e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.322e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.393e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.519e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.508e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.357e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-3.578) r2: (test=0.933) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-9.837) r2: (test=0.877) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-11.170) r2: (test=0.835) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-5.323) r2: (test=0.893) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-4.520) r2: (test=0.858) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-3.578) r2: (test=0.933) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-9.837) r2: (test=0.877) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-11.170) r2: (test=0.835) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-5.323) r2: (test=0.893) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-4.520) r2: (test=0.858) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-3.578) r2: (test=0.933) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-9.837) r2: (test=0.877) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-11.170) r2: (test=0.835) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.322e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.393e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-5.323) r2: (test=0.893) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-4.520) r2: (test=0.858) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-3.452) r2: (test=0.935) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-9.534) r2: (test=0.881) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-10.715) r2: (test=0.842) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-5.079) r2: (test=0.898) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-4.449) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-3.452) r2: (test=0.935) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-9.534) r2: (test=0.881) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-10.715) r2: (test=0.842) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-5.079) r2: (test=0.898) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-4.449) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-3.452) r2: (test=0.935) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-9.534) r2: (test=0.881) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-10.715) r2: (test=0.842) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-5.079) r2: (test=0.898) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-4.449) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-3.400) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-9.389) r2: (test=0.883) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-10.484) r2: (test=0.845) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-4.964) r2: (test=0.900) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-4.418) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-3.400) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-9.389) r2: (test=0.883) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-10.484) r2: (test=0.845) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-4.964) r2: (test=0.900) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-4.418) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-3.400) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-9.389) r2: (test=0.883) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-10.484) r2: (test=0.845) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-4.964) r2: (test=0.900) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-4.418) r2: (test=0.861) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-3.331) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-9.133) r2: (test=0.886) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-10.042) r2: (test=0.852) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-4.758) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-4.366) r2: (test=0.863) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-3.331) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-9.133) r2: (test=0.886) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-10.042) r2: (test=0.852) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-4.758) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-4.366) r2: (test=0.863) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-3.331) r2: (test=0.937) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-9.133) r2: (test=0.886) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-10.042) r2: (test=0.852) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-4.758) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-4.366) r2: (test=0.863) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-3.278) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-8.857) r2: (test=0.890) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-9.403) r2: (test=0.861) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-4.670) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-4.326) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-3.278) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-8.857) r2: (test=0.890) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-9.403) r2: (test=0.861) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-4.670) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-4.326) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-3.278) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-8.857) r2: (test=0.890) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-9.403) r2: (test=0.861) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-4.670) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-4.326) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-3.275) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-8.784) r2: (test=0.890) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-9.193) r2: (test=0.864) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-4.694) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-4.328) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-3.275) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-8.784) r2: (test=0.890) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-9.193) r2: (test=0.864) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-4.694) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-4.328) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-3.275) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-8.784) r2: (test=0.890) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-9.193) r2: (test=0.864) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-4.694) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-4.328) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-3.284) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-8.725) r2: (test=0.891) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-8.985) r2: (test=0.867) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-4.734) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-4.340) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-3.284) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-8.725) r2: (test=0.891) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-8.985) r2: (test=0.867) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-4.734) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-4.340) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-3.284) r2: (test=0.938) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-8.725) r2: (test=0.891) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-8.985) r2: (test=0.867) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-4.734) r2: (test=0.905) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-4.340) r2: (test=0.864) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.124e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.000e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.847e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.180e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.132e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.124e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.000e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.847e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.180e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.132e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.124e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.000e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.847e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.180e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.132e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-56.046) r2: (test=-0.057) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-62.089) r2: (test=0.226) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-71.709) r2: (test=-0.059) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-52.130) r2: (test=-0.045) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-56.537) r2: (test=-0.777) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-56.046) r2: (test=-0.057) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-62.089) r2: (test=0.226) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-71.709) r2: (test=-0.059) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-52.130) r2: (test=-0.045) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-56.537) r2: (test=-0.777) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-56.046) r2: (test=-0.057) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-62.089) r2: (test=0.226) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-71.709) r2: (test=-0.059) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-52.130) r2: (test=-0.045) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-56.537) r2: (test=-0.777) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-55.900) r2: (test=-0.055) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-61.582) r2: (test=0.232) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-71.135) r2: (test=-0.051) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-52.318) r2: (test=-0.049) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-56.179) r2: (test=-0.765) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-55.900) r2: (test=-0.055) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-61.582) r2: (test=0.232) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-71.135) r2: (test=-0.051) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-52.318) r2: (test=-0.049) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-56.179) r2: (test=-0.765) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-55.900) r2: (test=-0.055) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-61.582) r2: (test=0.232) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-71.135) r2: (test=-0.051) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-52.318) r2: (test=-0.049) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-56.179) r2: (test=-0.765) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-55.839) r2: (test=-0.053) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-61.325) r2: (test=0.235) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-70.841) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-52.440) r2: (test=-0.051) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-55.992) r2: (test=-0.759) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-55.839) r2: (test=-0.053) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-61.325) r2: (test=0.235) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-70.841) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-52.440) r2: (test=-0.051) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-55.992) r2: (test=-0.759) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-55.839) r2: (test=-0.053) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-61.325) r2: (test=0.235) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-70.841) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-52.440) r2: (test=-0.051) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-55.992) r2: (test=-0.759) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-55.750) r2: (test=-0.052) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-60.804) r2: (test=0.242) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-70.240) r2: (test=-0.038) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-52.753) r2: (test=-0.057) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-55.603) r2: (test=-0.747) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-55.750) r2: (test=-0.052) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-60.804) r2: (test=0.242) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-70.240) r2: (test=-0.038) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-52.753) r2: (test=-0.057) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-55.603) r2: (test=-0.747) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-55.750) r2: (test=-0.052) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-60.804) r2: (test=0.242) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-70.240) r2: (test=-0.038) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-52.753) r2: (test=-0.057) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-55.603) r2: (test=-0.747) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-55.719) r2: (test=-0.051) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-60.013) r2: (test=0.252) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-69.307) r2: (test=-0.024) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-53.577) r2: (test=-0.074) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-55.305) r2: (test=-0.738) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-55.719) r2: (test=-0.051) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-60.013) r2: (test=0.252) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-69.307) r2: (test=-0.024) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-53.577) r2: (test=-0.074) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-55.305) r2: (test=-0.738) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-55.719) r2: (test=-0.051) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-60.013) r2: (test=0.252) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-69.307) r2: (test=-0.024) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-53.577) r2: (test=-0.074) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-55.305) r2: (test=-0.738) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-55.741) r2: (test=-0.052) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-59.749) r2: (test=0.255) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-68.989) r2: (test=-0.019) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-53.967) r2: (test=-0.082) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-55.361) r2: (test=-0.740) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-55.741) r2: (test=-0.052) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-59.749) r2: (test=0.255) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-68.989) r2: (test=-0.019) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-53.967) r2: (test=-0.082) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-55.361) r2: (test=-0.740) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-55.741) r2: (test=-0.052) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-59.749) r2: (test=0.255) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-68.989) r2: (test=-0.019) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-53.967) r2: (test=-0.082) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-55.361) r2: (test=-0.740) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-55.786) r2: (test=-0.052) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-59.487) r2: (test=0.258) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-68.668) r2: (test=-0.014) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-54.402) r2: (test=-0.091) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-55.664) r2: (test=-0.749) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-55.786) r2: (test=-0.052) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-59.487) r2: (test=0.258) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-68.668) r2: (test=-0.014) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-54.402) r2: (test=-0.091) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-55.664) r2: (test=-0.749) total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-55.786) r2: (test=-0.052) total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-59.487) r2: (test=0.258) total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-68.668) r2: (test=-0.014) total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-54.402) r2: (test=-0.091) total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-55.664) r2: (test=-0.749) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-12.406) r2: (test=0.766) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-24.663) r2: (test=0.692) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-26.839) r2: (test=0.604) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-13.906) r2: (test=0.721) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-10.560) r2: (test=0.668) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-12.406) r2: (test=0.766) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-24.663) r2: (test=0.692) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e+03, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.983e+03, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.983e+03, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.983e+03, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-26.839) r2: (test=0.604) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-13.906) r2: (test=0.721) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-10.560) r2: (test=0.668) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-12.406) r2: (test=0.766) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-24.663) r2: (test=0.692) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-26.839) r2: (test=0.604) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-13.906) r2: (test=0.721) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-10.560) r2: (test=0.668) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-11.392) r2: (test=0.785) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-23.159) r2: (test=0.711) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-25.319) r2: (test=0.626) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-12.601) r2: (test=0.747) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-9.834) r2: (test=0.691) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-11.392) r2: (test=0.785) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-23.159) r2: (test=0.711) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-25.319) r2: (test=0.626) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-12.601) r2: (test=0.747) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-9.834) r2: (test=0.691) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-11.392) r2: (test=0.785) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-23.159) r2: (test=0.711) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-25.319) r2: (test=0.626) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-12.601) r2: (test=0.747) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-9.834) r2: (test=0.691) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-10.807) r2: (test=0.796) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-22.273) r2: (test=0.722) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-24.404) r2: (test=0.639) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-11.811) r2: (test=0.763) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-9.403) r2: (test=0.705) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-10.807) r2: (test=0.796) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-22.273) r2: (test=0.722) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-24.404) r2: (test=0.639) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-11.811) r2: (test=0.763) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-9.403) r2: (test=0.705) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-10.807) r2: (test=0.796) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-22.273) r2: (test=0.722) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-24.404) r2: (test=0.639) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-11.811) r2: (test=0.763) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-9.403) r2: (test=0.705) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-9.439) r2: (test=0.822) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-20.134) r2: (test=0.749) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-22.130) r2: (test=0.673) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-9.844) r2: (test=0.803) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-8.357) r2: (test=0.737) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-9.439) r2: (test=0.822) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-20.134) r2: (test=0.749) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-22.130) r2: (test=0.673) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-9.844) r2: (test=0.803) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-8.357) r2: (test=0.737) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-9.439) r2: (test=0.822) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-20.134) r2: (test=0.749) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-22.130) r2: (test=0.673) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-9.844) r2: (test=0.803) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-8.357) r2: (test=0.737) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-6.690) r2: (test=0.874) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-15.499) r2: (test=0.807) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-16.959) r2: (test=0.749) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-5.539) r2: (test=0.889) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-6.149) r2: (test=0.807) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-6.690) r2: (test=0.874) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-15.499) r2: (test=0.807) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-16.959) r2: (test=0.749) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-5.539) r2: (test=0.889) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-6.149) r2: (test=0.807) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-6.690) r2: (test=0.874) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-15.499) r2: (test=0.807) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-16.959) r2: (test=0.749) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-5.539) r2: (test=0.889) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-6.149) r2: (test=0.807) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-5.539) r2: (test=0.896) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-13.615) r2: (test=0.830) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-14.986) r2: (test=0.779) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-4.458) r2: (test=0.911) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-5.641) r2: (test=0.823) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-5.539) r2: (test=0.896) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-13.615) r2: (test=0.830) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-14.986) r2: (test=0.779) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-4.458) r2: (test=0.911) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-5.641) r2: (test=0.823) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-5.539) r2: (test=0.896) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-13.615) r2: (test=0.830) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-14.986) r2: (test=0.779) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-4.458) r2: (test=0.911) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-5.641) r2: (test=0.823) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-4.534) r2: (test=0.914) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-12.015) r2: (test=0.850) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-13.245) r2: (test=0.804) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-4.386) r2: (test=0.912) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-5.533) r2: (test=0.826) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-4.534) r2: (test=0.914) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-12.015) r2: (test=0.850) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-13.245) r2: (test=0.804) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-4.386) r2: (test=0.912) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-5.533) r2: (test=0.826) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-4.534) r2: (test=0.914) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-12.015) r2: (test=0.850) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-13.245) r2: (test=0.804) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-4.386) r2: (test=0.912) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-5.533) r2: (test=0.826) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-68.484) r2: (test=-0.292) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-79.336) r2: (test=0.011) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-90.733) r2: (test=-0.340) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-51.038) r2: (test=-0.023) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-56.582) r2: (test=-0.778) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-68.484) r2: (test=-0.292) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-79.336) r2: (test=0.011) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-90.733) r2: (test=-0.340) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-51.038) r2: (test=-0.023) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-56.582) r2: (test=-0.778) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-68.484) r2: (test=-0.292) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-79.336) r2: (test=0.011) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-90.733) r2: (test=-0.340) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-51.038) r2: (test=-0.023) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.272e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.069e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.448e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.272e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.069e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.272e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.069e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-56.582) r2: (test=-0.778) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-67.590) r2: (test=-0.275) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-77.680) r2: (test=0.031) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-89.070) r2: (test=-0.316) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-50.290) r2: (test=-0.008) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-56.290) r2: (test=-0.769) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-67.590) r2: (test=-0.275) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-77.680) r2: (test=0.031) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-89.070) r2: (test=-0.316) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-50.290) r2: (test=-0.008) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-56.290) r2: (test=-0.769) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-67.590) r2: (test=-0.275) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-77.680) r2: (test=0.031) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-89.070) r2: (test=-0.316) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-50.290) r2: (test=-0.008) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-56.290) r2: (test=-0.769) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-67.100) r2: (test=-0.266) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-76.691) r2: (test=0.044) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-88.072) r2: (test=-0.301) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-49.858) r2: (test=0.001) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-56.054) r2: (test=-0.761) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-67.100) r2: (test=-0.266) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-76.691) r2: (test=0.044) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-88.072) r2: (test=-0.301) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-49.858) r2: (test=0.001) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-56.054) r2: (test=-0.761) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-67.100) r2: (test=-0.266) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-76.691) r2: (test=0.044) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-88.072) r2: (test=-0.301) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-49.858) r2: (test=0.001) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-56.054) r2: (test=-0.761) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-66.047) r2: (test=-0.246) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-74.251) r2: (test=0.074) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-85.591) r2: (test=-0.264) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-48.867) r2: (test=0.020) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-55.281) r2: (test=-0.737) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-66.047) r2: (test=-0.246) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-74.251) r2: (test=0.074) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-85.591) r2: (test=-0.264) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-48.867) r2: (test=0.020) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-55.281) r2: (test=-0.737) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-66.047) r2: (test=-0.246) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-74.251) r2: (test=0.074) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-85.591) r2: (test=-0.264) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-48.867) r2: (test=0.020) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-55.281) r2: (test=-0.737) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-62.708) r2: (test=-0.183) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-68.639) r2: (test=0.144) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-79.862) r2: (test=-0.180) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-47.008) r2: (test=0.058) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-52.598) r2: (test=-0.653) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-62.708) r2: (test=-0.183) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-68.639) r2: (test=0.144) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-79.862) r2: (test=-0.180) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-47.008) r2: (test=0.058) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-52.598) r2: (test=-0.653) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-62.708) r2: (test=-0.183) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-68.639) r2: (test=0.144) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-79.862) r2: (test=-0.180) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-47.008) r2: (test=0.058) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-52.598) r2: (test=-0.653) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-60.641) r2: (test=-0.144) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-65.975) r2: (test=0.177) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-77.416) r2: (test=-0.144) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-46.716) r2: (test=0.064) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-50.933) r2: (test=-0.600) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-60.641) r2: (test=-0.144) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-65.975) r2: (test=0.177) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-77.416) r2: (test=-0.144) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-46.716) r2: (test=0.064) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-50.933) r2: (test=-0.600) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-60.641) r2: (test=-0.144) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-65.975) r2: (test=0.177) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-77.416) r2: (test=-0.144) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-46.716) r2: (test=0.064) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-50.933) r2: (test=-0.600) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-58.521) r2: (test=-0.104) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-64.177) r2: (test=0.200) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-74.755) r2: (test=-0.104) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-47.188) r2: (test=0.054) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-52.334) r2: (test=-0.645) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-58.521) r2: (test=-0.104) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-64.177) r2: (test=0.200) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-74.755) r2: (test=-0.104) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-47.188) r2: (test=0.054) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-52.334) r2: (test=-0.645) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-58.521) r2: (test=-0.104) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-64.177) r2: (test=0.200) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-74.755) r2: (test=-0.104) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-47.188) r2: (test=0.054) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-52.334) r2: (test=-0.645) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e+02, tolerance: 8.111e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+02, tolerance: 7.276e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+02, tolerance: 7.588e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-3.416) r2: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-8.423) r2: (test=0.895) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-8.665) r2: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-4.714) r2: (test=0.906) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=True, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-4.462) r2: (test=0.860) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=5000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+02, tolerance: 8.233e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e+02, tolerance: 8.725e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=6000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0, max_iter=7000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=5000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=6000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.2, max_iter=7000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=5000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=6000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.3, max_iter=7000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=5000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=6000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.5, max_iter=7000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=5000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=6000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.8, max_iter=7000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=5000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=6000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=0.9, max_iter=7000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=5000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n",
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=6000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "[CV 1/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-56.516) r2: (test=-0.066) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+03, tolerance: 1.417e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e+03, tolerance: 1.385e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e+03, tolerance: 1.357e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+03, tolerance: 1.566e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning:\n",
      "\n",
      "With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning:\n",
      "\n",
      "Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "\n",
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+03, tolerance: 1.657e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-59.240) r2: (test=0.261) total time=   0.0s\n",
      "[CV 3/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-68.388) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 4/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-55.938) r2: (test=-0.121) total time=   0.0s\n",
      "[CV 5/5] END alpha=0, fit_intercept=False, l1_ratio=1, max_iter=7000; neg_mean_squared_error: (test=-55.337) r2: (test=-0.739) total time=   0.0s\n",
      "\n",
      "For  SVR\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END C=0.01, kernel=linear; neg_mean_squared_error: (test=-48.634) r2: (test=0.083) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, kernel=linear; neg_mean_squared_error: (test=-59.438) r2: (test=0.259) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, kernel=linear; neg_mean_squared_error: (test=-61.737) r2: (test=0.088) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, kernel=linear; neg_mean_squared_error: (test=-29.027) r2: (test=0.418) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, kernel=linear; neg_mean_squared_error: (test=-20.712) r2: (test=0.349) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, kernel=rbf; neg_mean_squared_error: (test=-81.028) r2: (test=-0.529) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, kernel=rbf; neg_mean_squared_error: (test=-88.070) r2: (test=-0.098) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, kernel=rbf; neg_mean_squared_error: (test=-88.733) r2: (test=-0.311) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, kernel=rbf; neg_mean_squared_error: (test=-49.113) r2: (test=0.015) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, kernel=rbf; neg_mean_squared_error: (test=-30.767) r2: (test=0.033) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, kernel=sigmoid; neg_mean_squared_error: (test=-76.201) r2: (test=-0.438) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, kernel=sigmoid; neg_mean_squared_error: (test=-84.351) r2: (test=-0.052) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, kernel=sigmoid; neg_mean_squared_error: (test=-85.049) r2: (test=-0.256) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, kernel=sigmoid; neg_mean_squared_error: (test=-46.073) r2: (test=0.076) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, kernel=sigmoid; neg_mean_squared_error: (test=-29.323) r2: (test=0.079) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, kernel=poly; neg_mean_squared_error: (test=-61.868) r2: (test=-0.167) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, kernel=poly; neg_mean_squared_error: (test=-71.098) r2: (test=0.113) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, kernel=poly; neg_mean_squared_error: (test=-77.998) r2: (test=-0.152) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, kernel=poly; neg_mean_squared_error: (test=-34.798) r2: (test=0.302) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, kernel=poly; neg_mean_squared_error: (test=-27.964) r2: (test=0.121) total time=   0.0s\n",
      "[CV 1/5] END C=0.1, kernel=linear; neg_mean_squared_error: (test=-8.368) r2: (test=0.842) total time=   0.0s\n",
      "[CV 2/5] END C=0.1, kernel=linear; neg_mean_squared_error: (test=-15.285) r2: (test=0.809) total time=   0.0s\n",
      "[CV 3/5] END C=0.1, kernel=linear; neg_mean_squared_error: (test=-18.216) r2: (test=0.731) total time=   0.0s\n",
      "[CV 4/5] END C=0.1, kernel=linear; neg_mean_squared_error: (test=-6.232) r2: (test=0.875) total time=   0.0s\n",
      "[CV 5/5] END C=0.1, kernel=linear; neg_mean_squared_error: (test=-5.921) r2: (test=0.814) total time=   0.0s\n",
      "[CV 1/5] END C=0.1, kernel=rbf; neg_mean_squared_error: (test=-58.334) r2: (test=-0.100) total time=   0.0s\n",
      "[CV 2/5] END C=0.1, kernel=rbf; neg_mean_squared_error: (test=-71.133) r2: (test=0.113) total time=   0.0s\n",
      "[CV 3/5] END C=0.1, kernel=rbf; neg_mean_squared_error: (test=-68.251) r2: (test=-0.008) total time=   0.0s\n",
      "[CV 4/5] END C=0.1, kernel=rbf; neg_mean_squared_error: (test=-36.936) r2: (test=0.260) total time=   0.0s\n",
      "[CV 5/5] END C=0.1, kernel=rbf; neg_mean_squared_error: (test=-21.012) r2: (test=0.340) total time=   0.0s\n",
      "[CV 1/5] END C=0.1, kernel=sigmoid; neg_mean_squared_error: (test=-34.148) r2: (test=0.356) total time=   0.0s\n",
      "[CV 2/5] END C=0.1, kernel=sigmoid; neg_mean_squared_error: (test=-45.304) r2: (test=0.435) total time=   0.0s\n",
      "[CV 3/5] END C=0.1, kernel=sigmoid; neg_mean_squared_error: (test=-47.192) r2: (test=0.303) total time=   0.0s\n",
      "[CV 4/5] END C=0.1, kernel=sigmoid; neg_mean_squared_error: (test=-19.227) r2: (test=0.615) total time=   0.0s\n",
      "[CV 5/5] END C=0.1, kernel=sigmoid; neg_mean_squared_error: (test=-14.489) r2: (test=0.545) total time=   0.0s\n",
      "[CV 1/5] END C=0.1, kernel=poly; neg_mean_squared_error: (test=-38.198) r2: (test=0.279) total time=   0.0s\n",
      "[CV 2/5] END C=0.1, kernel=poly; neg_mean_squared_error: (test=-48.096) r2: (test=0.400) total time=   0.0s\n",
      "[CV 3/5] END C=0.1, kernel=poly; neg_mean_squared_error: (test=-62.538) r2: (test=0.076) total time=   0.0s\n",
      "[CV 4/5] END C=0.1, kernel=poly; neg_mean_squared_error: (test=-35.361) r2: (test=0.291) total time=   0.0s\n",
      "[CV 5/5] END C=0.1, kernel=poly; neg_mean_squared_error: (test=-24.925) r2: (test=0.217) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, kernel=linear; neg_mean_squared_error: (test=-4.116) r2: (test=0.922) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, kernel=linear; neg_mean_squared_error: (test=-9.524) r2: (test=0.881) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, kernel=linear; neg_mean_squared_error: (test=-11.013) r2: (test=0.837) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, kernel=linear; neg_mean_squared_error: (test=-3.900) r2: (test=0.922) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, kernel=linear; neg_mean_squared_error: (test=-4.330) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, kernel=rbf; neg_mean_squared_error: (test=-10.484) r2: (test=0.802) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, kernel=rbf; neg_mean_squared_error: (test=-17.550) r2: (test=0.781) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, kernel=rbf; neg_mean_squared_error: (test=-14.364) r2: (test=0.788) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, kernel=rbf; neg_mean_squared_error: (test=-7.396) r2: (test=0.852) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, kernel=rbf; neg_mean_squared_error: (test=-3.698) r2: (test=0.884) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, kernel=sigmoid; neg_mean_squared_error: (test=-16.899) r2: (test=0.681) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, kernel=sigmoid; neg_mean_squared_error: (test=-23.577) r2: (test=0.706) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, kernel=sigmoid; neg_mean_squared_error: (test=-21.222) r2: (test=0.686) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, kernel=sigmoid; neg_mean_squared_error: (test=-18.493) r2: (test=0.629) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, kernel=sigmoid; neg_mean_squared_error: (test=-11.886) r2: (test=0.626) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, kernel=poly; neg_mean_squared_error: (test=-25.983) r2: (test=0.510) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, kernel=poly; neg_mean_squared_error: (test=-36.521) r2: (test=0.545) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, kernel=poly; neg_mean_squared_error: (test=-45.248) r2: (test=0.332) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, kernel=poly; neg_mean_squared_error: (test=-48.955) r2: (test=0.019) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, kernel=poly; neg_mean_squared_error: (test=-17.942) r2: (test=0.436) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, kernel=linear; neg_mean_squared_error: (test=-4.116) r2: (test=0.922) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, kernel=linear; neg_mean_squared_error: (test=-9.524) r2: (test=0.881) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, kernel=linear; neg_mean_squared_error: (test=-11.013) r2: (test=0.837) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, kernel=linear; neg_mean_squared_error: (test=-3.900) r2: (test=0.922) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, kernel=linear; neg_mean_squared_error: (test=-4.330) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, kernel=rbf; neg_mean_squared_error: (test=-10.484) r2: (test=0.802) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, kernel=rbf; neg_mean_squared_error: (test=-17.550) r2: (test=0.781) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, kernel=rbf; neg_mean_squared_error: (test=-14.364) r2: (test=0.788) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, kernel=rbf; neg_mean_squared_error: (test=-7.396) r2: (test=0.852) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, kernel=rbf; neg_mean_squared_error: (test=-3.698) r2: (test=0.884) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, kernel=sigmoid; neg_mean_squared_error: (test=-16.899) r2: (test=0.681) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, kernel=sigmoid; neg_mean_squared_error: (test=-23.577) r2: (test=0.706) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, kernel=sigmoid; neg_mean_squared_error: (test=-21.222) r2: (test=0.686) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, kernel=sigmoid; neg_mean_squared_error: (test=-18.493) r2: (test=0.629) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, kernel=sigmoid; neg_mean_squared_error: (test=-11.886) r2: (test=0.626) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, kernel=poly; neg_mean_squared_error: (test=-25.983) r2: (test=0.510) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, kernel=poly; neg_mean_squared_error: (test=-36.521) r2: (test=0.545) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, kernel=poly; neg_mean_squared_error: (test=-45.248) r2: (test=0.332) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, kernel=poly; neg_mean_squared_error: (test=-48.955) r2: (test=0.019) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, kernel=poly; neg_mean_squared_error: (test=-17.942) r2: (test=0.436) total time=   0.0s\n",
      "[CV 1/5] END C=5, kernel=linear; neg_mean_squared_error: (test=-3.521) r2: (test=0.934) total time=   0.0s\n",
      "[CV 2/5] END C=5, kernel=linear; neg_mean_squared_error: (test=-9.355) r2: (test=0.883) total time=   0.0s\n",
      "[CV 3/5] END C=5, kernel=linear; neg_mean_squared_error: (test=-10.271) r2: (test=0.848) total time=   0.0s\n",
      "[CV 4/5] END C=5, kernel=linear; neg_mean_squared_error: (test=-3.682) r2: (test=0.926) total time=   0.0s\n",
      "[CV 5/5] END C=5, kernel=linear; neg_mean_squared_error: (test=-4.335) r2: (test=0.864) total time=   0.0s\n",
      "[CV 1/5] END C=5, kernel=rbf; neg_mean_squared_error: (test=-3.197) r2: (test=0.940) total time=   0.0s\n",
      "[CV 2/5] END C=5, kernel=rbf; neg_mean_squared_error: (test=-5.672) r2: (test=0.929) total time=   0.0s\n",
      "[CV 3/5] END C=5, kernel=rbf; neg_mean_squared_error: (test=-6.105) r2: (test=0.910) total time=   0.0s\n",
      "[CV 4/5] END C=5, kernel=rbf; neg_mean_squared_error: (test=-2.483) r2: (test=0.950) total time=   0.0s\n",
      "[CV 5/5] END C=5, kernel=rbf; neg_mean_squared_error: (test=-2.597) r2: (test=0.918) total time=   0.0s\n",
      "[CV 1/5] END C=5, kernel=sigmoid; neg_mean_squared_error: (test=-258.139) r2: (test=-3.870) total time=   0.0s\n",
      "[CV 2/5] END C=5, kernel=sigmoid; neg_mean_squared_error: (test=-350.568) r2: (test=-3.372) total time=   0.0s\n",
      "[CV 3/5] END C=5, kernel=sigmoid; neg_mean_squared_error: (test=-214.358) r2: (test=-2.167) total time=   0.0s\n",
      "[CV 4/5] END C=5, kernel=sigmoid; neg_mean_squared_error: (test=-489.556) r2: (test=-8.814) total time=   0.0s\n",
      "[CV 5/5] END C=5, kernel=sigmoid; neg_mean_squared_error: (test=-156.898) r2: (test=-3.930) total time=   0.0s\n",
      "[CV 1/5] END C=5, kernel=poly; neg_mean_squared_error: (test=-18.021) r2: (test=0.660) total time=   0.0s\n",
      "[CV 2/5] END C=5, kernel=poly; neg_mean_squared_error: (test=-27.792) r2: (test=0.653) total time=   0.0s\n",
      "[CV 3/5] END C=5, kernel=poly; neg_mean_squared_error: (test=-48.256) r2: (test=0.287) total time=   0.0s\n",
      "[CV 4/5] END C=5, kernel=poly; neg_mean_squared_error: (test=-54.316) r2: (test=-0.089) total time=   0.0s\n",
      "[CV 5/5] END C=5, kernel=poly; neg_mean_squared_error: (test=-15.811) r2: (test=0.503) total time=   0.0s\n",
      "[CV 1/5] END C=10, kernel=linear; neg_mean_squared_error: (test=-3.505) r2: (test=0.934) total time=   0.0s\n",
      "[CV 2/5] END C=10, kernel=linear; neg_mean_squared_error: (test=-9.352) r2: (test=0.883) total time=   0.0s\n",
      "[CV 3/5] END C=10, kernel=linear; neg_mean_squared_error: (test=-10.229) r2: (test=0.849) total time=   0.0s\n",
      "[CV 4/5] END C=10, kernel=linear; neg_mean_squared_error: (test=-3.775) r2: (test=0.924) total time=   0.0s\n",
      "[CV 5/5] END C=10, kernel=linear; neg_mean_squared_error: (test=-4.266) r2: (test=0.866) total time=   0.0s\n",
      "[CV 1/5] END C=10, kernel=rbf; neg_mean_squared_error: (test=-2.714) r2: (test=0.949) total time=   0.0s\n",
      "[CV 2/5] END C=10, kernel=rbf; neg_mean_squared_error: (test=-3.488) r2: (test=0.957) total time=   0.0s\n",
      "[CV 3/5] END C=10, kernel=rbf; neg_mean_squared_error: (test=-4.258) r2: (test=0.937) total time=   0.0s\n",
      "[CV 4/5] END C=10, kernel=rbf; neg_mean_squared_error: (test=-2.014) r2: (test=0.960) total time=   0.0s\n",
      "[CV 5/5] END C=10, kernel=rbf; neg_mean_squared_error: (test=-2.197) r2: (test=0.931) total time=   0.0s\n",
      "[CV 1/5] END C=10, kernel=sigmoid; neg_mean_squared_error: (test=-800.967) r2: (test=-14.110) total time=   0.0s\n",
      "[CV 2/5] END C=10, kernel=sigmoid; neg_mean_squared_error: (test=-1795.384) r2: (test=-21.390) total time=   0.0s\n",
      "[CV 3/5] END C=10, kernel=sigmoid; neg_mean_squared_error: (test=-743.022) r2: (test=-9.976) total time=   0.0s\n",
      "[CV 4/5] END C=10, kernel=sigmoid; neg_mean_squared_error: (test=-2078.927) r2: (test=-40.674) total time=   0.0s\n",
      "[CV 5/5] END C=10, kernel=sigmoid; neg_mean_squared_error: (test=-566.142) r2: (test=-16.790) total time=   0.0s\n",
      "[CV 1/5] END C=10, kernel=poly; neg_mean_squared_error: (test=-15.279) r2: (test=0.712) total time=   0.0s\n",
      "[CV 2/5] END C=10, kernel=poly; neg_mean_squared_error: (test=-27.791) r2: (test=0.653) total time=   0.0s\n",
      "[CV 3/5] END C=10, kernel=poly; neg_mean_squared_error: (test=-78.315) r2: (test=-0.157) total time=   0.0s\n",
      "[CV 4/5] END C=10, kernel=poly; neg_mean_squared_error: (test=-47.377) r2: (test=0.050) total time=   0.0s\n",
      "[CV 5/5] END C=10, kernel=poly; neg_mean_squared_error: (test=-14.210) r2: (test=0.553) total time=   0.0s\n",
      "\n",
      "For  DecisionTreeReg\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END criterion=squared_error, max_depth=2, random_state=100; neg_mean_squared_error: (test=-9.277) r2: (test=0.825) total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=2, random_state=100; neg_mean_squared_error: (test=-9.252) r2: (test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=2, random_state=100; neg_mean_squared_error: (test=-9.148) r2: (test=0.865) total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=2, random_state=100; neg_mean_squared_error: (test=-5.931) r2: (test=0.881) total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=2, random_state=100; neg_mean_squared_error: (test=-8.029) r2: (test=0.748) total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, random_state=100; neg_mean_squared_error: (test=-5.568) r2: (test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, random_state=100; neg_mean_squared_error: (test=-5.148) r2: (test=0.936) total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, random_state=100; neg_mean_squared_error: (test=-4.671) r2: (test=0.931) total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, random_state=100; neg_mean_squared_error: (test=-4.343) r2: (test=0.913) total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, random_state=100; neg_mean_squared_error: (test=-4.842) r2: (test=0.848) total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, random_state=100; neg_mean_squared_error: (test=-4.057) r2: (test=0.923) total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, random_state=100; neg_mean_squared_error: (test=-4.736) r2: (test=0.941) total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, random_state=100; neg_mean_squared_error: (test=-3.923) r2: (test=0.942) total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, random_state=100; neg_mean_squared_error: (test=-2.846) r2: (test=0.943) total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, random_state=100; neg_mean_squared_error: (test=-4.740) r2: (test=0.851) total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=6, random_state=100; neg_mean_squared_error: (test=-3.047) r2: (test=0.943) total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=6, random_state=100; neg_mean_squared_error: (test=-4.807) r2: (test=0.940) total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=6, random_state=100; neg_mean_squared_error: (test=-4.315) r2: (test=0.936) total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=6, random_state=100; neg_mean_squared_error: (test=-3.173) r2: (test=0.936) total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=6, random_state=100; neg_mean_squared_error: (test=-2.939) r2: (test=0.908) total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, random_state=100; neg_mean_squared_error: (test=-2.044) r2: (test=0.961) total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, random_state=100; neg_mean_squared_error: (test=-4.146) r2: (test=0.948) total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, random_state=100; neg_mean_squared_error: (test=-4.498) r2: (test=0.934) total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, random_state=100; neg_mean_squared_error: (test=-2.939) r2: (test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, random_state=100; neg_mean_squared_error: (test=-2.897) r2: (test=0.909) total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, random_state=100; neg_mean_squared_error: (test=-4.393) r2: (test=0.917) total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, random_state=100; neg_mean_squared_error: (test=-4.516) r2: (test=0.944) total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, random_state=100; neg_mean_squared_error: (test=-4.676) r2: (test=0.931) total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, random_state=100; neg_mean_squared_error: (test=-1.940) r2: (test=0.961) total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, random_state=100; neg_mean_squared_error: (test=-4.898) r2: (test=0.846) total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=15, random_state=100; neg_mean_squared_error: (test=-2.281) r2: (test=0.957) total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=15, random_state=100; neg_mean_squared_error: (test=-4.516) r2: (test=0.944) total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=15, random_state=100; neg_mean_squared_error: (test=-4.301) r2: (test=0.936) total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=15, random_state=100; neg_mean_squared_error: (test=-3.556) r2: (test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=15, random_state=100; neg_mean_squared_error: (test=-4.898) r2: (test=0.846) total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=20, random_state=100; neg_mean_squared_error: (test=-2.281) r2: (test=0.957) total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=20, random_state=100; neg_mean_squared_error: (test=-4.516) r2: (test=0.944) total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=20, random_state=100; neg_mean_squared_error: (test=-4.301) r2: (test=0.936) total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=20, random_state=100; neg_mean_squared_error: (test=-3.556) r2: (test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=20, random_state=100; neg_mean_squared_error: (test=-4.898) r2: (test=0.846) total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=None, random_state=100; neg_mean_squared_error: (test=-2.281) r2: (test=0.957) total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=None, random_state=100; neg_mean_squared_error: (test=-4.516) r2: (test=0.944) total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=None, random_state=100; neg_mean_squared_error: (test=-4.301) r2: (test=0.936) total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=None, random_state=100; neg_mean_squared_error: (test=-3.556) r2: (test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=None, random_state=100; neg_mean_squared_error: (test=-4.898) r2: (test=0.846) total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=2, random_state=100; neg_mean_squared_error: (test=-9.277) r2: (test=0.825) total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=2, random_state=100; neg_mean_squared_error: (test=-9.252) r2: (test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=2, random_state=100; neg_mean_squared_error: (test=-9.148) r2: (test=0.865) total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=2, random_state=100; neg_mean_squared_error: (test=-5.931) r2: (test=0.881) total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=2, random_state=100; neg_mean_squared_error: (test=-8.029) r2: (test=0.748) total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=4, random_state=100; neg_mean_squared_error: (test=-5.568) r2: (test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=4, random_state=100; neg_mean_squared_error: (test=-5.148) r2: (test=0.936) total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=4, random_state=100; neg_mean_squared_error: (test=-4.671) r2: (test=0.931) total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=4, random_state=100; neg_mean_squared_error: (test=-4.343) r2: (test=0.913) total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=4, random_state=100; neg_mean_squared_error: (test=-4.842) r2: (test=0.848) total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=5, random_state=100; neg_mean_squared_error: (test=-5.954) r2: (test=0.888) total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=5, random_state=100; neg_mean_squared_error: (test=-4.736) r2: (test=0.941) total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=5, random_state=100; neg_mean_squared_error: (test=-3.941) r2: (test=0.942) total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=5, random_state=100; neg_mean_squared_error: (test=-2.846) r2: (test=0.943) total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=5, random_state=100; neg_mean_squared_error: (test=-4.740) r2: (test=0.851) total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=6, random_state=100; neg_mean_squared_error: (test=-5.135) r2: (test=0.903) total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=6, random_state=100; neg_mean_squared_error: (test=-4.858) r2: (test=0.939) total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=6, random_state=100; neg_mean_squared_error: (test=-4.334) r2: (test=0.936) total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=6, random_state=100; neg_mean_squared_error: (test=-3.339) r2: (test=0.933) total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=6, random_state=100; neg_mean_squared_error: (test=-2.939) r2: (test=0.908) total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=8, random_state=100; neg_mean_squared_error: (test=-4.259) r2: (test=0.920) total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=8, random_state=100; neg_mean_squared_error: (test=-4.236) r2: (test=0.947) total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=8, random_state=100; neg_mean_squared_error: (test=-4.662) r2: (test=0.931) total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=8, random_state=100; neg_mean_squared_error: (test=-2.908) r2: (test=0.942) total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=8, random_state=100; neg_mean_squared_error: (test=-3.281) r2: (test=0.897) total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=10, random_state=100; neg_mean_squared_error: (test=-2.524) r2: (test=0.952) total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=10, random_state=100; neg_mean_squared_error: (test=-4.599) r2: (test=0.943) total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=10, random_state=100; neg_mean_squared_error: (test=-4.693) r2: (test=0.931) total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=10, random_state=100; neg_mean_squared_error: (test=-1.915) r2: (test=0.962) total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=10, random_state=100; neg_mean_squared_error: (test=-4.700) r2: (test=0.852) total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=15, random_state=100; neg_mean_squared_error: (test=-3.727) r2: (test=0.930) total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=15, random_state=100; neg_mean_squared_error: (test=-4.599) r2: (test=0.943) total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=15, random_state=100; neg_mean_squared_error: (test=-4.319) r2: (test=0.936) total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=15, random_state=100; neg_mean_squared_error: (test=-3.528) r2: (test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=15, random_state=100; neg_mean_squared_error: (test=-4.700) r2: (test=0.852) total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=20, random_state=100; neg_mean_squared_error: (test=-3.727) r2: (test=0.930) total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=20, random_state=100; neg_mean_squared_error: (test=-4.599) r2: (test=0.943) total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=20, random_state=100; neg_mean_squared_error: (test=-4.319) r2: (test=0.936) total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=20, random_state=100; neg_mean_squared_error: (test=-3.528) r2: (test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=20, random_state=100; neg_mean_squared_error: (test=-4.700) r2: (test=0.852) total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=None, random_state=100; neg_mean_squared_error: (test=-3.727) r2: (test=0.930) total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=None, random_state=100; neg_mean_squared_error: (test=-4.599) r2: (test=0.943) total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=None, random_state=100; neg_mean_squared_error: (test=-4.319) r2: (test=0.936) total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=None, random_state=100; neg_mean_squared_error: (test=-3.528) r2: (test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=None, random_state=100; neg_mean_squared_error: (test=-4.700) r2: (test=0.852) total time=   0.0s\n",
      "\n",
      "For  RandomForestReg\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5] END criterion=squared_error, max_depth=2, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-5.620) r2: (test=0.894) total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=2, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-7.920) r2: (test=0.901) total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=2, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-5.730) r2: (test=0.915) total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=2, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-5.009) r2: (test=0.900) total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=2, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-6.718) r2: (test=0.789) total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=2, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-5.448) r2: (test=0.897) total time=   0.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=2, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-8.081) r2: (test=0.899) total time=   0.6s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=2, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-5.798) r2: (test=0.914) total time=   0.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=2, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-5.129) r2: (test=0.897) total time=   0.7s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=2, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-6.560) r2: (test=0.794) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=2, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-5.310) r2: (test=0.900) total time=   0.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=2, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-8.060) r2: (test=0.899) total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=2, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-5.520) r2: (test=0.918) total time=   1.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=2, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-5.019) r2: (test=0.899) total time=   0.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=2, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-6.562) r2: (test=0.794) total time=   0.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.263) r2: (test=0.957) total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.457) r2: (test=0.969) total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.680) r2: (test=0.975) total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.194) r2: (test=0.956) total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-3.257) r2: (test=0.898) total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.119) r2: (test=0.960) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.505) r2: (test=0.969) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.655) r2: (test=0.976) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.047) r2: (test=0.959) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.960) r2: (test=0.907) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.983) r2: (test=0.963) total time=   0.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.466) r2: (test=0.969) total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.624) r2: (test=0.976) total time=   0.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.035) r2: (test=0.959) total time=   0.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.972) r2: (test=0.907) total time=   1.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.807) r2: (test=0.966) total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.223) r2: (test=0.972) total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.499) r2: (test=0.978) total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.994) r2: (test=0.960) total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.701) r2: (test=0.915) total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.582) r2: (test=0.970) total time=   0.6s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.217) r2: (test=0.972) total time=   0.6s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.496) r2: (test=0.978) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.810) r2: (test=0.964) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.463) r2: (test=0.923) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.500) r2: (test=0.972) total time=   0.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.169) r2: (test=0.973) total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.485) r2: (test=0.978) total time=   1.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.759) r2: (test=0.965) total time=   0.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.491) r2: (test=0.922) total time=   0.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=6, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.490) r2: (test=0.972) total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=6, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.077) r2: (test=0.974) total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=6, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.497) r2: (test=0.978) total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=6, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.101) r2: (test=0.958) total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=6, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.505) r2: (test=0.921) total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=6, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.399) r2: (test=0.974) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=6, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.041) r2: (test=0.975) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=6, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.430) r2: (test=0.979) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=6, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.807) r2: (test=0.964) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=6, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.299) r2: (test=0.928) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=6, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.398) r2: (test=0.974) total time=   0.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=6, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.006) r2: (test=0.975) total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=6, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.431) r2: (test=0.979) total time=   1.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=6, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.772) r2: (test=0.964) total time=   1.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=6, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.336) r2: (test=0.927) total time=   1.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.647) r2: (test=0.969) total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.017) r2: (test=0.975) total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.458) r2: (test=0.978) total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.193) r2: (test=0.956) total time=   0.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.491) r2: (test=0.922) total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.463) r2: (test=0.972) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.041) r2: (test=0.975) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.434) r2: (test=0.979) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.860) r2: (test=0.963) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.335) r2: (test=0.927) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.333) r2: (test=0.975) total time=   0.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.033) r2: (test=0.975) total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.446) r2: (test=0.979) total time=   0.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.790) r2: (test=0.964) total time=   0.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.351) r2: (test=0.926) total time=   0.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.518) r2: (test=0.971) total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.059) r2: (test=0.974) total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.463) r2: (test=0.978) total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.028) r2: (test=0.959) total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.576) r2: (test=0.919) total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.414) r2: (test=0.973) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.065) r2: (test=0.974) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.455) r2: (test=0.979) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.869) r2: (test=0.963) total time=   0.6s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.309) r2: (test=0.927) total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.338) r2: (test=0.975) total time=   1.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.042) r2: (test=0.975) total time=   0.9s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.449) r2: (test=0.979) total time=   1.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.810) r2: (test=0.964) total time=   0.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.317) r2: (test=0.927) total time=   0.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=15, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.512) r2: (test=0.971) total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=15, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.054) r2: (test=0.974) total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=15, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.461) r2: (test=0.978) total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=15, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.001) r2: (test=0.960) total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=15, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.554) r2: (test=0.920) total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=15, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.432) r2: (test=0.973) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=15, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.082) r2: (test=0.974) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=15, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.444) r2: (test=0.979) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=15, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.857) r2: (test=0.963) total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=15, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.317) r2: (test=0.927) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=15, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.342) r2: (test=0.975) total time=   0.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=15, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.067) r2: (test=0.974) total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=15, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.432) r2: (test=0.979) total time=   1.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=15, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.826) r2: (test=0.963) total time=   0.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=15, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.323) r2: (test=0.927) total time=   0.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=20, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.512) r2: (test=0.971) total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=20, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.054) r2: (test=0.974) total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=20, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.461) r2: (test=0.978) total time=   0.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=20, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.001) r2: (test=0.960) total time=   0.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=20, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.554) r2: (test=0.920) total time=   0.3s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=20, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.432) r2: (test=0.973) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=20, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.082) r2: (test=0.974) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=20, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.444) r2: (test=0.979) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=20, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.857) r2: (test=0.963) total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=20, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.317) r2: (test=0.927) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=20, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.342) r2: (test=0.975) total time=   0.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=20, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.067) r2: (test=0.974) total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=20, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.432) r2: (test=0.979) total time=   0.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=20, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.826) r2: (test=0.963) total time=   0.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=20, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.323) r2: (test=0.927) total time=   0.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=None, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.512) r2: (test=0.971) total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=None, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.054) r2: (test=0.974) total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=None, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.461) r2: (test=0.978) total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=None, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.001) r2: (test=0.960) total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=None, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.554) r2: (test=0.920) total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=None, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.432) r2: (test=0.973) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=None, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.082) r2: (test=0.974) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=None, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.444) r2: (test=0.979) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=None, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.857) r2: (test=0.963) total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=None, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.317) r2: (test=0.927) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=None, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.342) r2: (test=0.975) total time=   0.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=None, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.067) r2: (test=0.974) total time=   0.9s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=None, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.432) r2: (test=0.979) total time=   0.9s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=None, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.826) r2: (test=0.963) total time=   1.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=None, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.323) r2: (test=0.927) total time=   0.8s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=2, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-5.620) r2: (test=0.894) total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=2, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-7.920) r2: (test=0.901) total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=2, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-5.730) r2: (test=0.915) total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=2, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-5.009) r2: (test=0.900) total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=2, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-6.718) r2: (test=0.789) total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=2, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-5.448) r2: (test=0.897) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=2, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-8.081) r2: (test=0.899) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=2, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-5.798) r2: (test=0.914) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=2, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-5.129) r2: (test=0.897) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=2, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-6.560) r2: (test=0.794) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=2, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-5.310) r2: (test=0.900) total time=   0.8s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=2, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-8.080) r2: (test=0.899) total time=   0.7s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=2, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-5.520) r2: (test=0.918) total time=   0.7s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=2, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-5.019) r2: (test=0.899) total time=   0.7s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=2, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-6.562) r2: (test=0.794) total time=   0.7s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=4, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.312) r2: (test=0.956) total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=4, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.400) r2: (test=0.970) total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=4, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.642) r2: (test=0.976) total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=4, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.289) r2: (test=0.954) total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=4, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-3.264) r2: (test=0.897) total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=4, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.163) r2: (test=0.959) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=4, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.435) r2: (test=0.970) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=4, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.639) r2: (test=0.976) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=4, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.092) r2: (test=0.958) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=4, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.938) r2: (test=0.908) total time=   0.6s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=4, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.005) r2: (test=0.962) total time=   0.8s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=4, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.411) r2: (test=0.970) total time=   0.8s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=4, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.611) r2: (test=0.976) total time=   1.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=4, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.067) r2: (test=0.959) total time=   0.8s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=4, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.952) r2: (test=0.907) total time=   0.9s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=5, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.825) r2: (test=0.966) total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=5, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.215) r2: (test=0.972) total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=5, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.486) r2: (test=0.978) total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=5, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.997) r2: (test=0.960) total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=5, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.702) r2: (test=0.915) total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=5, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.611) r2: (test=0.970) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=5, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.186) r2: (test=0.973) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=5, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.507) r2: (test=0.978) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=5, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.801) r2: (test=0.964) total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=5, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.459) r2: (test=0.923) total time=   1.1s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=5, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.542) r2: (test=0.971) total time=   1.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=5, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.152) r2: (test=0.973) total time=   1.1s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=5, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.500) r2: (test=0.978) total time=   1.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=5, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.750) r2: (test=0.965) total time=   0.9s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=5, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.469) r2: (test=0.922) total time=   1.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=6, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.502) r2: (test=0.972) total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=6, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.027) r2: (test=0.975) total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=6, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.421) r2: (test=0.979) total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=6, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.889) r2: (test=0.962) total time=   0.2s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=6, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.531) r2: (test=0.920) total time=   0.2s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=6, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.433) r2: (test=0.973) total time=   0.6s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=6, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.029) r2: (test=0.975) total time=   0.9s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=6, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.388) r2: (test=0.979) total time=   1.2s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=6, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.756) r2: (test=0.965) total time=   0.9s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=6, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.318) r2: (test=0.927) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=6, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.416) r2: (test=0.973) total time=   0.7s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=6, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.981) r2: (test=0.975) total time=   0.7s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=6, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.412) r2: (test=0.979) total time=   0.8s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=6, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.758) r2: (test=0.965) total time=   1.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=6, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.340) r2: (test=0.926) total time=   0.8s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=8, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.495) r2: (test=0.972) total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=8, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.892) r2: (test=0.976) total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=8, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.412) r2: (test=0.979) total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=8, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.089) r2: (test=0.958) total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=8, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.516) r2: (test=0.921) total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=8, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.392) r2: (test=0.974) total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=8, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.993) r2: (test=0.975) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=8, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.379) r2: (test=0.980) total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=8, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.808) r2: (test=0.964) total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=8, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.306) r2: (test=0.928) total time=   0.5s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=8, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.319) r2: (test=0.975) total time=   0.9s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=8, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.988) r2: (test=0.975) total time=   1.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=8, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.405) r2: (test=0.979) total time=   0.9s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=8, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.772) r2: (test=0.964) total time=   0.9s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=8, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.338) r2: (test=0.927) total time=   0.9s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=10, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.586) r2: (test=0.970) total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=10, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.968) r2: (test=0.975) total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=10, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.426) r2: (test=0.979) total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=10, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.000) r2: (test=0.960) total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=10, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.547) r2: (test=0.920) total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=10, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.426) r2: (test=0.973) total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=10, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.982) r2: (test=0.975) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=10, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.424) r2: (test=0.979) total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=10, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.849) r2: (test=0.963) total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=10, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.272) r2: (test=0.929) total time=   0.5s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=10, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.377) r2: (test=0.974) total time=   0.9s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=10, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.983) r2: (test=0.975) total time=   1.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=10, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.444) r2: (test=0.979) total time=   0.9s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=10, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.765) r2: (test=0.965) total time=   0.9s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=10, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.295) r2: (test=0.928) total time=   0.9s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=15, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.579) r2: (test=0.970) total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=15, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.963) r2: (test=0.976) total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=15, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.410) r2: (test=0.979) total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=15, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.999) r2: (test=0.960) total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=15, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.523) r2: (test=0.921) total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=15, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.423) r2: (test=0.973) total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=15, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.996) r2: (test=0.975) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=15, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.421) r2: (test=0.979) total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=15, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.826) r2: (test=0.963) total time=   0.6s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=15, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.263) r2: (test=0.929) total time=   0.5s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=15, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.357) r2: (test=0.974) total time=   0.8s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=15, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.006) r2: (test=0.975) total time=   0.9s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=15, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.434) r2: (test=0.979) total time=   0.8s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=15, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.767) r2: (test=0.965) total time=   1.2s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=15, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.293) r2: (test=0.928) total time=   0.8s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=20, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.579) r2: (test=0.970) total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=20, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.963) r2: (test=0.976) total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=20, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.410) r2: (test=0.979) total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=20, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.999) r2: (test=0.960) total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=20, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.523) r2: (test=0.921) total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=20, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.423) r2: (test=0.973) total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=20, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.996) r2: (test=0.975) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=20, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.421) r2: (test=0.979) total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=20, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.826) r2: (test=0.963) total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=20, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.263) r2: (test=0.929) total time=   0.5s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=20, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.357) r2: (test=0.974) total time=   0.9s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=20, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.006) r2: (test=0.975) total time=   0.9s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=20, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.434) r2: (test=0.979) total time=   1.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=20, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.767) r2: (test=0.965) total time=   0.9s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=20, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.293) r2: (test=0.928) total time=   0.9s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=None, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.579) r2: (test=0.970) total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=None, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.963) r2: (test=0.976) total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=None, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.410) r2: (test=0.979) total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=None, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-1.999) r2: (test=0.960) total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=None, n_estimators=100, random_state=100; neg_mean_squared_error: (test=-2.523) r2: (test=0.921) total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=None, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.423) r2: (test=0.973) total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=None, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.996) r2: (test=0.975) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=None, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.421) r2: (test=0.979) total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=None, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-1.826) r2: (test=0.963) total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=None, n_estimators=300, random_state=100; neg_mean_squared_error: (test=-2.263) r2: (test=0.929) total time=   0.5s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=None, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.357) r2: (test=0.974) total time=   0.9s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=None, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.006) r2: (test=0.975) total time=   1.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=None, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.434) r2: (test=0.979) total time=   2.1s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=None, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-1.767) r2: (test=0.965) total time=   1.5s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=None, n_estimators=500, random_state=100; neg_mean_squared_error: (test=-2.293) r2: (test=0.928) total time=   1.4s\n"
     ]
    }
   ],
   "source": [
    "tuned_models = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    print(\"\\nFor \",name)\n",
    "    parameters = param_grid[name]\n",
    "    current_best_model = train_classifier(clf,parameters)\n",
    "    \n",
    "    ####### Saving Trainined MOdel #####################\n",
    "    \n",
    "    # create the directory if it does not exist\n",
    "    if not os.path.exists('../Regression/tuned_models_raw4_4'):\n",
    "        os.makedirs('../Regression/tuned_models_raw4_4')\n",
    "\n",
    "    filename = 'tuned_' + re.search(r'^[^\\(]+', str(current_best_model.best_estimator_))[0] + '_model.pkl'\n",
    "    filepath = os.path.join('../Regression/tuned_models_raw4_4', filename)\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(current_best_model, file)\n",
    "            \n",
    "    ##############################################################################\n",
    "    \n",
    "    tuned_models.append(current_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a48108-03a1-4733-bb70-4105417e2250",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Import and Features Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "619fc6ea-4b49-4dfd-8c28-e9c84c080c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = pickle.load(open('../Regression/tuned_models_raw4_4/tuned_SVR_model.pkl','rb'))\n",
    "linReg_model = pickle.load(open('../Regression/tuned_models_raw4_4/tuned_LinearRegression_model.pkl','rb'))\n",
    "lasso_model = pickle.load(open('../Regression/tuned_models_raw4_4/tuned_Lasso_model.pkl','rb'))\n",
    "elasticNet_model = pickle.load(open('../Regression/tuned_models_raw4_4/tuned_ElasticNet_model.pkl','rb'))\n",
    "ridge_model = pickle.load(open('../Regression/tuned_models_raw4_4/tuned_Ridge_model.pkl','rb'))\n",
    "rfReg_model = pickle.load(open('../Regression/tuned_models_raw4_4/tuned_RandomForestRegressor_model.pkl','rb'))\n",
    "dtcReg_model = pickle.load(open('../Regression/tuned_models_raw4_4/tuned_DecisionTreeRegressor_model.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b0644360-7530-4bd4-a43b-be814f0b1af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Temperature', 'RH', 'Ws', 'Rain', 'ISI/FFMC', 'ISI/DMC*BUI'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['Temperature', 'RH', 'Ws', 'Rain', 'FFMC', 'DMC', 'DC', 'ISI','BUI']  ####### tuned_models_raw4_3: Features Used\n",
    "\n",
    "# ['Temperature', 'RH', 'Ws', 'Rain', 'ISI/FFMC', 'ISI/DMC*BUI']        ######### Tuned_models_raw4_4\n",
    "\n",
    "# ['Temperature', 'RH', 'Ws', 'Rain', 'DC', 'ISI/FFMC', 'ISI/DMC*BUI']   ######### Tuned_models_raw4_5\n",
    "\n",
    "#['Temperature', 'RH', 'ISI/FFMC', 'ISI/DMC*BUI']       ######### Tuned_models_raw4_6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "svr_model.best_estimator_.feature_names_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de12253e-4649-4d48-a1be-d74b971e970e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Model Scores"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2aa35c48-46e1-4011-bd39-4210336991a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "######## FOR RAw\n",
    "######## FOR RAw\n",
    "######## FOR RAw\n",
    "######## FOR RAw\n",
    "\n",
    "model_scores = pd.DataFrame({\n",
    "    'model': ['SVR','LinearRgression','Lasso','Ridge','ElasticNet','RandomForestReg','DecisionTreeReg'],\n",
    "    'MSE_train': [mean_squared_error(y_train,svr_model.best_estimator_.predict(X_train)),\n",
    "                                \n",
    "                                mean_squared_error(y_train,linReg_model.best_estimator_.predict(X_train)),\n",
    "                                mean_squared_error(y_train,lasso_model.best_estimator_.predict(X_train)),\n",
    "                                mean_squared_error(y_train,ridge_model.best_estimator_.predict(X_train)),\n",
    "                                mean_squared_error(y_train,elasticNet_model.best_estimator_.predict(X_train)),\n",
    "                                mean_squared_error(y_train,rfReg_model.best_estimator_.predict(X_train)),\n",
    "                                \n",
    "                                mean_squared_error(y_train,dtcReg_model.best_estimator_.predict(X_train)),\n",
    "                                \n",
    "                               ]})\n",
    "\n",
    "\n",
    "MSE_test =  [mean_squared_error(y_test,svr_model.best_estimator_.predict(X_test)),\n",
    "                           \n",
    "                           mean_squared_error(y_test,linReg_model.best_estimator_.predict(X_test)),\n",
    "                           mean_squared_error(y_test,lasso_model.best_estimator_.predict(X_test)),\n",
    "                           mean_squared_error(y_test,ridge_model.best_estimator_.predict(X_test)),\n",
    "                           mean_squared_error(y_test,elasticNet_model.best_estimator_.predict(X_test)),                   \n",
    "                           mean_squared_error(y_test,rfReg_model.best_estimator_.predict(X_test)),\n",
    "                           mean_squared_error(y_test,dtcReg_model.best_estimator_.predict(X_test)),\n",
    "                           \n",
    "                          ] \n",
    "\n",
    "R2_score_train = [r2_score(y_train,svr_model.best_estimator_.predict(X_train)),\n",
    "                  \n",
    "                  \n",
    "                  r2_score(y_train,linReg_model.best_estimator_.predict(X_train)),\n",
    "                  r2_score(y_train,lasso_model.best_estimator_.predict(X_train)),\n",
    "                  r2_score(y_train,ridge_model.best_estimator_.predict(X_train)),\n",
    "                  r2_score(y_train,elasticNet_model.best_estimator_.predict(X_train)),\n",
    "                  r2_score(y_train,rfReg_model.best_estimator_.predict(X_train)),\n",
    "                  r2_score(y_train,dtcReg_model.best_estimator_.predict(X_train)),\n",
    "                  \n",
    "                 ]\n",
    "\n",
    "\n",
    "R2_score_test = [r2_score(y_test,svr_model.best_estimator_.predict(X_test)),\n",
    "                 \n",
    "                 \n",
    "                 r2_score(y_test,linReg_model.best_estimator_.predict(X_test)),\n",
    "                 r2_score(y_test,lasso_model.best_estimator_.predict(X_test)),\n",
    "                 r2_score(y_test,ridge_model.best_estimator_.predict(X_test)),\n",
    "                 r2_score(y_test,elasticNet_model.best_estimator_.predict(X_test)),\n",
    "                 r2_score(y_test,rfReg_model.best_estimator_.predict(X_test)),\n",
    "                 r2_score(y_test,dtcReg_model.best_estimator_.predict(X_test)),\n",
    "                 \n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_score= [svr_model.best_score_, linReg_model.best_score_,\n",
    "          lasso_model.best_score_, ridge_model.best_score_, elasticNet_model.best_score_,rfReg_model.best_score_, dtcReg_model.best_score_]\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "model_scores['MSE_test'],model_scores['R2_train'],model_scores['R2_test'] = [MSE_test,R2_score_train,R2_score_test]\n",
    "\n",
    "model_scores.insert(1,'best_score',best_score)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "model_scores.to_csv('../Regression/tuned_models_raw4_3//model_scores.csv',index=False)\n",
    "\n",
    "########################\n",
    "\n",
    "model_scores.style.highlight_min(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d94208f0-7f67-4873-98e8-aa0dc4cb9a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eedcc_row1_col1, #T_eedcc_row1_col5, #T_eedcc_row2_col4, #T_eedcc_row4_col4, #T_eedcc_row5_col3, #T_eedcc_row6_col0, #T_eedcc_row6_col2 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eedcc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_eedcc_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n",
       "      <th id=\"T_eedcc_level0_col1\" class=\"col_heading level0 col1\" >best_score</th>\n",
       "      <th id=\"T_eedcc_level0_col2\" class=\"col_heading level0 col2\" >MSE_train</th>\n",
       "      <th id=\"T_eedcc_level0_col3\" class=\"col_heading level0 col3\" >MSE_test</th>\n",
       "      <th id=\"T_eedcc_level0_col4\" class=\"col_heading level0 col4\" >R2_train</th>\n",
       "      <th id=\"T_eedcc_level0_col5\" class=\"col_heading level0 col5\" >R2_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_eedcc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_eedcc_row0_col0\" class=\"data row0 col0\" >SVR</td>\n",
       "      <td id=\"T_eedcc_row0_col1\" class=\"data row0 col1\" >0.911462</td>\n",
       "      <td id=\"T_eedcc_row0_col2\" class=\"data row0 col2\" >1.647436</td>\n",
       "      <td id=\"T_eedcc_row0_col3\" class=\"data row0 col3\" >3.540023</td>\n",
       "      <td id=\"T_eedcc_row0_col4\" class=\"data row0 col4\" >0.972017</td>\n",
       "      <td id=\"T_eedcc_row0_col5\" class=\"data row0 col5\" >0.923751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eedcc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_eedcc_row1_col0\" class=\"data row1 col0\" >LinearRgression</td>\n",
       "      <td id=\"T_eedcc_row1_col1\" class=\"data row1 col1\" >0.892718</td>\n",
       "      <td id=\"T_eedcc_row1_col2\" class=\"data row1 col2\" >5.412207</td>\n",
       "      <td id=\"T_eedcc_row1_col3\" class=\"data row1 col3\" >11.086146</td>\n",
       "      <td id=\"T_eedcc_row1_col4\" class=\"data row1 col4\" >0.908069</td>\n",
       "      <td id=\"T_eedcc_row1_col5\" class=\"data row1 col5\" >0.761215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eedcc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_eedcc_row2_col0\" class=\"data row2 col0\" >Lasso</td>\n",
       "      <td id=\"T_eedcc_row2_col1\" class=\"data row2 col1\" >0.893146</td>\n",
       "      <td id=\"T_eedcc_row2_col2\" class=\"data row2 col2\" >5.508425</td>\n",
       "      <td id=\"T_eedcc_row2_col3\" class=\"data row2 col3\" >10.265810</td>\n",
       "      <td id=\"T_eedcc_row2_col4\" class=\"data row2 col4\" >0.906435</td>\n",
       "      <td id=\"T_eedcc_row2_col5\" class=\"data row2 col5\" >0.778884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eedcc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_eedcc_row3_col0\" class=\"data row3 col0\" >Ridge</td>\n",
       "      <td id=\"T_eedcc_row3_col1\" class=\"data row3 col1\" >0.892973</td>\n",
       "      <td id=\"T_eedcc_row3_col2\" class=\"data row3 col2\" >5.418000</td>\n",
       "      <td id=\"T_eedcc_row3_col3\" class=\"data row3 col3\" >10.831228</td>\n",
       "      <td id=\"T_eedcc_row3_col4\" class=\"data row3 col4\" >0.907971</td>\n",
       "      <td id=\"T_eedcc_row3_col5\" class=\"data row3 col5\" >0.766705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eedcc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_eedcc_row4_col0\" class=\"data row4 col0\" >ElasticNet</td>\n",
       "      <td id=\"T_eedcc_row4_col1\" class=\"data row4 col1\" >0.893146</td>\n",
       "      <td id=\"T_eedcc_row4_col2\" class=\"data row4 col2\" >5.508425</td>\n",
       "      <td id=\"T_eedcc_row4_col3\" class=\"data row4 col3\" >10.265810</td>\n",
       "      <td id=\"T_eedcc_row4_col4\" class=\"data row4 col4\" >0.906435</td>\n",
       "      <td id=\"T_eedcc_row4_col5\" class=\"data row4 col5\" >0.778884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eedcc_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_eedcc_row5_col0\" class=\"data row5 col0\" >RandomForestReg</td>\n",
       "      <td id=\"T_eedcc_row5_col1\" class=\"data row5 col1\" >0.961500</td>\n",
       "      <td id=\"T_eedcc_row5_col2\" class=\"data row5 col2\" >0.228657</td>\n",
       "      <td id=\"T_eedcc_row5_col3\" class=\"data row5 col3\" >2.405339</td>\n",
       "      <td id=\"T_eedcc_row5_col4\" class=\"data row5 col4\" >0.996116</td>\n",
       "      <td id=\"T_eedcc_row5_col5\" class=\"data row5 col5\" >0.948191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eedcc_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_eedcc_row6_col0\" class=\"data row6 col0\" >DecisionTreeReg</td>\n",
       "      <td id=\"T_eedcc_row6_col1\" class=\"data row6 col1\" >0.927711</td>\n",
       "      <td id=\"T_eedcc_row6_col2\" class=\"data row6 col2\" >0.000044</td>\n",
       "      <td id=\"T_eedcc_row6_col3\" class=\"data row6 col3\" >2.499949</td>\n",
       "      <td id=\"T_eedcc_row6_col4\" class=\"data row6 col4\" >0.999999</td>\n",
       "      <td id=\"T_eedcc_row6_col5\" class=\"data row6 col5\" >0.946153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1708e70e650>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## FOR Scaled Engineered Data\n",
    "######## FOR Scaled Engineered Data\n",
    "######## FOR Scaled Engineered Data\n",
    "######## FOR Scaled Engineered Data\n",
    "######## FOR Scaled Engineered Data\n",
    "\n",
    "\n",
    "\n",
    "model_scores = pd.DataFrame({\n",
    "    'model': ['SVR','LinearRgression','Lasso','Ridge','ElasticNet','RandomForestReg','DecisionTreeReg'],\n",
    "    'MSE_train': [mean_squared_error(y_train,svr_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                                \n",
    "                                mean_squared_error(y_train,linReg_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                                mean_squared_error(y_train,lasso_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                                mean_squared_error(y_train,ridge_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                                mean_squared_error(y_train,elasticNet_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                                mean_squared_error(y_train,rfReg_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                                \n",
    "                                mean_squared_error(y_train,dtcReg_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                                \n",
    "                               ]})\n",
    "\n",
    "\n",
    "MSE_test =  [mean_squared_error(y_test,svr_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                           \n",
    "                           mean_squared_error(y_test,linReg_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                           mean_squared_error(y_test,lasso_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                           mean_squared_error(y_test,ridge_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                           mean_squared_error(y_test,elasticNet_model.best_estimator_.predict(X_test_scaled_df)),                   \n",
    "                           mean_squared_error(y_test,rfReg_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                           mean_squared_error(y_test,dtcReg_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                           \n",
    "                          ] \n",
    "\n",
    "R2_score_train = [r2_score(y_train,svr_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                  \n",
    "                  \n",
    "                  r2_score(y_train,linReg_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                  r2_score(y_train,lasso_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                  r2_score(y_train,ridge_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                  r2_score(y_train,elasticNet_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                  r2_score(y_train,rfReg_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                  r2_score(y_train,dtcReg_model.best_estimator_.predict(X_train_scaled_df)),\n",
    "                  \n",
    "                 ]\n",
    "\n",
    "\n",
    "R2_score_test = [r2_score(y_test,svr_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                 \n",
    "                 \n",
    "                 r2_score(y_test,linReg_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                 r2_score(y_test,lasso_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                 r2_score(y_test,ridge_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                 r2_score(y_test,elasticNet_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                 r2_score(y_test,rfReg_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                 r2_score(y_test,dtcReg_model.best_estimator_.predict(X_test_scaled_df)),\n",
    "                 \n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_score= [svr_model.best_score_, linReg_model.best_score_,\n",
    "          lasso_model.best_score_, ridge_model.best_score_, elasticNet_model.best_score_,rfReg_model.best_score_, dtcReg_model.best_score_]\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "model_scores['MSE_test'],model_scores['R2_train'],model_scores['R2_test'] = [MSE_test,R2_score_train,R2_score_test]\n",
    "\n",
    "model_scores.insert(1,'best_score',best_score)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "model_scores.to_csv('../Regression/tuned_models_raw4_4//model_scores.csv',index=False)\n",
    "\n",
    "########################\n",
    "\n",
    "model_scores.style.highlight_min(axis=0)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1bc0fd7-b5a2-4d5c-b2d0-ad5535332013",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "df  = pd.read_csv('../Regression/tuned_models_raw4_3//model_scores.csv')\n",
    "#df = df.drop('Unnamed: 0', axis =1)\n",
    "df = df.set_index('model')\n",
    "df1 = df[['MSE_train']]\n",
    "df2 = df[['MSE_test']]\n",
    "\n",
    "fig = px.bar(data_frame=df,y=['MSE_train','MSE_test'],barmode='group', title='Model MSE Score: Engineered Features')\n",
    "\n",
    "##########################\n",
    "\n",
    "# Update remaining layout properties\n",
    "fig.update_layout(\n",
    "    \n",
    "    \n",
    "    #title_y=0.96,\n",
    "\n",
    "    paper_bgcolor = \"rgba(0,0,0,0)\",\n",
    "    plot_bgcolor = \"rgba(0,0,0,0)\",\n",
    "    margin_autoexpand=True,\n",
    "    autosize=True,\n",
    "\n",
    ")\n",
    "\n",
    "fig.show(scale=500, config= dict(displayModeBar = False))\n",
    "\n",
    "############################################################\n",
    "\n",
    "# Writing and exporting interactive figure as html file \n",
    "\n",
    "#f1.write_html('../Regression/tuned_models_raw4_3/Model_Scores.html',config= dict(displayModeBar = False))\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb02d85f-7b27-4b77-b99e-5d265b2f121f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "df  = pd.read_csv('../Regression/tuned_models_raw4_3//model_scores.csv')\n",
    "#df = df.drop('Unnamed: 0', axis =1)\n",
    "df = df.set_index('model')\n",
    "\n",
    "fig = px.bar(data_frame=df,y=['R2_train','R2_test'],barmode='group', title='Model R2 Score: Engineered Features')\n",
    "\n",
    "##########################\n",
    "\n",
    "# Update remaining layout properties\n",
    "fig.update_layout(\n",
    "    \n",
    "    \n",
    "    #title_y=0.96,\n",
    "\n",
    "    paper_bgcolor = \"rgba(0,0,0,0)\",\n",
    "    plot_bgcolor = \"rgba(0,0,0,0)\",\n",
    "    margin_autoexpand=True,\n",
    "    autosize=True,\n",
    "\n",
    ")\n",
    "\n",
    "fig.show(scale=500, config= dict(displayModeBar = False))\n",
    "\n",
    "############################################################\n",
    "\n",
    "# Writing and exporting interactive figure as html file \n",
    "\n",
    "#f1.write_html('../Regression/tuned_models_raw4_3/Model_Scores.html',config= dict(displayModeBar = False))\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "377ef823-02d3-40c9-b6bd-bf77dc39bd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>model: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.5f}",
         "type": "heatmap",
         "x": [
          "best_score",
          "MSE_train",
          "MSE_test",
          "R2_train",
          "R2_test"
         ],
         "xaxis": "x",
         "y": [
          "SVR",
          "LinearRgression",
          "Lasso",
          "Ridge",
          "ElasticNet",
          "RandomForestReg",
          "DecisionTreeReg"
         ],
         "yaxis": "y",
         "z": [
          [
           0.911461879336937,
           1.647436412458598,
           3.54002271783259,
           0.9720168762802741,
           0.9237511758245543
          ],
          [
           0.892717883233531,
           5.412207274011198,
           11.086145748693532,
           0.9080690067306242,
           0.7612146459633333
          ],
          [
           0.893145985143321,
           5.508425038087426,
           10.2658101632541,
           0.9064346652921208,
           0.778883917830981
          ],
          [
           0.8929728787192909,
           5.418000202580407,
           10.831227747481996,
           0.9079706088588606,
           0.7667053445838877
          ],
          [
           0.893145985143321,
           5.508425038087426,
           10.2658101632541,
           0.9064346652921208,
           0.778883917830981
          ],
          [
           0.9614997366230907,
           0.22865677280640953,
           2.405338966148683,
           0.9961160681441744,
           0.9481912172517045
          ],
          [
           0.9277113732616256,
           4.4117647058823214e-05,
           2.4999486301369855,
           0.999999250623838,
           0.9461534123533341
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "#00224e"
          ],
          [
           0.1111111111111111,
           "#123570"
          ],
          [
           0.2222222222222222,
           "#3b496c"
          ],
          [
           0.3333333333333333,
           "#575d6d"
          ],
          [
           0.4444444444444444,
           "#707173"
          ],
          [
           0.5555555555555556,
           "#8a8678"
          ],
          [
           0.6666666666666666,
           "#a59c74"
          ],
          [
           0.7777777777777778,
           "#c3b369"
          ],
          [
           0.8888888888888888,
           "#e1cc55"
          ],
          [
           1,
           "#fee838"
          ]
         ],
         "showscale": false
        },
        "font": {
         "size": 12
        },
        "height": 700,
        "margin": {
         "autoexpand": true,
         "pad": 0,
         "t": 40
        },
        "paper_bgcolor": "rgba(0, 0, 0, 0)",
        "plot_bgcolor": "rgba(0, 0, 0, 0)",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Model Score: Enineerd Features, Rain adn Ws Removed",
         "x": 0.5
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0.11063372717508052,
          0.8893662728249194
         ],
         "range": [
          -0.5,
          4.5
         ],
         "scaleanchor": "y",
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "automargin": true,
         "autorange": true,
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "range": [
          6.5,
          -0.5
         ],
         "title": {
          "text": "model"
         },
         "type": "category"
        }
       }
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJAAAAK8CAYAAACwbkVeAAAAAXNSR0IArs4c6QAAIABJREFUeF7s3X+8VVWd//G1LyAgXrBGyGicJh1JrJksE8ZIwDTN/FGYmpagolJqv1S+44/MHjqWOl80y9QGQwVMSUtKUfw5AWp+QSkbTRBFMx1ScApEBLw/9vexNncd11nsc84+97y5rMt93X/q3rPP56zzXPsc3W8/a+3E8IMAAggggAACCCCAAAIIIIAAAggggEAVgQQdBBBAAAEEEEAAAQQQQAABBBBAAAEEqgkQIHF+IIAAAggggAACCCCAAAIIIIAAAghUFSBA4gRBAAEEEEAAAQQQQAABBBBAAAEEECBA4hxAAAEEEEAAAQQQQAABBBBAAAEEEOi8AB1InbfjmQgggAACCCCAAAIIIIAAAggggECPECBA6hHTzJtEAAEEEEAAAQQQQAABBBBAAAEEOi9AgNR5O56JAAIIdAuB4aMnXJYYs8vqdf1OXbF46ltFBz1s7HE79WrvM8cYM2/JghnnFn0exyHgzp3EmKnPLJhxAyIIbEmBPUdPmJgaM6mtqeWwZfNufX1Lvha14xLYffT44b2TZG7anp6w9OGZ8+MaHaNBAAEEtj0BAqRtb055RwggEKFA6YI6SUaaND0576LaXgSZJJmWpulC5YVQVwZI7j2EU9De3j52W/yX+z32Gz+mqalpXsVTLk1v6WxwlxizvN7nxnLq1xMgFTDM/bw0+l7t58IYM1b5WWt0TKrnD9170vY7DthwvUmSL4U10zS9vLOBsLtYN6mZ1dkaqvfo11EHSCU/Y0z4Gaxm4M5lxfddpc9FatKXWtP0kOcWzFyyJSy7W00CpO42Y4wXAQS6uwABUnefQcaPAALdQsAPkPIColqPN/ImuyJAchdcaWJGhRc32esnyTmVgrNG3tvWfq7ygtG9Fy986VEBkuKiu57zoUcESEEA4i62k9Q82plwsqcESPY8ykKpxFwYfp9VC/qV51Sl7xb3fdrVn5d6PltdeSwBUldq81oIIICAMQRInAUIIIBAFwj4oUBqzG7h0h73X9Bt14l9XNkV0RUBUq0gxf5Lfp/EfPiZ+TNv7wLuLnuJWu+7ywYS2Qt1pgOpqy+IlRf7kfGbah00LgDpau8taaTuQLJj9cK2i/2O0Y7v0/3TxLzHXzZVCtGNeVnRnVXpu2VbCJiV5wIBklKTWggggEBtAQKk2kYcgQACCDQs4O8n1FGstHTGu9h7KDVmWN6yms2WhlVYGlW66DHJ++3r2OUOSWpeM8Y8H3YchEskws6oevZAqvRf66vBlS3rcwcG7yvv/eR1BLhOgd4mOSHrdjLG+BfIRfyqdVFVeh/1BEjvBBZNJ/Zqb78pscsZs0kqX+aW5+5fzGbPSZJpbkx5QUDuEqacpZNFjvNfuz1Nl7sle/5SqBzfRfYCO0lN2cV3nmM9hrXO2YpLtwLjUlecNyC3NChpal1l9/4KQ968gKCITa0xl4UVHZ/bjvOi00v36g2QKi2XCs+tvFDFffbbk/SoXu3JmW7ZXD1LcfOWvlZaqpX7vWHMvWmavssF7/5nKE3TuWXLTCssIQ7PzbzP4Tt/Sy9OTPJlY8xDLlyqGjh1fCdt+rgXW6LcmQCp1vecH+yG3yOuQ3Szz0aOV94c+OdKtX925D1W5HvIzU/O+LLvGvZAavhfUyiAAAIIFBIgQCrExEEIIIBAYwL+vzS3mnS6v+mnvVBIkuRye/HTq73P5DBACjslvAvZsk6l0kWg9y/8lS4ks5qJOdYPY8IQqJ4AyXvtQnv+5I3VCu85ZsL5LWk62+7vkXcBldc94V80hRe8lazyuk+6IkCy4ZZ/AVn9IvWdzcvLgjRvfvOCu7xlRtVCKX8/m6rhlUnen7d/Tt65VOliupEAqcg5a+dw0A4bp7Sm7Ve7PWKqfgZy9kCq1D1VNUCqwyacszyrekK1PNNqAVLeud/xHXSI3zmTN4ZKAVK2d5u3N0+1188bb/YZNsb4nT5Fz237vPA9BUuCS3s+1esa1s06KU1yU4tJT8zCau/mBJlhUzLd/06t9N1tx1xrCWGlsebNQdHvuUp78ZUFTwW/X/xwOO/7vNJ/VAjfV9Hvq1r/3NuWOuoa+7cNno0AAghsWQECpC3rS3UEEEAgEwgvzN2ystamlm/2bu/zQ/dfssMLjlr/FdrdIa3a8olwCVullv9wjPUESFn407EJuD/leV0ERepWOyY0qtb9lHdRZ8dXT8BR7RQusAF0KVCrtGQqXH5TqwPJv8jOCzsqLVkMnYoeV82q1rlU5C5s1QxdYFXrdWrdKbDIxb2b504FSDmdVkXHXOn8tc9vajIDnp0384l6v0YrBTiVgttqIVTqLcmq1oEUdgZW+uwVfS91n9veXdgqfX/Uu8wsfA8dQdcBNvwZuP36fVzwb+/8VinEyjs39xwz/ujVb/a/u9pdMfO++6uFKGF4lfc9V+ncLvr3Wp1t/p5RNZYAlu4KWvR7qNZ3OR1IRT9ZHIcAAgg0JkCA1Jgfz0YAAQQKCYQXNP5/dfU7gXLDkZzbU4f/Ij9gwPr3266mvCVD4b+gV9svxD92h+a129ulPLUuzkOAcNmZfdwPkorsWVHtmPCCu1qAVOnipN4LyUqTXE9HQ9UAydustzMBkpujSheC/sWkvdBq79X6x7xlWuFx9s551QKkSvbVxhFaFjEses66C/IiYWal+VAFSEXHbIMIu8Sq6NKmIl84RZfy+bXyliVln13vrm31Bkj2fRXtDMn73sjG19ERUy1ULhLC2lL1dkaF77fj+2SZDXH976g33ur/uL3rnR+2lc1BwWVz/nwUXVZon1P0e65oUFQpTK32uc77HOd1cPn/nCr6fWW/hyp9Xov886TIZ4ZjEEAAAQSKCRAgFXPiKAQQQKAhgbyLH7eXg3+BFv5LcqV/aXYXDW65W1Nb7w9VulgLLy7c61Z8Qx37xXQ2QKoYKHXc+cldMFe7sKwWKoSPVQoxKl5EewNs5JbmtkyR8MO9XFcESBUvwr33bN3bErMyu5Dz99wJJs7NT7UAqd4QJu+cK2JY9zmbmJ39jpit0YFUdMw29MoLCxo5N/OCklKolhNmuMf816y155PrhCu6VKnaF2jJyhtbGC7UDDLr6ECyY6m1hMwPnGww1NbUMsWGrmmanmMDDX/vuhaTPuYvS3bvNe87qNLeTqFP+Lnw/hli/Jss1PM912iAVKQbMW9pm/suCYO+ot9XLqDLmzcCpIb+1YQnI4AAAnULECDVTcYTEEAAgfoF8gKkIhe1lboYKnUg5bXx19OB5L+zIkvNikr4QUPa3ntw3sWWX2tLdyAVHXet44qEH10ZIBXt/Cl6nB17PRfu7r3WU7+IYbVuHn+OqoUZtfanqTX2ooGKq1N0zHnnWF6gUutc9B+vtu9Ttsl8TlATdhoWfb+NBkiVzq/wHKp2Tm2pDiRr6r67bHCUJMm/tTW1nGCXrLnH7D5IqUl/ZpLk2nAZXzhnXufpq7XutFltDyqTmrLnV+pACl+/0QCp3g4k/xxyAZx/ntXzPVHpPRIg1fPNwLEIIIBA4wIESI0bUgEBBBCoKVA0jAk7OorugVStfvgv3kUu2O0bKjpme6zd06MlNU+7jYurXcxW62z64NjxH29vN+vcnbDyls/lLvPzloAVCRRqTljBA4pa+hei4YVjeAHeyBK2okt0ih5XK0CqdX7WswdSZzvS/Kmq1BGVF9ZWCnjq2T+nWrhW9NwYPnr8Z9uaWhe5UKLez17eqVppfv1ulVodZl0VIBU9h2ruv7MFOpCsrdcddq9J07/6nUvZeZUklyfGLLfH+o9tOo96j1iyYOY9nflOquTi7WNV2l+t2jJe/7UbDZBqzkHO97AbW2KSK1OTnuWHbPV8D1XbK6zWf5Ao+HXOYQgggAACBQQIkAogcQgCCCDQqEDRMCbvAjj7m3fHtEobqeb9C7a3bKXs7miuwyG8aO+4IMruxlR0zFmA5DbQDm6XXhprYkaFS4qyW2t7nRDhRb53oVS6nbl7HX/c1S6eKr1+aczenZ+qHVtp/ouGBF0VIAWBz6P+Ba19f/4dyrzwo+hxF/sbeNvXyrsArHfvl6KGRc7ZvFrub+HSoWqvG34O/fdUa0+gMNCyHT/VPmd552/e2Eqfx2B5Xj0BUlk41VFn3br+L9n9e/wApJ7322gHUt73TNl+TMF3RLhUtzS/abrQhbO1QsAw7Kn2/V5pLL5lkiQj/e+ySiFgPYFJtfMzXHJY9Huu0QDJ/37x796Y913tTAO/ze7SWfR7qNZ5UnSvrUb/Wc7zEUAAgZ4uQIDU088A3j8CCHSJQNEwpto+OfZW2aXBBkGN+/tmmwen6cmpMcP82027Y3P3XfFuxV10zNXq2ccq7eWSt/9FeBEQHpO3f0iR//qeu6myd8HphyFpEHZVO0HyDMuO9+apK/ZAcq9daV+UcC6KHFety6YsREqSL2XzbdKX7FLKjs6MqWHoFHoWDZDs82qds3nH2PecpuncvLtU+edF7m3ovffUnqRH9WpPzqx1V7JK78//e3geh/sl5Z3n/sb7NuCtdl7WCir8z5X9zJX2mOnE+200QNosiNn0nbGwranpxF7t7TeFXWzhOWDnNzFmWbqFOpDyurbyPmd5AUbuDQW8TcmLfLdUCka8ZY5lnUhl/5woWbYcZjvcFAFS3nzZv1ULcCqFv/V+X5WFUR3vLVta2JRM5y5sXfKvMrwIAgggYAiQOAkQQAABBBBAAIHIBYoEpZG/BYaHAAIIIIAAAt1cgACpm08gw0cAAQQQQACBbVsgbz+ibfsd8+4QQAABBBBAIEYBAqQYZ4UxIYAAAggggAACHQJ2KVQfk9zUYtIT8zaqBwoBBBBAAAEEEOgKAQKkrlDmNRBAAAEEEEAAAQQQQAABBBBAAIFuLECA1I0nj6EjgAACCCCAAAIIIIAAAggggAACXSFAgNQVyrwGAggggAACCCCAAAIIIIAAAggg0I0FCJC68eQxdAQQQAABBBBAAAEEEEAAAQQQQKArBAiQukKZ10AAAQQQQAABBBBAAAEEEEAAAQS6sQABUjeePIaOAAIIIIAAAggggAACCCCAAAIIdIUAAVJXKPMaCCCAAAIIIIAAAggggAACCCCAQDcWIEDqxpPH0BFAAAEEEEAAAQQQQAABBBBAAIGuECBA6gplXgMBBBBAAAEEEEAAAQQQQAABBBDoxgIESN148hg6AggggAACCCCAAAIIIIAAAggg0BUCBEhdocxrIIAAAggggAACCCCAAAIIIIAAAt1YgACpG08eQ0cAAQQQQAABBBBAAAEEEEAAAQS6QoAAqSuUeQ0EEEAAAQQQQAABBBBAAAEEEECgGwsQIHXjyWPoCCCAAAIIIIAAAggggAACCCCAQFcIECB1hTKvgQACCCCAAAIIIIAAAggggAACCHRjAQKkbjx5DB0BBBBAAAEEEEAAAQQQQAABBBDoCgECpK5Q5jUQQAABBBBAAAEEEEAAAQQQQACBbixAgNSNJ4+hI4AAAjUEkua9vtKOUuMCTUli3jWgb+OFqGC265Waf35fioRAYP3bqXlkeZugUs8ukab2fOSc1JwF6fNrn5y6u6YWVRBAAAEEYhMgQIptRhgPAgggoBMgQBJZEiCJII0hQNJRGgIkDSYBksZxUxUCJKUmtRBAAIHYBAiQYpsRxoMAAgjoBAiQRJYESCJIAiQdpDEESCJNAiQRJAGSEpJaCCCAQJQCBEhRTguDQgABBCQCBEgSRmMIkESQBEg6SAIkmSUBkoySDiQlJbUQQACBCAUIkCKcFIaEAAIIiAQIkESQBEgiSAIkHSQBksySAElGSYCkpKQWAgggEKEAAVKEk8KQEEAAAZEAAZIIkgBJBEmApIMkQJJZEiDJKAmQlJTUQgABBCIUIECKcFIYEgIIICASIEASQRIgiSAJkHSQBEgySwIkGSUBkpKSWggggECEAgRIEU4KQ0IAAQREAgRIIkgCJBEkAZIOkgBJZkmAJKMkQFJSUgsBBBCIUIAAKcJJYUgIIICASIAASQRJgCSCJEDSQRIgySwJkGSUBEhKSmohgAACEQoQIEU4KQwJAQQQEAkQIIkgCZBEkARIOkgCJJklAZKMkgBJSUktBBBAIEIBAqQIJ4UhIYAAAiIBAiQRJAGSCJIASQdJgCSzJECSURIgKSmphQACCEQoQIAU4aQwJAQQQEAkQIAkgiRAEkESIOkgCZBklgRIMkoCJCUltRBAAIEIBQiQIpwUhoQAAgiIBAiQRJAESCJIAiQdJAGSzJIASUZJgKSkpBYCCCAQoQABUoSTwpAQQAABkQABkgiSAEkESYCkgyRAklkSIMkoCZCUlNRCAAEEIhQgQIpwUhgSAgggIBIgQBJBEiCJIAmQdJAESDJLAiQZJQGSkpJaCCCAQIQCBEgRTgpDQgABBEQCBEgiSAIkESQBkg6SAElmSYAkoyRAUlJSCwEEEIhQgAApwklhSAgggIBIgABJBEmAJIIkQNJBEiDJLAmQZJQESEpKaiGAAAIRChAgRTgpDAkBBBAQCRAgiSAJkESQBEg6SAIkmSUBkoySAElJSS0EEEAgQgECpAgnhSEhgAACIgECJBEkAZIIkgBJB0mAJLMkQJJREiApKamFAAIIRChAgBThpDAkBBBAQCRAgCSCJEASQRIg6SAJkGSWBEgySgIkJSW1EEAAgQgFCJAinBSGhAACCIgECJBEkARIIkgCJB0kAZLMkgBJRkmApKSkFgIIIBChAAFShJPCkBBAAAGRAAGSCJIASQRJgKSDJECSWRIgySgJkJSU1EIAAQQiFCBAinBSGBICCCAgEiBAEkESIIkgCZB0kARIMksCJBklAZKSkloIIIBAhAIESBFOCkNCAAEERAIESCJIAiQRJAGSDpIASWZJgCSjJEBSUlILAQQQiFCAACnCSWFICCCAgEiAAEkESYAkgiRA0kESIMksCZBklARISkpqIYAAAhEKECBFOCkMCQEEEBAJECCJIAmQRJAESDpIAiSZJQGSjJIASUlJLQQQQCBCAQKkCCeFISGAAAIiAQIkESQBkgiSAEkHSYAksyRAklESICkpqYUAAghEKECAFOGkMCQEEEBAJECAJIIkQBJBEiDpIAmQZJYESDJKAiQlJbUQQACBCAUIkCKcFIaEAAIIiAQIkESQBEgiSAIkHSQBksySAElGSYCkpKQWAgggEKEAAVKEk8KQEEAAAZEAAZIIkgBJBEmApIMkQJJZEiDJKAmQlJTUQgABBCIUIECKcFIYEgIIICASIEASQRIgiSAJkHSQBEgySwIkGSUBkpKSWggggECEAgRIEU4KQ0IAAQREAgRIIkgCJBEkAZIOkgBJZkmAJKMkQFJSUgsBBBCIUIAAKcJJYUgIIICASIAASQRJgCSCJEDSQRIgySwJkGSUBEhKSmohgAACEQoQIEU4KQwJAQQQEAkQIIkgCZBEkARIOkgCJJklAZKMkgBJSUktBBBAIEIBAqQIJ4UhIYAAAiIBAiQRJAGSCJIASQdJgCSzJECSURIgKSmphQACCEQoQIAU4aQwJAQQQEAkQIAkgiRAEkESIOkgCZBklgRIMkoCJCUltRBAAIEIBQiQIpwUhoQAAgiIBCQB0rGHjjRXnHecaR7QLxvWjNmPmq9dPLPiEL992uHmzJMONtv16V3xeFvz0rOPNj+9fb753nV3bVbrzp98y+w8eJAZ8YWLcl9n9D4fNFMvOSl7bNIFN5oFjz+b/X/396FDdsx+n7dwqTniq1c1zKkOkO6fea5Z+fob5vgzr605tsvOOdZ88bB/zY57862N5sIrbzez73ui7HlnnnyI+eqXDzSP/2F5VnPcwR83F591tNlh+75lx+U9f9+P7W6uvOD47LizLrnZPPa758qe417/53P+nzn38lk1x1vrgO16peaf35fWOqzm4z/4j/PNLu/buXTcQ/MeM9ddf2vF54XH2wOfevpZc9Gl15Q954tHfdaMO/xAs2Tp8tJjH95zd/ON08abd79703kVPm/0J/cxp554tOnff9NnxB/LaaceZw4Yu2/pNf7619XmR9fNNE8/U+5c8w3nHLD+7dQ8srytM08tf8+HjjBXnHvsO5/xX/3WfP3imyvWPf+0w8yZJx70zmfcO/7XP/mGGTtij82eO2/RUvO5r/7ILPzFd8weu7639Lj7u/vDF6uM5eoLjzcTPv+J0nNXrFxtvvKdm8yCx5c1ZKAMkJTfl+F36dp1G8zZl95qZt29MHu/9nty7Mh3rP3vu/C5Dsia2e/M/T4+rOx72j4e1u8cavr82ien7t655/IsBBBAAIHYBQiQYp8hxocAAtuswLCxx+3Uq73PnCRJRpbeZJresnpdv1MHbr9+nyRJLm9rajls2bxbX3ePdzxneqtJJ/dKzZCmpqZ5ZUBpevIzC2bc0PG3hgMkF8gse/HVLIixFyWnf/kAc+3PHsoNftzF0+z7F2ch048vHG+OPWyk+cGN92XH+wHP2y2tpb+792CPnzBuVPbr0hf+khsg+TXcxZANkMKxKk8cVYB08w9ON6M+Piwb2qNPLKsZINnw5tBPfTQ3NHLvz4VH2/XpVbWmfe0hOw00B42/rETjwiMb1r26as1mAZIfXsUUINnAZtwRnzbTbro9C2Js6HPYZ8aaOffOMz//xT25U28DJPtz5r99v+Kp4cKj3r17l4VE/nNdWPTbhb/PAisXLv3PiteywCkcy3fPO8OsfP2vZceuW7+h6jiKnruKAGn0PsPMf/77iWbZn17NAh4bDp3+pU+Za2/5L/P96+ZsNhQX8Mx+4HdZyGRDnWMPHWF+cNP9FY+/9OyjzE9vX2AeeWKZ+b/nfNFceeN95ud3L8peywZRs+5elNWqNRYbTv15xV/Ljn3jzfVm5FH/XpQs9zhVgKT+vrTfh/8w9O9KIfiiX37XDNyhfxYA2Z8p5x5rrrzh3ixQCr97896ofb79nBf5Lu88KAFS5+14JgIIIBC/AAFS/HPECBFAYBsUGLr3pO13HLDhetus4AU+Zs8xE85vSdPZSVPrKhsupWl6ztKHZ853BHvsN35MU5JMyguZdh89fnjvJJmbtqcndDyn4QDJBkanHD3GnHfF7dlFSq2Qxv4X8WEf2LnUFVTp+EY6kNxFkDXxX6tW11Ijp5EqQHJjKNKBZLuILvjaOHPzrx4xP5g2N3f47phfP/CEOWTsXmb5S6/lhlKVarlx2OK7vf89ZQGSDaaO//wnzczZj5iTvzjW3P1fv4+qA8kHCUOdPKxaAZKtceLx48zDjz5h9h2xl3GBkPv7fQ8+Ugqn/Fo2MDr4wE+am26ebRY88vhmgVI4FhsovW/oeyRdSIoAyYY4pxw92px3xS+yUCcMccLx2xBn2D/uXOr8KXL8zjsNyg158gKjRsbS2c+4KkDaUt+X7n3ZQGncQXuXdSG5x2p9N4djq/UfAzpraQwBUufteCYCCCAQvwABUvxzxAgRQGAbFLBhTx+T3NRi0hOfWzBzSd5bHD56QtYqsmTBjHPd4/ZviTHLbOhkwyS/SyknlGo4QMq7YLEBjv3JW14WBkj2uLzjOxsg+bXC17KP+Utj8jqcOnsqbY0Aye8scuN+7k+vljqI3DI1G+z8+oHF2TK0SgFSXveRDY/sj+1Iso/7AZJ97YnHjDU33DbP/OmVVdlyuJgDJLtMbMwn9zGz73qwageSv+TNX4bmB1A2QLLL1Sp1FFkzPwTab9THzSdGftRcf9PtWYBkf6qFVbWCrHrOUUWAZDuIxn36Y+bsy2ZlAZL9scvM7E9eZ08YIFU73nYrue6jot1M9Yyl2jjrcVQFSFvq+9K9l7zvV/eYW7I2a87C3CXGfveRfU6t5XH1+JUfS4DUeTueiQACCMQvQIAU/xwxQgQQ2AYFSsvXjFluu4lWLJ76Vvg2w4DIX75mQ6fw8TCUuu2223qd/P2HWhvhsxdEB476UNk+Q9UCpLz/qq0KkMIOI/9iyr5HuyfSg4/+sXTxZB/f+8P/mPtf6+s12RoBkl0+Nmbk8FJXkAuM/vDMS+aamQ9kgdH8hUuyriC3FC0vQMrrPgoDJT9AssvZ/M4nP6iKaQ8kO4f+krNaeyD5c+6eN/+Rx7OOIxsY/f6/l1RckuZ3GOUFSB/9l+FlHUWVQiIbdIVhU73non+8KkA68BN7lu0lVC2YyVviVul4GzZV6j7KC55smFV0LHnBV2ctlQHSlvi+dIFP3vJhf8+lSnu+hd1HeU7+8ji3p1xnPJuaml5Yvfja3ZMkae/M83kOAggggEDcAgRIcc8Po0MAgW1YoMIeSKU9jFxHUXuaTrVL0vzlazZwyn739kBK03Shv2fSmg0bdv/7f/1mQ7vL1vtf1O10hRu72r+FFzad6UAKO4zcqWH3QfrxzAfN18YfWBYgFdkTpOjpFUOAZMfqgp477nvcTDhyv802ybbHhHsr+Z1G7v3av+3+j+9sQO3+bvdH+e3vlpnDPvUxY/dUCn8U+yCpNtH2x1ZkCVv4XmzIs/pva8xvHl5UtgG2f5ztUlr63Iub7a/UmQ6kIl1SRc9Hd5wqQKqn68e+dt5G2eFm2LX2UrKhk93Px98Eu2g3VK19l+p1VAZI4RKzaoF70e/LWt1Ftk6lJWy1lrY5qyIhUxHXf3zf37X995zv2QDpxSLHcwwCCCCAQPcSIEDqXvPFaBFAYBsWcIFQe3v7WLfv0Z6jJ0xMjRlml7HZ5Wtpms51j/kdSJYlZ8+khpew1bunRzg99uLl6gvHm9vuWVi26XZnAqSwdt4SNrdBrD221mvUcyptjQDJ7UF0yY9nl+66lrcUzb6PSh1I/lK0Svso2eeHS9h8m5g7kPxxukAovKtapXmudHy4KbZiD6QtER7Z96UIkOrdA2nzz/gw86PvHG9um7uobBPtal1MeeGRrVtkLOrwyL6uKkDaEt+XRcIjNyd5+8BV2zfJn0tVgMRsmzELAAAgAElEQVQeSPX8k4VjEUAAge4nQIDU/eaMESOAwDYqkLexdrYxtkmmtDU1nd27vf07rU0t33R3ZQuXsIW/G2MaDpBq3VXIdfksfvpPpTsF+dNT6b++1wp3imyIHQZI4R3fqu0XUu8p1BUBkr9E7fgzry2FQmvXrc/2KaoW5FQKkPK6j/Lee3cLkOwStL33+pD5twv+b/Z2/CVp9s5oriPp+eUvZXdGs78fdMAoc8FFV5WOr3TXtjBAsk9o5C5s6mVr/vwpAqRadz5zd11b/Mc/ZXdpC3/ygqJq3UfVgqVaY1EuW/PfhypAUn9fVtvo2n6HnjXxM2byZbOMXXKW911crfto1lWnm6eefbkU7NfqlCr+nckeSMWtOBIBBBDofgIESN1vzhgxAghsAwKb7pjW9PU1b/ad7PY/yttY24VKqTEv27ftb6idExiZjk22d+nYV2l9815faXgfCn+PDTuGGbMfLe0zlHfR4i81C5euuQuaoUN2LM2iXYJmb0ttL4JsCDRh3KiyGfZfz38gLyDyl8+tXbdBsv+RfU1VgGSDmlEfH1Z6G2+3tJmf/OzB7C5rYYBkD3J/22H7vtlzwuVprlBegGT3UDr0Ux81F155e6mDqdJHp7sFSC7kefe73zmP/D2QwgCp1vG+S16AFD7f34DbPte9Xv/+/bJS/lhs+ORv3m0fb21trbrhd9GvOEWAZF/LhUTNAzaNf8avfmu+fvHN2f/PC5BsCOQ2rA+XrlW7K1v4Ou592u8At5St2lj813XPzTbLv+n+su6non7uOFWAZOspvy/zlgP738Hhst7w+7ZaiB5+1/rfw/X6lR9PgNSYH89GAAEE4hYgQIp7fhgdAghsowKlbqMk+VLpIsakL7Wm6SHhXdnsMjaTJNP8pW32OXkBktfFZGyItLYtWbeNEnbp21IFSF066EhfbEvsgRTpW93iw1IFSFt8oJG/gDJAivytdsHwCJC6AJmXQAABBLaaAAHSVqPnhRFAAIEtLtDwErYtPsJu8gIESLqJIkDSWRIgaSwJkDSOm6oQICk1qYUAAgjEJkCAFNuMMB4EEEBAJ0CAJLIkQBJBGmMIkHSWBEgaSwIkjSMBktKRWggggECcAgRIcc4Lo0IAAQQUAgRICkXhHkii4XTrMgRIuukjQNJYEiBpHAmQlI7UQgABBOIUIECKc14YFQIIIKAQIEBSKBIgiRQ3lSFA0nESIGksCZA0jgRISkdqIYAAAnEKECDFOS+MCgEEEFAIECApFAmQRIoESFJIYwwBkkaUAEnjSICkdKQWAgggEKcAAVKc88KoEEAAAYUAAZJCkQBJpEiAJIUkQJJxEiDJKNlEW0lJLQQQQCBCAQKkCCeFISGAAAIiAQIkESSbaIsgWcKmgyRAklkSIMkoCZCUlNRCAAEEIhQgQIpwUhgSAgggIBIgQBJBEiCJIAmQdJAESDJLAiQZJQGSkpJaCCCAQIQCBEgRTgpDQgABBEQCBEgiSAIkESQBkg6SAElmSYAkoyRAUlJSCwEEEIhQgAApwklhSAgggIBIgABJBEmAJIIkQNJBEiDJLAmQZJQESEpKaiGAAAIRChAgRTgpDAkBBBAQCRAgiSAJkESQBEg6SAIkmSUBkoySAElJSS0EEEAgQgECpAgnhSEhgAACIgECJBEkAZIIkgBJB0mAJLMkQJJREiApKamFAAIIRChAgBThpDAkBBBAQCRAgCSCJEASQRIg6SAJkGSWBEgySgIkJSW1EEAAgQgFCJAinBSGhAACCIgECJBEkARIIkgCJB0kAZLMkgBJRkmApKSkFgIIIBChAAFShJPCkBBAAAGRAAGSCJIASQRJgKSDJECSWRIgySgJkJSU1EIAAQQiFCBAinBSGBICCCAgEiBAEkESIIkgCZB0kARIMksCJBklAZKSkloIIIBAhAIESBFOCkNCAAEERAIESCJIAiQRJAGSDpIASWZJgCSjJEBSUlILAQQQiFCAACnCSWFICCCAgEiAAEkESYAkgiRA0kESIMksCZBklARISkpqIYAAAhEKECBFOCkMCQEEEBAJECCJIAmQRJAESDpIAiSZJQGSjJIASUlJLQQQQCBCAQKkCCeFISGAAAIiAQIkESQBkgiSAEkHSYAksyRAklESICkpqYUAAghEKECAFOGkMCQEEEBAJECAJIIkQBJBEiDpIAmQZJYESDJKAiQlJbUQQACBCAUIkCKcFIaEAAIIiAQIkESQBEgiSAIkHSQBksySAElGSYCkpKQWAgggEKEAAVKEk8KQEEAAAZEAAZIIkgBJBEmApIMkQJJZEiDJKAmQlJTUQgABBCIUIECKcFIYEgIIICASIEASQRIgiSAJkHSQBEgySwIkGSUBkpKSWggggECEAgRIEU4KQ0IAAQREAgRIIkgCJBEkAZIOkgBJZkmAJKMkQFJSUgsBBBCIUIAAKcJJYUgIIICASIAASQRJgCSCJEDSQRIgySwJkGSUBEhKSmohgAACEQoQIEU4KQwJAQQQEAkQIIkgCZBEkARIOkgCJJklAZKMkgBJSUktBBBAIEIBAqQIJ4UhIYAAAiIBAiQRJAGSCJIASQdJgCSzJECSURIgKSmphQACCEQoQIAU4aQwJAQQQEAkQIAkgiRAEkESIOkgCZBklgRIMkoCJCUltRBAAIEIBQiQIpwUhoQAAgiIBAiQRJAESCJIAiQdJAGSzJIASUZJgKSkpBYCCCAQoQABUoSTwpAQQAABkQABkgiSAEkESYCkgyRAklkSIMkoCZCUlNRCAAEEIhQgQIpwUhgSAgggIBIgQBJBEiCJIAmQdJAESDJLAiQZJQGSkpJaCCCAQIQCBEgRTgpDQgABBEQCBEgiSAIkESQBkg6SAElmSYAkoyRAUlJSCwEEEIhQgAApwklhSAgggIBIgABJBEmAJIIkQNJBEiDJLAmQZJQESEpKaiGAAAIRChAgRTgpDAkBBBAQCRAgiSAJkESQBEg6SAIkmSUBkoySAElJSS0EEEAgQgECpAgnhSEhgAACIgECJBEkAZIIkgBJB0mAJLMkQJJREiApKamFAAIIRChAgBThpDAkBBBAQCRAgCSCJEASQRIg6SAJkGSWBEgySgIkJSW1EEAAgQgFCJAinBSGhAACCIgECJBEkM39E3Pi2GZRtZ5dZsfmDWbyxMd7NoLo3b/0Wh/zLyfsKarWc8vYAClN23ougPCdp6l5/q2npu0uLEkpBBBAAIGIBAiQIpoMhoIAAgiIBQiQRKAESCJIYwwBks6SAEljSYCkcbRVCJB0llRCAAEEYhQgQIpxVhgTAgggoBEgQNI4GgIkESQBkg7SGEOApOEkQNI4EiDpHKmEAAIIxCpAgBTrzDAuBBBAoHEBAqTGDbMKBEgiSAIkHSQBksySAElGSQeSjpJKCCCAQJQCBEhRTguDQgABBCQCBEgSRgIkEWNWhiVsOk06kDSWBEgaR1uFJWw6SyohgAACMQoQIMU4K4wJAQQQ0AgQIGkc6UASORIgCSHpQJJhEiDJKAmQdJRUQgABBKIUIECKcloYFAIIICARIECSMNKBJGLMytCBpNOkA0ljSYCkcbRV6EDSWVIJAQQQiFGAACnGWWFMCCCAgEaAAEnjSAeSyJEASQhJB5IMkwBJRkmApKOkEgIIIBClAAFSlNPCoBBAAAGJAAGShJEOJBFjVoYOJJ0mHUgaSwIkjaOtQgeSzpJKCCCAQIwCBEgxzgpjQgABBDQCBEgaRzqQRI4ESEJIOpBkmARIMkoCJB0llRBAAIEoBQiQopwWBoUAAghIBAiQJIx0IIkYszJ0IOk06UDSWBIgaRxtFTqQdJZUQgABBGIUIECKcVYYEwIIIKARIEDSONKBJHIkQBJC0oEkwyRAklESIOkoqYQAAghEKUCAFOW0MCgEEEBAIkCAJGGkA0nEmJWhA0mnSQeSxpIASeNoq9CBpLOkEgIIIBCjAAFSjLPCmBBAAAGNAAGSxpEOJJEjAZIQkg4kGSYBkoySAElHSSUEEEAgSgECpCinhUEhgAACEgECJAkjHUgixqwMHUg6TTqQNJYESBpHW4UOJJ0llRBAAIEYBQiQYpwVxoQAAghoBAiQNI50IIkcCZCEkHQgyTAJkGSUBEg6SiohgAACUQoQIEU5LQwKAQQQkAgQIEkY6UASMWZl6EDSadKBpLEkQNI42ip0IOksqYQAAgjEKECAFOOsMCYEEEBAI0CApHGkA0nkSIAkhKQDSYZJgCSjJEDSUVIJAQQQiFKAACnKaWFQCCCAgESAAEnCSAeSiDErQweSTpMOJI0lAZLG0VahA0lnSSUEEEAgRgECpBhnhTEhgAACGgECJI0jHUgiRwIkISQdSDJMAiQZJQGSjpJKCCCAQJQCBEhRTguDQgABBCQCBEgSRjqQRIxZGTqQdJp0IGksCZA0jrYKHUg6SyohgAACMQoQIMU4K4wJAQQQ0AgQIGkc6UASORIgCSHpQJJhEiDJKAmQdJRUQgABBKIUIECKcloYFAIIICARIECSMNKBJGLMytCBpNOkA0ljSYCkcbRV6EDSWVIJAQQQiFGAACnGWWFMCCCAgEaAAEnjSAeSyJEASQhJB5IMkwBJRkmApKOkEgIIIBClAAFSlNPCoBBAAAGJAAGShJEOJBFjVoYOJJ0mHUgaSwIkjaOtQgeSzpJKCCCAQIwCBEgxzgpjQgABBDQCBEgaRzqQRI4ESEJIOpBkmARIMkoCJB0llRBAAIEoBQiQopwWBoUAAghIBAiQJIx0IIkYszJ0IOk06UDSWBIgaRxtFTqQdJZUQgABBGIUIECKcVYYEwIIIKARIEDSONKBJHIkQBJC0oEkwyRAklESIOkoqYQAAghEKUCAFOW0MCgEEEBAIkCAJGGkA0nEmJWhA0mnSQeSxpIASeNoq9CBpLOkEgIIIBCjAAFSjLPCmBBAAAGNAAGSxpEOJJEjAZIQkg4kGSYBkoySAElHSSUEEEAgSgECpCinhUEhgAACEgECJAkjHUgixqwMHUg6TTqQNJYESBpHW4UOJJ0llRBAAIEYBQiQYpwVxoQAAghoBAiQNI50IIkcCZCEkHQgyTAJkGSUBEg6SiohgAACUQoQIEU5LQwKAQQQkAgQIEkY6UASMWZl6EDSadKBpLEkQNI42ip0IOksqYQAAgjEKECAFOOsMCYEEEBAI0CApHGkA0nkSIAkhKQDSYZJgCSjJEDSUVIJAQQQiFKAACnKaWFQCCCAgESAAEnCSAeSiDErQweSTpMOJI0lAZLG0VahA0lnSSUEEEAgRgECpBhnhTEh0AME9thv/JgkSS5va2o5bNm8W1/vAW+58FsU2hAgFVavfmBz/8ScOLZZVK1nlyFA0s0/AZLGkgBJ40iApHOkEgIIIBCrAAFSrDPDuBDYBgSG7j1p+x0HbLjeGPPQMwtm3OC/JWFIUpdUaUxJ8iX3xDRNF8YUZAltJAHSsYeONFecd5xpHtAvI5sx+1HztYtnVnT/9mmHmzNPOths16d3dsy8hUvNEV+9qnT8nT/5lhk7co/s97XrNpizL73VzLp7Yfb7ol9+1+yx63tLx/rPDeu6g1asXG0mXXCjOeaQEWbCuFGl57q/L3j82brOkbyDVQHSN791thky5D1lL7F8+fPmhmlTq45x1113M0cfc2x2zO23zTIvvLC8dPxeH/2YOfSzh5uFCx8zDz54f+nv4Wv5r+PqDRw4qHT8E08sMrPv+EXZOA488CAzcuS+5u577jJP/v53DTvaAo0GSLPv621eXtFkvnHS25uN529rjLnoqn7m6yduNLu9P6063if+u5c5/z/6Z8fsMrTNTPn2evOudzjMj27czsx5aLuKj9d6fqWx2PFfN3PTZ8n9HHbA27nvpxa4KkBq9DMefif8+MLxpc9i+BkPX2vpC38xI75wUemtVhtL+P3gnlTrO6mWozJAOu6wfc2V53+59H05/Y6HzRkXTc8dwgWnf86cNfGQ0nflO99pfzOnfnuamb9oafanx++42AzfbWj2/5csX2H2OfLCsnp3TT3b7LzToLK/jxmxh7n+eyeboUPeVTo2byx2DKccs785b8rPza1zHqtFVfNxOpBqEnEAAggg0K0FCJC69fQxeATiFqgWIG2tkeeNafjoCZclxuyyel2/U1csnvrW1hrbFnjdhgOk0ft80Ey95CSz7MVXsxDIhjinf/kAc+3PHjLfu+6uzYbsLv5m3784C5nC3+2F5biD9i6FRvaCcOAO/bMAyP5MOfdYc+UN92aBkguMZs1ZWDGwss9/ddWabGw2mPrziv/NjnXjfuPN9WUXp501VgZIdgw/vOqKwkPxw5433lhTCpD8v7e1tZkF839TCpDsY4cf8Xkzf/5vsuDHBkGjx+xvfv/7xVlIZEOnMWP2N3fd+assjBp35FHmox/du1TDPn7EEeNM3759zcaNG82dd87e6gGSH9iEgcuGjcZc8qN+ZtEfepuBze3m8nPXVw2Qlr+UmO/9uJ/59tc2ZMfZUGfxf/c2F3xjg+nX19T83Y7lupu32yx0spNaayzhaxU+EXIOVARIjX7G7Wf62MNGmh/ceF/2nRB+R9jP5bAP7Fz6jPvfJ+Fr1zsW+1qnHD3GnHfF7aUQujOeqgDJhTbPvviqOXzSFcaGM2cc/2lzzc0PmEuu/XWhodmw6NXX12TPd+GR/d8wNLJ/u+a7J5gTjtwvOy4MlmyQZcOpyZfdkgVR9tjjDt/XXHnD3GwsftBlQ76zvv8zAqRCM8RBCCCAQM8WIEDq2fPPu0dgiwoU7UCyg+jV3mdOkiS3pCY9KzHJ+02a3uIHOrYrp6mpaZ49NuwYygKgJDkne8ykL7Wm6SHPLZi5ZNjY43by69rH33rbjBvQx0z2u6LyOn72HD1hokmSaQ7IvWY4Vvu7fb116/q/lHVbuc6mND3ZdV3tPnr88N5JMjd7X5vGf/mSBTPO9cY3Mnudjvc8cPv1+/jL+8Lj2tvbxy59eOZ8+xT73k2SDEzSdJB9bf/9G2MaDpDCC7TwAi88gcKLR//4KdPmloVR9rnVAqkir1Xt4tG/cG20C2lrBki2k2jt2rUZ9eDBgwt3IPlz48KmVatW5XY7ucDoqaf+UNaFtK12IIVdTGGgZLuP7I/rcvIDI/v3Il1O1TqQ/LCqkS9hRYBU72c8/FyFn1P7+M6DB5WCW/8zvvzPK7NuRhcw2/duQ2D7Y7uQ6h2LHyA34qgKkMJunjBQqjXG8Pk29Pn0Jz9c1o2UVyOvAyk8zgVGd9z3eFlHFB1ItWaFxxFAAAEEfAECJM4HBBDYYgJ1B0jGLLehkR2Qv/QtC3iakukuGLLhTmrMMBfC9E77HPfM/BlXu0DFdRPt0Lx2+yxA6qhru4sqdSDZ59p69n/D1/MDJvt4pZqpMS97wdD0VpNOdsFSe5pOtaFP9vo7bDxl9Zt9fzpowIYLE2OWuaBpzzETvt6atNza1Nb7Qy5AenNt81u+hQuj0vb0BFtvU4BkjvVtjDEHdIRv65v3+kp7IxMcdgyFF3x5te1F3a67DM46EuyPC3nskjK/+8A+FnYo+fWqPebG4bqPKo3DXZg2YmCfqwyQ/CVstZav2fDI/tiOpYknT+p0gFQpIHIuNij6xKj9zG8ffbhsGdy2GiCFAZENeyZ/r7857fi3zcf/pc3YQOmcy/qb0SNasxDJHr/L0HYz7uDW0mNvrG0qnVZ5S9CKLmHr7PI1++KKAKnez3heMOuHQP7/z/uMuyWsdtnZI4uXmUvPPtr89Pb5WfdSPWNRdR/ZMaoCJBv4HHnwPmXdPLajyP7kdRCF30th95ENhvYfObzssLxlaEUCpErdUARIjf7TgecjgAACPUuAAKlnzTfvFoEuFag3QErT9By/s8aFK1lI4gU8WYhikiltTS0nhBtw54U9ft28PZCM1y1kXyd8vVo17Xj6mOSmFpOeaDufXA07/tamljs7Aqep/j5QbhwudPInxn+9tL334LzaziNvrE1JMskGSAt/9Z10z8MvaWhJnr2gO3DUh7LlJ66LJ7xADE8qdxHYd7ve2d4e/j5G4cVntZCo2uvUunjMuxBt5ORXBUj+GMJlZeH4bGDU3NxcWu7WSIDkB1Hh61TrTtqWAyQXCFmPMEByy9DWrkvMkud7le2RZLuRfnVfn9JyN/fcww5oyQIm91NkP6ZKzy16rqoCpHo+43ldg2GA5Ae74WfcPd++R7uvmr8HUj3fN6ruI3WAFHYMFQ2Q8oKcMFAKl6G586RWgFStE0odIPXr2+fl1xddt3uSJBuLnscchwACCCDQfQQIkLrPXDFSBLqdgDJAckvUHIK/jM1f3tZxMZBtim3/vw1vcgOkjo29s6Vq73TsZGFLx55Ipc6gIgGSv0StNFEdwVS4hM0tQctZwpYtewsDpDAs8zuwqgVIf3zkh0P+Yd9vvdjIiVNPR4B9nTDYcRePi5/+U7ZPkVvuMnTIjqVhvd3SWto/xf3R3xspXH5Wa2lbuCdLI+/fPXdLBEi2tluelreJdt6G2/Y5/j5I9vdKm2i7sds6/fr122zpm33chUcbNmzI3ZdpWw6Q7Pt3S9TCAMnvOLLH2SVvcx7qk+15tPyl8gDJPR4uSysSILnnVtoUvNa5qwqQ/H3J7GvWCon9jfDdGF1QXK0DKew4CvcqK/p9ow6It3YHUqWAJwyQKh1XLUByz1mzdn1uF5Q6QHrfe9694dn7/8MGSK/UOn95HAEEEECg+wkQIHW/OWPECHQbAWmA5C318gGKLDerFiAVXtKWJJdXCqWqdUSFk1XpDmt+F1Ov1AxxS9ga6UBasXhqw0vY6t2TpJ4OAhc4HfPZkebrF88s63ByG2vn7V1U7eJxS4RHdpxbI0AKz53OdCA1Eh7Z199WA6RqeyC9b+c025D78we3ZMvZ7I+/R5L9/eqb+prvfmtD6a5teXeG6y4BUr2f8fC8tCHQ1ReON7fdszBbhlZtDyT73HDfMr8rcb+PDyt7PC8srhUgd+YfkKoAqbN7IOUtfbPvIwyGXBj0wCNPl+1jVClAqhUe2ddQB0jcha0zZyDPQQABBLqPAAFS95krRopAtxNQBUhhSGQh8vYLssvZOrpzJhXtQLK1wn2FwpCno8tnbK2a/nK0LBBKzIdbk9bf+Hs0udpr1r999I7b9x1n90KyezNVCpDcHkiudu4eSMH+TW4JmyJAqnVXpLDDKLxzWvi4fxLnLV+r1flQ7eJR3ZXgj1URINlOoREj/tVM/c9rs9LhvkNun6JXXnk5d6PregOkzi5b89/3thIguT2Nzj1tY2mPo2p3YbMdSCtfbyq7K5vrQOrfb9Md34bs1J51MIXdS84vL0CyS+N+ObeP+cIhLdnd3io9t+iXvaIDqd7PeDi28DNb7S5stvPQbqIddiS6uyXWGot97S3xOVcFSLXuwuY2sn7i6RdLd1mrtbzM3knt1rseywKjokGTdSq6gTcBUtFPG8chgAACCFgBAiTOAwQQ2GICufsNddyFLE3Tua7Lxg4gXGqWt4zM3YXNHu/uZJbzGvemafquWmGPfxc2W88tg3PLy8ru7Jaml4cbc/tdTfb54Tjc3dDCu7P5d0nzX8PWcK8dBlg178K2BQMkOy4X9Nj9SuyP3fz2axfPzP5/XkBkL/AmjBtVOq/8PZD8WuHStfB1XAG7+bbbg6nandXsheweu7637HzOWx7XmRNeESC55WIDBw4qDeGJJxaV7npWb4CUV88tbxs4aJA54ohxpm/fvmVv1z1unzt6zP6mV69eZY+vXPlatpTNjcV/vnusM37+c3Zs3mAmT3y87jJ276Hz/6N/2fO+/2/rs0DI7Vm06A+9S4+P+EhrKQAKAyR7kF9vl6Ft2fK0d3VMTVgvfNwFPy+v2OR32vgNpf2Pao3FhlNzHtp0l7fwufWiKAKkznzG/c+a//l24/e/A+wt4s++9FYz6+6F2cMuZLb7o9kffw+komPx7+JWr1ne8aoAydZ2IZH7vvQ3vc4LkGz30Ac/sHPFO63Z0OiEI/fLhm2/z668Ya655NpfZ7/7j7n35V7PBkM2fHLO7vEly1dkS9nCcdrH3WONmNKB1Igez0UAAQTiFyBAin+OGCECCGxlAX/Poa08lHpfPmn0Lmz1vuC2erwiQNpWbep9X50NkOp9nZ5wvCpA6glW1d6jMkDC0jz/1lPTdu/pDrx/BBBAYFsVIEDaVmeW94UAAp0WyNnc+hZ7VzO71KzTRbfOEwmQRO4ESCJIYwwBks6SAEljSYCkcbRV6EDSWVIJAQQQiFGAACnGWWFMCCCAgEaAAEnjuMU20RYNr1uVIUDSTRcBksaSAEnjSICkc6QSAgggEKsAAVKsM8O4EEAAgcYFCJAaN8wq0IEkgqQDSQdpjCFA0nASIGkcCZB0jlRCAAEEYhUgQIp1ZhgXAggg0LgAAVLjhgRIIkNXhg4kHSgBksaSAEnjSICkc6QSAgggEKsAAVKsM8O4EEAAgcYFCJAaNyRAEhkSIIkh6UCSgRIgySjZA0lHSSUEEEAgSgECpCinhUEhgAACEgECJAkjS9hEjFkZOpB0mnQgaSwJkDSOtgqbaOssqYQAAgjEKECAFOOsMCYEEEBAI0CApHFkDySRIwGSEJIOJBkmAZKMkgBJR0klBBBAIEoBAqQop4VBIYAAAhIBAiQJIx1IIsasDB1IOk06kDSWBEgaR1uFDiSdJZUQQACBGAUIkGKcFcaEAAIIaAQIkDSOdCCJHAmQhJB0IMkwCZBklARIOkoqIYAAAlEKECBFOS0MCgEEEJAIECBJGOlAEjFmZehA0mnSgaSxJEDSONoqdCDpLKmEAAIIxChAgBTjrDAmBBBAQCNAgKRxpANJ5EiAJISkA0mGSYAkoyRA0lFSCQEEEIhSgAApymlhUAgggIBEgABJwkgHkogxK0MHkk6TDiSNJQGSxtFWoS1CvQkAACAASURBVANJZ0klBBBAIEYBAqQYZ4UxIYAAAhoBAiSNIx1IIkcCJCEkHUgyTAIkGSUBko6SSggggECUAgRIUU4Lg0IAAQQkAgRIEkY6kESMWRk6kHSadCBpLAmQNI62Ch1IOksqIYAAAjEKECDFOCuMCQEEENAIECBpHOlAEjkSIAkh6UCSYRIgySgJkHSUVEIAAQSiFCBAinJaGBQCCCAgESBAkjDSgSRizMrQgaTTpANJY0mApHG0VehA0llSCQEEEIhRgAApxllhTAgggIBGgABJ40gHksiRAEkISQeSDJMASUZJgKSjpBICCCAQpQABUpTTwqAQQAABiQABkoSRDiQRY1aGDiSdJh1IGksCJI2jrUIHks6SSggggECMAgRIMc4KY0IAAQQ0AgRIGkc6kESOBEhCSDqQZJgESDJKAiQdJZUQQACBKAUIkKKcFgaFAAIISAQIkCSMdCCJGLMydCDpNOlA0lgSIGkcbRU6kHSWVEIAAQRiFCBAinFWGBMCCCCgESBA0jjSgSRyJEASQtKBJMMkQJJREiDpKKmEAAIIRClAgBTltDAoBBBAQCJAgCRhpANJxJiVoQNJp0kHksaSAEnjaKvQgaSzpBICCCAQowABUoyzwpgQQAABjQABksaRDiSRIwGSEJIOJBkmAZKMkgBJR0klBBBAIEoBAqQop4VBIYAAAhIBAiQJIx1IIsasDB1IOk06kDSWBEgaR1uFDiSdJZUQQACBGAUIkGKcFcaEAAIIaAQIkDSOdCCJHAmQhJB0IMkwCZBklARIOkoqIYAAAlEKECBFOS0MCgEEEJAIECBJGOlAEjFmZehA0mnSgaSxJEDSONoqdCDpLKmEAAIIxChAgBTjrDAmBBBAQCNAgKRxpANJ5EiAJISkA0mGSYAkoyRA0lFSCQEEEIhSgAApymlhUAgggIBEgABJwkgHkogxK0MHkk6TDiSNJQGSxtFWoQNJZ0klBBBAIEYBAqQYZ4UxIYAAAhoBAiSNIx1IIkcCJCEkHUgyTAIkGSUBko6SSggggECUAgRIUU4Lg0IAAQQkAgRIEkY6kESMWRk6kHSadCBpLAmQNI62Ch1IOksqIYAAAjEKECDFOCuMCQEEENAIECBpHOlAEjkSIAkh6UCSYRIgySgJkHSUVEIAAQSiFCBAinJaGBQCCCAgESBAkjDSgSRizMrQgaTTpANJY0mApHG0VehA0llSCQEEEIhRgAApxllhTAgggIBGgABJ40gHksiRAEkISQeSDJMASUZJgKSjpBICCCAQpQABUpTTwqAQQAABiQABkoSRDiQRY1aGDiSdJh1IGksCJI2jrUIHks6SSggggECMAgRIMc4KY0IAAQQ0AgRIGkc6kESOBEhCSDqQZJgESDJKAiQdJZUQQACBKAUIkKKcFgaFAAIISAQIkCSMdCCJGLMydCDpNOlA0lgSIGkcbRU6kHSWVEIAAQRiFCBAinFWGBMCCCCgESBA0jjSgSRyJEASQtKBJMMkQJJREiDpKKmEAAIIRClAgBTltDAoBBBAQCJAgCRh3NSBNPFTzaJqPbtM84C3zcTPPd+zEUTv/pVVvczob71XVK3nliFA0s09HUg6SyohgAACMQoQIMU4K4wJAQQQ0AgQIGkcCZBEjrYMAZIOkwBJY0mApHG0VQiQdJZUQgABBGIUIECKcVYYEwIIIKARIEDSOBIgiRwJkISQxhgCJI0nAZLGkQBJ50glBBBAIFYBAqRYZ4ZxIYAAAo0LECA1bphVYAmbCJIOJB0kAZLMkgBJRkkHko6SSggggECUAgRIUU4Lg0IAAQQkAgRIEkYCJBHjpjCOPZBknHQgaSgJkDSOtgpL2HSWVEIAAQRiFCBAinFWGBMCCCCgESBA0jjSgSRyJEASQtKBJMMkQJJREiDpKKmEAAIIRClAgBTltDAoBBBAQCJAgCRhpANJxJiVoQNJp0kHksaSAEnjaKvQgaSzpBICCCAQowABUoyzwpgQQAABjQABksaRDiSRIwGSEJIOJBkmAZKMkgBJR0klBBBAIEoBAqQop4VBIYAAAhIBAiQJIx1IIsasDB1IOk06kDSWBEgaR1uFDiSdJZUQQACBGAUIkGKcFcaEAAIIaAQIkDSOdCCJHAmQhJB0IMkwCZBklARIOkoqIYAAAlEKECBFOS0MCgEEEJAIECBJGOlAEjFmZehA0mnSgaSxJEDSONoqdCDpLKmEAAIIxChAgBTjrDAmBBBAQCNAgKRxpANJ5EiAJISkA0mGSYAkoyRA0lFSCQEEEIhSgAApymlhUAgggIBEgABJwkgHkogxK0MHkk6TDiSNJQGSxtFWoQNJZ0klBBBAIEYBAqQYZ4UxIYAAAhoBAiSNIx1IIkcCJCEkHUgyTAIkGSUBko6SSggggECUAgRIUU4Lg0IAAQQkAgRIEkY6kESMWRk6kHSadCBpLAmQNI62Ch1IOksqIYAAAjEKECDFOCuMCQEEENAIECBpHOlAEjkSIAkh6UCSYRIgySgJkHSUVEIAAQSiFCBAinJaGBQCCCAgESBAkjDSgSRizMrQgaTTpANJY0mApHG0VehA0llSCQEEEIhRgAApxllhTAgggIBGgABJ40gHksiRAEkISQeSDJMASUZJgKSjpBICCCAQpQABUpTTwqAQQAABiQABkoSRDiQRY1aGDiSdJh1IGksCJI2jrUIHks6SSggggECMAgRIMc4KY0IAAQQ0AgRIGkc6kESOBEhCSDqQZJgESDJKAiQdJZUQQACBKAUIkKKcFgaFAAIISAQIkCSMdCCJGLMydCDpNOlA0lgSIGkcbRU6kHSWVEIAAQRiFCBAinFWGBMCCCCgESBA0jjSgSRyJEASQtKBJMMkQJJREiDpKKmEAAIIRClAgBTltDAoBBBAQCJAgCRhpANJxJiVoQNJp0kHksaSAEnjaKvQgaSzpBICCCAQowABUoyzwpgQQAABjQABksaRDiSRIwGSEJIOJBkmAZKMkgBJR0klBBBAIEoBAqQop4VBIYAAAhIBAiQJIx1IIsasDB1IOk06kDSWBEgaR1uFDiSdJZUQQACBGAUIkGKcFcaEAAIIaAQIkDSOdCCJHAmQhJB0IMkwCZBklARIOkoqIYAAAlEKECBFOS0MCgEEEJAIECBJGOlAEjFmZehA0mnSgaSxJEDSONoqdCDpLKmEAAIIxChAgBTjrDAmBBBAQCNAgKRxpANJ5EiAJISkA0mGSYAkoyRA0lFSCQEEEIhSgAApymlhUAgggIBEgABJwkgHkogxK0MHkk6TDiSNJQGSxtFWoQNJZ0klBBBAIEYBAqQYZ4UxIYAAAhoBAiSNIx1IIkcCJCEkHUgyTAIkGSUBko6SSggggECUAgRIUU4Lg0IAAQQkAgRIEkY6kESMWRk6kHSadCBpLAmQNI62Ch1IOksqIYAAAjEKECDFOCuMCQEEENAIECBpHOlAEjkSIAkh6UCSYRIgySgJkHSUVEIAAQSiFCBAinJaGBQCCCAgESBAkjDSgSRizMrQgaTTpANJY0mApHG0VehA0llSCQEEEIhRgAApxllhTAgggIBGgABJ40gHksiRAEkISQeSDJMASUZJgKSjpBICCCAQpQABUpTTwqAQQAABiQABkoSRDiQRY1aGDiSdJh1IGksCJI2jrUIHks6SSggggECMAgRIMc4KY0IAAQQ0AgRIGkc6kESOBEhCSDqQZJgESDJKAiQdJZUQQACBKAUIkKKcFgaFAALdXWDP0RMmGmMOWL2u36krFk99ayu9H0mAdOyhI80V5x1nmgf0y97GjNmPmq9dPLPiW/r2aYebM0862GzXp3d2zLyFS80RX72qdPydP/mWGTtyj+z3tes2mLMvvdXMunth9rv/WN5zXZFFv/yueXXVmrK64evm1e/sPDT3T8zETzV39uml5339G2ebIUPeU1Zn+fLnzU03Ts2tXev4z487yuy994jsuRs3bjR33TXb/OHJ32W/f2Svj5nDDx9n+vbtm/2+cuVr5uofXbHZ6+y6627mC0cdm/39l7+YZV54Ybk54ICDzH6j9ze9evXK/v7GG2tKjzWK0GgH0r3zW83/vJaak4/pUzaUPyxpN5f9pCX729D3JOY7X+tjdhyY/685f3ql3Xz/2hazdt2mEnnHb9iYmh/e1GKefCbNjjnhyF7mM2M2ndPTbmsxDz7aXvb6/uN2jNPvaMsebx5gzPmn9zH/+PdNZcdXeh/1+Ko6kBr9jIffCT++cLyZMG5U9lbCz7j9m/9Zfbul1fzgxvvM9667q+ytj97ng2bqJSdlf5t0wY1mwePPlj3P/n3FytWlx+pxC49VBkjHHbavufL8L5e+L6ff8bA546LpucO74PTPmbMmHlL6rnQHrVj5N3Pqt6eZyaccavYfOXyz5/5m4RJz+KQrTPhaS5avMPsceWHp+LC+e5474PE7LjbDdxtamqezvv8zc+ucxxqhJEBqSI8nI4AAAvELECDFP0eMEAEEuqHAthIguYu4ZS++moU19sLv9C8fYK792UObXfDZaXIXorPvX5yFTOHv9sJy3EF7l0IjGwQN3KF/dhFof6ace6y58oZ7s0ApfK593A+YwmCq1tgaOY2UAZIdR16Qkzc+GyBVOt6GPPt+Yj/z2G8fNg89dL858aRJZvDgwVnQY39sKLRq1aosnHIhkfvdvZb7+8CBg8pCIltr9eq/ml/N/kV2aLVx1Ova2QDJD4gOHNVUFiDZQOhH01vMN07YFNTYcOYPS9vNN0/sY/r13fxfdWytv6xsLwuEXv9bWjrehUcf2aOpdIz/Pm2AZH/CEMv+zdaeMbu1FGDl/e6CrvB91GupCJAa/Yzbz/Sxh40shUDh59B+Zod9YOeyEKjad4g1cGMaOmTHspDI1vrziv8tBdj2+8P+jPjCRfXSlR2vCpDGjNjDXP+9k82zL76aBTw2wDnj+E+ba25+wFxy7a8LjdGGOq++viZ7fvhjA6NLJ3/R/PS235iHn3i27LXC13bh0h33PZ4FWOHvd00923zwAztnQdX8RUtN+HuhweYcxBK2zsrxPAQQQKB7CBAgdY95YpQIINDNBKoFSMNHT7gsSZJz7FtKTfpSa5oe8tyCmUvs79nzkmSae7vt7e1jlz48c/7uo8cP750kcxOTvD97XppevmTBjHM3e06a3uJ1PTXcgWQvBk85eow574rbs1AnvNgMpyW8ePSPnzJtbtZR4MIo+9xqoU+116rUgVTrwrSzp1GMAZINeZqbm0thlB8ovf6/r2fdR08//YeqIZANhtauXZuxuPDJdiCFP344lfd4Pa6dDZDca+R17oR/CwOlWuMLQ55a3UHVAqQwvKo0llqvUWvM9nFFgFTvZzwMhMLPqX1858GDSqGO/xl/+Ill2XfAg4/+sWoXo/t82/foh0+hSTiWImZ5x6gCJBsYnXLM/ua8KT/POnnCUKfW+MLnh8fbkGfnnQZlXUZhIGSPteGT/bGPh+FVOBb/WPuca757gjny4H1Mo11IBEi1ZpnHEUAAge4tQIDUveeP0SOAQKQClQKkYWOP26l32ue4Z+bPuNoOPQuTjNnFhj4DBqx/f2+TTGlrajlh2bxbX7ehUZ/EfHj1m/3v3nHAhuvb03SqDZOG7j1p+x132HjK6jf7/nTg9uv3SZLk8ramlsPsc/x6KxZPXd+811fK19nU6RV2DNmn1/qv/vbxXXcZnHUk2B8XQNnlJmGAlNdl5IbolrnMmrNws4vNIkvY8pbO1Pn2S4crAyR/CVu15Wv2xcMlbP7xYVeQW7LmQiMb+uy22z+ZxYsXmRdffMF89rOHm0ULH8u6lVxt+7+2G6paQOS6lDZs2FC4c6qa85YIkMJAZ/Ubqfn3H7eYCeN6m48ML186lje2MPQJl6iFy9DCx/3la+61h/ydyTqa5v2/ttwld7EESPV+xvNCG/87Ifx+8D/jjyxeVrYc1s5FuAzNf361gMgFV2+8uT6aDqS8ECYMaqp9Nop2H7luJhso2SVudpmctXXdSe5xW2+3fxhirrxh7qbvYi/ccsvblv95ZRY4VXvter43CZDq0eJYBBBAoPsJECB1vzljxAgg0A0Eii5h22O/8WNcANTU1vtDSVMy3e9Ism/Vhk692vvMSYyZ+syCGTf4b98GRvZ3142UhU4muanFpCfe+6sfrtjrU+etboTLXlweOOpDZfuM1AqQ3AVp3+16Z3t7+EvNwgvCvADJ348lXKbm3ktegBS+T395nN0/pZEfVYDkj8HtM/Tkk4tLXULVxhge77qH3P5JYYDkOpJsTbsPkr8HUti9VClAcgFW7Hsg2UDnfe9JSsvN6gmQwg4ht3ztM6PfCZ9s2PPAo+25+yq5/ZTOGN+nFFbZ8bz0P6l57k9p9Hsg1fsZz+saDAMkf38y/zP+l1WrczsaXQgUdi9VCpDs6+2x63uj2wPJBkif/uSHS8vC7GevaIBUT/eR+55wXUb2d7tHXbgHkgu03HexvweS60jqu10f83c77pDtVdVo99GmcfR/7S+/vXr3JEk2tTbygwACCCCwTQkQIG1T08mbQQCBWASqBUg2NGpqaprnxpqm6ULXQeQvYfP/Hi5hc0vbOjqOlrlgqSNsmt5q0sm/nfuTNbuOOut/GjGptzshXA7jLh4XP/2nbA8lf28TN65am+j6S97qCZDCsTTisCUCJDueMASqNUb/+GodSGHHUdhFlLc5t33tSkFR7EvYOtuBlBf+5AVItQIpP8AKO4vs8rhrZrZstpF2d+1AsudJuNm9/ZsLe6t1IIUBkn2e/x1z1sTPZMFQ+FNps+zYlrB1tgOp1lK3vL2U/P2QbMeRq7Fm7frSEja/48gteXvi6Rez/ZXCjiPbzfTxD3+g4RBpyE4D33jhoSttgLSy1vcZjyOAAAIIdD8BAqTuN2eMGAEEuoFApQAp6zjyuoz8DiS7BM1/a2F3kXvMf06v9j6T7d/zOpCeWzBzaaNL2OrdH6Uz3QzHfHak+frFM7O7LIU/YUcCAdKmPYts11G1PZCs04iR+5p77rmrdFe2aiFQrYDIdjOF9Tr7MdwSS9g6swdSXnjk3lNeR9MPbmgxJx3Ve7O7qdnn+McX7YaKJUCq9zMezrsNha++cLy57Z6F2cb61fZAssulLj37aPPT2+eXNuHP+85wr1ErIFKFxFt7D6Ra+w/ldTHldSz5G2Efc8jIit1Qky+7JduA+4FHni7dIa4zG37nfQewhK2z34w8DwEEEOgeAgRI3WOeGCUCCHQzgaoBkrdnkT0uNWaS7UCyS9js27T7HNn/dQFSW1PLFH/fpGrL3tR7INW6Q1PYYRTuWxQ+7k9j3h3bbAfC5MtmZWFStefmLWGbddXp5qlnXy5dmNZaalfPKaXoQLJLzEbs86/m+uuvzV46vIuaW4L2yisvZwFRreOr3YWteeCgbBNtV6vWPkZhgHTa6d80y55dUrZfUr9+/bI7vMW4iXatu7CFYVGtTbbDriF/j6QNG022r9HnD+qdzWPea/vL3WLvQKr3Mx5+bsLPWa27sIV3Xgz3RfPrhwHSglvON/c9/FTZZ9zdxbGRZaqqAKnWXdjCLiD7XjvTfWSfF9bK60A6a+Ih5ta7Hiu7C5vfgTSouX/ZXdgUHUgESPX8k4VjEUAAge4nQIDU/eaMESOAQDcQCO+mZodsl6StWf/20Tv23+4ykyRf6ngb96Zp+i4bIKXtvQf7d1ozHXdUs8fZTbTdc6reuU18Fzb72v6eRPb3GbMfLW1qnRfy2I6CCeNGlWbJ38fIr5W3dM3tbeKeHO6BFC6d8WuEr1tp2UtnTh9FgORCnIEDB5WGYDe4/tXsX2S/hwFSrePtcz4/7iiz994jsudv3LjR3HXX7FLHkdszqVevXtnj/h5IoUEYIPl17bEx7IFkg5jLftJSNvRzv/rOvkP+40Pfk5TtVxQGSDYQmn5H22angl/PP8av55a4PflMWnq+/zz7R3+T7XAD7lrvo57zU3EXts58xv3Pad4+Zf5nMdzMPlzGuvSFv1TcBDsMkLbUZ1wVIFlLF+zYPYnsj93g+oyLpmf/Py9A8ruG5i9aWjb9RcIlGxLZvebsT94eSCccuV+pZt4eSEOHvCt7XLUHEgFSPZ9gjkUAAQS6nwABUvebM0aMAAIIFBVIGl3CVvSFtvXjFAHStm5U9P01uoSt6Ov0hONUAVJPsKr2HpUBEpbm+beemrZ7T3fg/SOAAALbqgAB0rY6s7wvBBBAwBgCJNFZQIAkgszu0vS2mfi553UFe3AlAiTN5BMgaRxtFTqQdJZUQgABBGIUIECKcVYYEwIIIKARIEDSOBoCJBEkAZIO0hhDgKThJEDSOBIg6RyphAACCMQqQIAU68wwLgQQQKBxAQKkxg2zCgRIIkgCJB0kAZLMkgBJRkkHko6SSggggECUAgRIUU4Lg0IAAQQkAgRIEkYCJBHjpjCOJWwyTjqQNJQESBpHW4UlbDpLKiGAAAIxChAgxTgrjAkBBBDQCBAgaRzpQBI5EiAJIelAkmESIMkoCZB0lFRCAAEEohQgQIpyWhgUAgggIBEgQJIw0oEkYszK0IGk06QDSWNJgKRxtFXoQNJZUgkBBBCIUYAAKcZZYUwIIICARoAASeNIB5LIkQBJCEkHkgyTAElGSYCko6QSAgggEKUAAVKU08KgEEAAAYkAAZKEkQ4kEWNWhg4knSYdSBpLAiSNo61CB5LOkkoIIIBAjAIESDHOCmNCAAEENAIESBpHOpBEjgRIQkg6kGSYBEgySgIkHSWVEEAAgSgFCJCinBYGhQACCEgECJAkjHQgiRizMnQg6TTpQNJYEiBpHG0VOpB0llRCAAEEYhQgQIpxVhgTAgggoBEgQNI40oEkciRAEkLSgSTDJECSURIg6SiphAACCEQpQIAU5bQwKAQQQEAiQIAkYaQDScSYlaEDSadJB5LGkgBJ42ir0IGks6QSAgggEKMAAVKMs8KYEEAAAY0AAZLGkQ4kkSMBkhCSDiQZJgGSjJIASUdJJQQQQCBKAQKkKKeFQSGAAAISAQIkCSMdSCLGrAwdSDpNOpA0lgRIGkdbhQ4knSWVEEAAgRgFCJBinBXGhAACCGgECJA0jnQgiRwJkISQdCDJMAmQZJQESDpKKiGAAAJRChAgRTktDAoBBBCQCBAgSRjpQBIxZmXoQNJp0oGksSRA0jjaKnQg6SyphAACCMQoQIAU46wwJgQQQEAjQICkcaQDSeRIgCSEpANJhkmAJKMkQNJRUgkBBBCIUoAAKcppYVAIIICARIAAScJIB5KIMStDB5JOkw4kjSUBksbRVqEDSWdJJQQQQCBGAQKkGGeFMSGAAAIaAQIkjSMdSCJHAiQhJB1IMkwCJBklAZKOkkoIIIBAlAIESFFOC4NCAAEEJAIESBJGOpBEjFkZOpB0mnQgaSwJkDSOtgodSDpLKiGAAAIxChAgxTgrjAkBBBDQCBAgaRzpQBI5EiAJIelAkmESIMkoCZB0lFRCAAEEohQgQIpyWhgUAgggIBEgQJIw0oEkYszK0IGk06QDSWNJgKRxtFXoQNJZUgkBBBCIUYAAKcZZYUwIIICARoAASeNIB5LIkQBJCEkHkgyTAElGSYCko6QSAgggEKUAAVKU08KgEEAAAYkAAZKEkQ4kEWNWhg4knSYdSBpLAiSNo61CB5LOkkoIIIBAjAIESDHOCmNCAAEENAIESBpHOpBEjgRIQkg6kGSYBEgySgIkHSWVEEAAgSgFCJCinBYGhQACCEgECJAkjHQgiRizMnQg6TTpQNJYEiBpHG0VOpB0llRCAAEEYhQgQIpxVhgTAgggoBEgQNI40oEkciRAEkLSgSTDJECSURIg6SiphAACCEQpQIAU5bQwKAQQQEAiQIAkYaQDScSYlaEDSadJB5LGkgBJ42ir0IGks6QSAgggEKMAAVKMs8KYEEAAAY0AAZLGkQ4kkSMBkhCSDiQZJgGSjJIASUdJJQQQQCBKAQKkKKeFQSGAAAISAQIkCSMdSCLGrAwdSDpNOpA0lgRIGkdbhQ4knSWVEEAAgRgFCJBinBXGhAACCGgECJA0jnQgiRwJkISQdCDJMAmQZJQESDpKKiGAAAJRChAgRTktDAoBBBCQCBAgSRjpQBIxZmXoQNJp0oGksSRA0jjaKnQg6SyphAACCMQoQIAU46wwJgQQQEAjQICkcaQDSeRIgCSEpANJhkmAJKMkQNJRUgkBBBCIUoAAKcppYVAIIICARIAAScJIB5KIMStDB5JOkw4kjSUBksbRVqEDSWdJJQQQQCBGAQKkGGeFMSGAAAIaAQIkjSMdSCJHAiQhJB1IMkwCJBklAZKOkkoIIIBAlAIESFFOC4NCAAEEJAIESBJGOpBEjFkZOpB0mnQgaSwJkDSOtgodSDpLKiGAAAIxChAgxTgrjAkBBBDQCBAgaRzpQBI5EiAJIelAkmESIMkoCZB0lFRCAAEEohQgQIpyWhgUAgggIBEgQJIwbupAOnFss6hazy4zqHmj+ebxT/ZsBNG7//Nrfczep/6TqFrPLUOApJt7OpB0llRCAAEEYhQgQIpxVhgTAgggoBEgQNI4EiCJHG0ZAiQdJgGSxpIASeNoqxAg6SyphAACCMQoQIAU46wwJgQQQEAjQICkcSRAEjkSIAkhjTEESBpPAiSNIwGSzpFKCCCAQKwCBEixzgzjQgABBBoXIEBq3DCrwBI2ESQdSDpIAiSZJQGSjJIOJB0llRBAAIEoBQiQopwWBoUAAghIBAiQJIwESCLGrAxL2HSadCBpLAmQNI62CkvYdJZUQgABBGIUIECKcVYYEwIIIKARIEDSONKBJHIkQBJC0oEkwyRAklESIOkoqYQAAghEKUCAFOW0MCgEEEBAIkCAJGGkA0nEmJWhA0mnSQeSxpIASeNoq9CBpLOkEgIIIBCjAAFSjLPCERIbGwAAIABJREFUmBBAAAGNAAGSxpEOJJEjAZIQkg4kGSYBkoySAElHSSUEEEAgSgECpCinhUEhgAACEgECJAkjHUgixqwMHUg6TTqQNJYESBpHW4UOJJ0llRBAAIEYBQiQYpwVxoQAAghoBAiQNI50IIkcCZCEkHQgyTAJkGSUBEg6SiohgAACUQoQIEU5LQwKAQQQkAgQIEkY6UASMWZl6EDSadKBpLEkQNI42ip0IOksqYQAAgjEKECAFOOsMCYEEEBAI0CApHGkA0nkSIAkhKQDSYZJgCSjJEDSUVIJAQQQiFKAACnKaWFQCCCAgESAAEnCSAeSiDErQweSTpMOJI0lAZLG0VahA0lnSSUEEEAgRgECpBhnhTEhgAACGgECJI0jHUgiRwIkISQdSDJMAiQZJQGSjpJKCCCAQJQCBEhRTguDQgABBCQCBEgSRjqQRIxZGTqQdJp0IGksCZA0jrYKHUg6SyohgAACMQoQIMU4K4wJAQQQ0AgQIGkc6UASORIgCSHpQJJhEiDJKAmQdJRUQgABBKIUIECKcloYFAIIICARIECSMNKBJGLMytCBpNOkA0ljSYCkcbRV6EDSWVIJAQQQiFGAACnGWWFMCCCAgEaAAEnjSAeSyJEASQhJB5IMkwBJRkmApKOkEgIIIBClAAFSlNPCoBBAAAGJAAGShJEOJBFjVoYOJJ0mHUgaSwIkjaOtQgeSzpJKCCCAQIwCBEgxzgpjQgABBDQCBEgaRzqQRI4ESEJIOpBkmARIMkoCJB0llRBAAIEoBQiQopwWBoUAAghIBAiQJIx0IIkYszJ0IOk06UDSWBIgaRxtFTqQdJZUQgABBGIUIECKcVYYU48XGDb2uJ16tfeZkyTJyFoYaZoubGtqOWzZvFtfr3Usj/c4AQIk0ZQ390/MiWObRdV6dhkCJN38EyBpLAmQNI4ESDpHKiGAAAKxChAgxTozjAsBBBBoXIAAqXHDrAIBkgiSDiQdJEvYZJYESDJKOpB0lFRCAAEEohQgQIpyWhgUAgggIBEgQJIwEiCJGLMydCDpNOlA0lgSIGkcbRWWsOksqYQAAgjEKECAFOOsMCYEEEBAI0CApHGkA0nkSIAkhKQDSYZJgCSjJEDSUVIJAQQQiFKAACnKaWFQCJQLDN170vY7DthwvUmSL6Umfak1TQ9Zt67/S9nfjHnomQUzbsAMgRwBAiTRacESNhEkHUg6SAIkmSUBkoySAElHSSUEEEAgSgECpCinhUEhUC4wfPSEyxJjlq1e12/WoB02TmlN269+bsHMJXvsN35MU5JMWr2u36krFk99CzcEAgECJNEpQYAkgiRA0kESIMksCZBklARIOkoqIYAAAlEKECBFOS0MCoF3BDruyDa91aSTbdeRHyDtPnr88N4mmdLW1HICd2HjrMkRIEASnRYESCJIAiQdJAGSzJIASUZJgKSjpBICCCAQpQABUpTTwqAQKBYg0YHEmVJDgABJdIoQIIkgCZB0kARIMksCJBklAZKOkkoIIIBAlAIESFFOC4NCoFxgz9ETJhpjDmhtavlmr3S7i+0StqSpdVWv9j5zEmOmsgcSZ0wFAQIk0alBgCSCJEDSQRIgySwJkGSUBEg6SiohgAACUQoQIEU5LQwKgc0Fsm6jpqZ5/iPt7e1jlz48cz5eCBAgbdlzgABJ5zuoeaP55vFP6gr24Ep/fq2P2fvUf+rBApq3ToCkcbRV0tQ8/9ZT03bXVaQSAggggEBMAgRIMc0GY0EAAQS0AnQgiTwJkESQdCDpIOlAklkSIMkoCZB0lFRCAAEEohQgQIpyWhgUAgggIBEgQJIwGkOAJIIkQNJBEiDJLAmQZJQESDpKKiGAAAJRChAgRTktDKqnC3TceW1OkiQja1mkabqwranlMO7CVkuqRz5OgCSadgIkESQBkg6SAElmSYAkoyRA0lFSCQEEEIhSgAApymlhUAiUCwwfPeGyxJhl/mbZQ/eetP2OAzZc356mU9kHiTOmggABkujUIEASQRIg6SAJkGSWBEgySgIkHSWVEEAAgSgFCJCinBYGhcA7Ah3dSNNbTTr5uQUzl/g22cbaSTJp9bp+p65YPPUt3LqPgA0F7WiXLJhxbjhq14GWpuk5DYaDBEiiU4IASQRJgKSDJECSWRIgySgJkHSUVEIAAQSiFCBAinJaGBQCxQKk3UePH97bJFPamlpOYAlbPGeN6w4zSfIlN6pwqWF3CpCOPXSkueK840zzgH7Z25kx+1HztYtnVgT/9mmHmzNPOths16d3dsy8hUvNEV+9qnT8nT/5lhk7co/s97XrNpizL73VzLp7Yfb7ol9+1+yx63tLx4bPDWv7Ywmf64rUGm+RM0cVIH3zW2ebIUPeU/aSy5c/b26YNrXqMHbddTdz9DHHZsfcftss88ILy0vH7/XRj5lDP3u4WbjwMfPgg/eX/f2II8aZvn37Zn9bufI188Orrqj4+BNPLDKz7/hF6fGJJ08yu+226Q5fb7yxZrPXLeKWd0yjd2G784Em8/JfEnPGhLay8r97OjEXXtkn+9vfv7fdXPpvreZdgyqP0taZeuumc3TgDqm5ZHKL2fUfNh3/wp+NuWBKH/PGm5v+Nenj/9Juzj2t1fTbRFn6uWZGL7PLe1NzxKfbS38LnxuOxX9d+6RJx7WWPb8eV9Vd2Br9jIefsR9fON5MGDcqeyv+Zzx8Hfde/WO2xmdcGSAdd9i+5srzv1z6vpx+x8PmjIum507rBad/zpw18ZDSd6U7aMXKv5lTvz3NzF+0NPvT43dcbIbvNjT7/0uWrzD7HHlhqZ5f4+2WVnPlDXPNJdf+2hStbY875Zj9zXlTfm5unfNYPadf7rHcha1hQgoggAACUQsQIEU9PQwOAWNKYYQxD/lL2KyN7UBKkuRy9kCK60zJm7OOZYi7FOkWi6kDafQ+HzRTLznJLHvx1SwEshd3p3/5AHPtzx4y37vurs3g3QXi7PsXZyFT+Lu9sBx30N6l0MiGPgN36G8mXXBjVmvKuceaK2+4NwuU3IXkrDkLK9Y69rCR5gc33pc7Fvv8U44eY8674vZSQNXZM0UZINkx+EFOrTG58GjgwEFlQY7/97a2NrNg/m9KAZJ7bNWqVVk4Vev3Aw88yHxi1H7mt48+nNUYd+RR5p//+SPmzjtnmyd//ztjg696x13pfXU2QPIDokPGtpUFSDa0ufwnvc05X23NQiAb0vzuj025oY8dl6019dZepZAp/N0+/+/fm5qPfTjN3oYNiuyPC638ECgMgGytV/6SlEIh+9xVf02ysdifaT/vZb70ubYs3PrbGmPO+4/eZtJxbaXXqnU++I8rAqRGP+P2M+1/DsPvCBsYD/vAztlnfMHjz2729uzjOw8eZEZ84aLc74uu+IyrAqQxI/Yw13/vZPPsi6+awyddkYU4Zxz/aXPNzQ9koU6RHxsWvfr6muz59sf+bn/80MjVqbe+X9sPumyAd9b3f0aAVGSCOAYBBBDo4QIESD38BODtdw+BLChqSqa3pukhbhlbaaNtY6aGwVL3eFfb7ijzAqQw7As7kLJusiSZm5jk/U6mvb19rFvClgVQSXJOSS1Nb3FhVLjpuve8hpewhSFMeLEZzmJ48egfP2Xa3LIwyj63WiAVvlZ4IVprLDacenXVmrLup86edVszQLLhzdq1a7OhDx48uFAHku1Kst1HTz31h1JXkR8C2cBo5Mh9zd333JUFRGHA5F7TdUaFgVJnHe3zOhsgudfM60AK/xYGSuF4w4Cp3uNdvbwOpPC1wnDKf3zDRmMuu663+diH2jvVhaQIkOr9jNf6HPqBUK3PuA2YLz37aPPT2+dnIXCt2qGt6jOuCpDCbp4wUKr1uQmff813TzCf/uSHy7qRXA1X+4FHnq7Y4eS/XqVOIzqQas0KjyOAAAII+AIESJwPCHQTgbw7s/kBQzd5Gz1imJU6kOybd3se+QFSGAaGHUh7jp4wMTVmkus0s78bYw6wAdIOzWu379XeZ07SESQGyxr/t3mvr7yztqYT+mHHkC1hL9rsj+0YyPuxj++6y+CsM8j+uC6gFStXbxYghR1Kfr3wsbxOhkpjUXYf2TEpAyR/CVut5Wt+6GOXlBUNkOyY3RI0uzTtxRdfKFvmlhcIude6685fZcvlXPeSrRV2KHXiVCo9ZUsESGGHUK3OHvf4zoNN1hl0/4L8ZXF20C7kGfzudLNlc0UCpGrdUG652+RJrVutA6nez3itz2H4maz2GQ/Dplq1/fNO+RlXBUg28Dny4H3KunmqdRCFn6Ow++iuqWeb/UcOLzvMLYkLl8rZg8Klb/4Tw9ruMQKkRr7NeC4CCCDQ8wQIkHrenPOOEUBgCwvk7YFk0vRkv1PMD5DC7iQ/QHrjrf6P27vtGW8Jox8gDdx+/T7+Mkb/7nz/dfc1f/zg6P+zqpG3ay8uDxz1obLlJ7UCJHdB2ne73tneHv4+RuEFYrWLy/B18rqVKo1F1Zng7FQBkj8XNpQZPWZ/8/vfLy7be8gdYwOg5ubm0nK3egMkF/rYenYfJH8PJBsgDRv2wbJupjBAWrbs2dK4ukOA5O9FVCtAsiY2/Hnx5cQsXd602R5Ibg7sMXPn9aprDyR/jit1NrnxvfKXpq2+B1K9n/Fan8Pws1fpMx52H1m3WrV9W+VnXBkghR1DRQOkvCAnDH1sQHXc4ftm+xzZH3/vIteRtGbt+s2Wu1ULidQB0rsHDfjrnxf88J+SJPlbI//s4bkIIIAAAnEKECDFOS+MCoHNBLI7rjU1zfMfoAMpzhMl7EDyAx93t7wwQPLvppcXILWn6VS3nC0MkMLzwqrYc+M391z7zLD9Jq9sRKne7oSwK8BdPC5++k/ZUjK37GzokB1Lw7Ibv4b7GPl7I/n7pvgbcLsC4UbbeWNuxMA+d0sESLZuuFTMH2fehtv28XBD67xNtMO/uSVqGzZsyAKpnt6BFC55s8vMpkztXbaRtj8XlbqIqnUgFekuimEJW72fcetS7XNYtAOpUvi7NT7jygCpMx1IlZa6hQGSf9zCJ5/fbPPrvA6oWsvo9AHSDn/984Krdk+S5K+Nfu/yfAQQQACB+AQIkOKbE0aEQG54FG6WXdozJzUXswdSXCdNGCDVWtLWaAeSHz4FEl2+B1JnuhmO+exI8/WLZ5Y22K0UHoWzbMOoqy8cb267Z2FpE+1a+yJ19kzZGgFSONZ6OpDCPY5sLf/5NlDqyXsghcFPrY4lGwZdd3Nvc/4Z5Xd2qxQgFQmP3PxWuqtckXN1a+yBVOtzWGQPpFqb8bvX6KrPuCpA6uweSHnBjzWwS9h23mlQqaPI3/fokcXLzKWTv2h+ettvSht05+2ZVKm2M1YHSNyFrcgnl2MQQACB7itAgNR9546R9xABf0mS60Bxbz3rSkqSSUXu7NVDuKJ4m3mBkQv80vb0BDuPeXsgpWl6jn3MdZu5DjO/48i+wY4lbSZvDyT7uH2+/d+lD89c0OgeSLXu0BR2GFW6c5rrQPInKG9pS63lcf7z847dEt1H9jUVAZLtChox4l/N1P+8Nnsb4bIwt/H1K6+8nN05rZEAKawVdiCFm2Z3h7uwVQtcat2FLQx0bGhzz7ymsruw+R1IN97eZMaMbM/u6GZ//Dup9ev7zszkBUjVNuS2QdUtv+5lTv5im7F1XHD12bFbbxPtej/j4XlZa6lpPfsa1aptH98Sn3FVgFTrLmxu36Innn6xdJe1ah1CNtw5a+Ih5ta7Hss2yg7DINuhNKi5f7bJtv3x7wBnf6/VfWSPIUCK4l8bGAQCCCDQbQQIkLrNVDHQnirQsZxpeqtJJ7s7sDmLYMPk13uqUWzvOy9AsmP0g6EkSQ6xf3ObapctUUzTW1JjdnOBkr+nUmrSl4xJ7jFp+oZ7brjBepqmCzs23G54E207Rhf0NA/ol1HPmP2o+drFM7P/HwZI7gJvwrhRpWnxl5j5tcKla+HruAJ28213C3B7sbrHru/NHgqXrlXbT6nRc0QRILnQZuDAQaXh2A2uZ9/xi+z3egOkvHr+8ja3x9L/b+/O4+Qs6n2P1zNJIBACeGQTFxQOu9cNIYqHgIAgggLKLgkIGAEVFXIPi5pzRQVyXiCCChhACZEdBWV1QSEImGCOG0IIuygiICdANphknvv6PTPVqa55enmmv8Ga9Cf/XJPprq5+13Tf0x/qqR4xov8r6MMzkMLHs/OR7E84F/u7P4Tb/nd82VwnnkM9RNsuM5vyjVF1D33q8b21w6fDn7/hdX21OGR3KNsR5M83sp+vuUZed/la/Fjvfltfcdi2j0cWoKZdMbI2l/D+8c/8jfxcw8e1n006eOmQvoHN7qvYgTSU13iz12H8HmBfEX/C6Ve4K2+aVVC0CkD/ite4KiDZ84sPt/aHXoc/CwOS7TLa/C0blH7Tmt3HotFhH92hsLP3TDv/6Gvn/bj4uw9EG673muLvDzzyVN35R83GLjuEO77/UF7n7EAaihr3QQABBIaPAAFp+KwVM+1SAXYgdenCN3natnspc25eG5cudnwJG/r9AoqAhGW/wFADEn6DBVQBqdttlQEJS/fwoj9dvGm3O/D8EUAAgZVVgIC0sq4sz2ulEoi/xt2eHGcgrVRL3PTJ1NbaZRvZDfM8n+p3H7VQICCJfk0ISCJIApIOUrgDSTqpYTgYAUm3aOxA0lkyEgIIIJCiAAEpxVVhTgiUCPAtbPxaDEGAgDQEtLK7EJBEkAQkHSQBSWZJQJJROgKSzpKREEAAgRQFCEgprgpzQgABBDQCBCSNI5ewiRxtGC5h02FyCZvGkoCkcbRRCEg6S0ZCAAEEUhQgIKW4KswJAQQQ0AgQkDSOBCSRIwFJCMkOJBkmAUlGSUDSUTISAgggkKQAASnJZWFSCCCAgESAgCRh5BBtEWMxDDuQdJrsQNJYEpA0jjYKO5B0loyEAAIIpChAQEpxVZgTApFAfIhy+OPgK9ufAw6BSICAJPqV4AwkESQBSQfJDiSZJQFJRklA0lEyEgIIIJCkAAEpyWVhUggsF9hwm0mrrz1myYXOudva+Np26BAIBQhIot8HApIIkoCkgyQgySwJSDJKApKOkpEQQACBJAUISEkuC5NCYLnAZjsdvM6IvlHTl7p88kMzZzyADQIVBAhIFbCa3ZSAJIIkIOkgCUgySwKSjJKApKNkJAQQQCBJAQJSksvCpBBYLuB3IPXl+bS5d864AxsEKggQkCpgEZBEWC2G4QwknTNnIGksCUgaRxuFM5B0loyEAAIIpChAQEpxVZgTApHAVuMnHuGc22X+wtGffGrOtEUAIdCmAAGpTahWN2MHUiuh9n9OQGrfqtUtCUithNr7OQGpPad2bkVAakeJ2yCAAALDV4CANHzXjpl3kQCHaHfRYmufKgFJ5ElAEkFyCZsOkkvYZJYEJBklO5B0lIyEAAIIJClAQEpyWZgUAssFOESb34YOBAhIHeCFdyUgiSAJSDpIApLMkoAkoyQg6SgZCQEEEEhSgICU5LIwKQSWC3CINr8NHQgQkDrAIyCJ8KJhuIRN58olbBpLApLG0UbhEjadJSMhgAACKQoQkFJcFeaEQCDAIdr8OnQgQEDqAI+AJMIjIK0YSHYgyVwJSDJKApKOkpEQQACBJAUISEkuC5NCoF6AQ7T5jRiiAAFpiHDx3biETQTJJWw6SAKSzJKAJKMkIOkoGQkBBBBIUoCAlOSyMCkElgsMXMJ2Y5Zl48pc8jyftaynd695t1/xHG4IRAIEJNGvBAFJBElA0kESkGSWBCQZJQFJR8lICCCAQJICBKQkl4VJIYAAAhIBApKE0TkCkgiSgKSDJCDJLAlIMkoCko6SkRBAAIEkBQhISS4Lk0IAAQQkAgQkCSMBScRYDMMh2jpNDtHWWBKQNI42Codo6ywZCQEEEEhRgICU4qowJwQQQEAjQEDSOLIDSeRIQBJCsgNJhklAklESkHSUjIQAAggkKUBASnJZmBQCCCAgESAgSRjZgSRiLIZhB5JOkx1IGksCksbRRmEHks6SkRBAAIEUBQhIKa4Kc0IAAQQ0AgQkjSM7kESOBCQhJDuQZJgEJBklAUlHyUgIIIBAkgIEpCSXhUkhgAACEgECkoSRHUgixmIYdiDpNNmBpLEkIGkcbRR2IOksGQkBBBBIUYCAlOKqMCcEEEBAI0BA0jiyA0nkSEASQrIDSYZJQJJREpB0lIyEAAIIJClAQEpyWZgUAgggIBEgIEkY2YEkYiyGYQeSTpMdSBpLApLG0UZhB5LOkpEQQACBFAUISCmuCnNCAAEENAIEJI0jO5BEjgQkISQ7kGSYBCQZJQFJR8lICCCAQJICBKQkl4VJIYAAAhIBApKEkR1IIsZiGHYg6TTZgaSxJCBpHG0UdiDpLBkJAQQQSFGAgJTiqjAnBBBAQCNAQNI4sgNJ5EhAEkKyA0mGSUCSURKQdJSMhAACCCQpQEBKclmYFAIIICARICBJGNmBJGIshmEHkk6THUgaSwKSxtFGYQeSzpKREEAAgRQFCEgprgpzQgABBDQCBCSNIzuQRI4EJCEkO5BkmAQkGSUBSUfJSAgggECSAgSkJJeFSSGAAAISAQKShJEdSCLGYhh2IOk02YGksSQgaRxtFHYg6SwZCQEEEEhRgICU4qowJwQQQEAjQEDSOLIDSeRIQBJCsgNJhklAklESkHSUjIQAAggkKUBASnJZmBQCCCAgESAgSRjZgSRiLIZhB5JOkx1IGksCksbRRmEHks6SkRBAAIEUBQhIKa4Kc0IAAQQ0AgQkjSM7kESOBCQhJDuQZJgEJBklAUlHyUgIIIBAkgIEpCSXhUkhgAACEgECkoSRHUgixmIYdiDpNNmBpLEkIGkcbRR2IOksGQkBBBBIUYCAlOKqMCcEEEBAI0BA0jiyA0nkSEASQrIDSYZJQJJREpB0lIyEAAIIJClAQEpyWZgUAgggIBEgIEkY2YEkYiyGYQeSTpMdSBpLApLG0UZhB5LOkpEQQACBFAUISCmuCnNCAAEENAIEJI1jsQPpiJ3Hikbr7mHGjnnFHbH3w92NIHr2f312hBv/+deJRuveYQhIurUnIOksGQkBBBBIUYCAlOKqMCcEEEBAI0BA0jgSkESONgwBSYdJQNJYEpA0jjYKAUlnyUgIIIBAigIEpBRXhTkhgAACGgECksaRgCRyJCAJIZ1zBCSNJwFJ40hA0jkyEgIIIJCqAAEp1ZVhXggggEDnAgSkzg2LEbiETQTJDiQdJAFJZklAklGyA0lHyUgIIIBAkgIEpCSXhUkhgAACEgECkoSRgCRi7I9xnIEk42QHkoaSgKRxtFG4hE1nyUgIIIBAigIEpBRXhTkhgAACGgECksaRHUgiRwKSEJIdSDJMApKMkoCko2QkBBBAIEkBAlKSy8KkEEAAAYkAAUnCyA4kEWMxDDuQdJrsQNJYEpA0jjYKO5B0loyEAAIIpChAQEpxVZgTAgggoBEgIGkc2YEkciQgCSHZgSTDJCDJKAlIOkpGQgABBJIUICAluSxMCgEEEJAIEJAkjOxAEjEWw7ADSafJDiSNJQFJ42ijsANJZ8lICCCAQIoCBKQUV4U5IYAAAhoBApLGkR1IIkcCkhCSHUgyTAKSjJKApKNkJAQQQCBJAQJSksvCpBBAAAGJAAFJwsgOJBFjMQw7kHSa7EDSWBKQNI42CjuQdJaMhAACCKQoQEBKcVWYEwIIIKARICBpHNmBJHIkIAkh2YEkwyQgySgJSDpKRkIAAQSSFCAgJbksTAoBBBCQCBCQJIzsQBIxFsOwA0mnyQ4kjSUBSeNoo7ADSWfJSAgggECKAgSkFFeFOSGAAAIaAQKSxpEdSCJHApIQkh1IMkwCkoySgKSjZCQEEEAgSQECUpLLwqQQQAABiQABScLIDiQRYzEMO5B0muxA0lgSkDSONgo7kHSWjIQAAgikKEBASnFVmBMCCCCgESAgaRzZgSRyJCAJIdmBJMMkIMkoCUg6SkZCAAEEkhQgICW5LEwKAQQQkAgQkCSM7EASMRbDsANJp8kOJI0lAUnjaKOwA0lnyUgIIIBAigIEpBRXhTkhgAACGgECksaRHUgiRwKSEJIdSDJMApKMkoCko2QkBBBAIEkBAlKSy8KkEEAAAYkAAUnCyA4kEWMxDDuQdJrsQNJYEpA0jjYKO5B0loyEAAIIpChAQEpxVZgTAgggoBEgIGkc2YEkciQgCSHZgSTDJCDJKAlIOkpGQgABBJIUICAluSxMCgEEEJAIEJAkjOxAEjEWw7ADSafJDiSNJQFJ42ijsANJZ8lICCCAQIoCBKQUV4U5IYAAAhoBApLGkR1IIkcCkhCSHUgyTAKSjJKApKNkJAQQQCBJAQJSksvCpBBAAAGJAAFJwsgOJBFjMQw7kHSa7EDSWBKQNI42CjuQdJaMhAACCKQoQEBKcVWYEwIIIKARICBpHNmBJHIkIAkh2YEkwyQgySgJSDpKRkIAAQSSFCAgJbksTAoBBBCQCBCQJIzsQBIxFsOwA0mnyQ4kjSUBSeNoo7ADSWfJSAgggECKAgSkFFeFOSGAAAIaAQKSxpEdSCJHApIQkh1IMkwCkoySgKSjZCQEEEAgSQECUpLLwqQQQAABiQABScLIDiQRYzEMO5B0muxA0lgSkDSONgo7kHSWjIQAAgikKEBASnFVmBMCCCCgESAgaRzZgSRyJCAJIdmBJMMkIMkoCUg6SkZCAAEEkhQgICW5LEwKAQQQkAgQkCSM7EASMRbDsANJp8kOJI0lAUnjaKOwA0lnyUgIIIBAigIEpBRXhTkhgAACGgECksaRHUgiRwKSEJIdSDJMApKMkoCko2QkBBBAIEkBAlKSy8KkEEAAAYkAAUnCyA4kEWMxDDuQdJrsQNJYEpA0jjYKO5B0loyEAAIIpChAQEpxVZgTAgggoBEgIGkc2YEkciSQGTzpAAAgAElEQVQgCSHZgSTDJCDJKAlIOkpGQgABBJIUICAluSxMCgEEEJAIEJAkjOxAEjEWw7ADSafJDiSNJQFJ42ijsANJZ8lICCCAQIoCBKQUV4U5IYAAAhoBApLGkR1IIkcCkhCSHUgyTAKSjJKApKNkJAQQQCBJAQJSksvCpBBAAAGJAAFJwsgOJBFjMQw7kHSa7EDSWBKQNI42CjuQdJaMhAACCKQoQEBKcVWYEwIIIKARICBpHNmBJHIkIAkh2YEkwyQgySgJSDpKRkIAAQSSFCAgJbksTAoBBP4VApuOn7DlKJdd0uvywx+aOeMB1Ry2HD/xDBvrgZmXnqQas81xCEhtQrW62djVMnfEzmNb3YyftyHADqQ2kNq8CTuQ2oRqcTMCksbRRmEHks6SkRBAAIEUBQhIKa4Kc0IAgRUmsMUOE3bs6em5fdAD5PmRvS6/p9OAVBah2glIG24zafW1xyy50GXZIX19fTvNvXPGHTbHYr5ZNmn+wtGffGrOtEWNYDbb6eB1RvSNujHP8xP9fZ1zkoB00J7j3FknH+zGjhldPPyl193lPnPqjIZr9MVjPuy+8Ind3SqjRha3uX3WXPeRo79Zu/1PLvi822ncFsXfX1q4xJ1w+hXuyptmFX8Pf1Z2Xz/I7B/+l3v62Rfqxo0ft2z8of5iqQLSZ487wa233vp103jkkYfdJd+fVjq1VrffZ9/93DbbbFfc9+WXX3Y33HCd+8Pv/6f4+9vf8S734Q/v61ZdddXi78888w/3rXPPGvQ4G2+8ifvYfgcV//7Da690jz76iNtll93cDuPf70aMGFH8+4svvlD72VAN/f06DUi33rHU/e0fuTvygFF1U/nDA33ujAt6i3/bcP3Mffkzo9zaa5b/nzmP/7XPnXZer3tpYf8QZbdf8nLuzrmk1/3+/ry4zWEfHeE+uGP/7/TFV/e6X9zVV/f44c9tjtN/tKz4+dgxzp1y7Cj35jf01N2+0fOo4qsKSJ2+xuP3hG9PmeAm7vu+4qnEr3H7t/C1+krvUnf293/qvn7+DXVPffy2m7tpX/tE8W+TvvR9N/PeB+vuZ//+1DPzaz+r4hbfVhmQDt7rve4bp3y89n45/Ud3uk9/ZXrp9L507N7u+CP2qL1X+hs99cz/uk9+8WI3+ag93fvHbTnovr+a9YD78KSzXPxYDzzylNv2o1Nqt4/H9/fzN7j3R6e6LTfZsLZOx592mbvixns6oSQgdaTHnRFAAIH0BQhI6a8RM0QAAaGABZksy6Yu6+nda97tVzwXDq3YgTTUMXxAyp17MnPujT4Y/asDkv8QN++xp4tYYx/8jv34Lu68y24b9IHPLP0H0et+NqeITPHf7YPlvrttU4tGFoLWXGO14kOg/TnzpIPcN753axGU4vvaz8PAFIepVnPr5NdIGZBsHmUhp2x+FpAa3d4iz3u338Hdc/ed7rbbfuYO/8Qkt+666xahx/5YFHr22WeLOOUjkf+7fyz/72uuuVZdJLKx5s9/3l1/3bXFTZvNo6rrUANSGIh2fV9PXUCyIHTu9F533GH9ocbizB/m9rnPHT7KjV518P+pY2P9/Zm+uiD03P/mtdv7ePT2LXpqtwmfpwUk+xNHLPs3G/vS65bWAlbZ333oip9HVUtFQOr0NW6v6YP2GleLQPHr0F6zm71lg7oI1Ow9xAz8nDZcb+26SGRj/eWpf9YCtr1/2J/tPvaVqnR1t1cFpB2328Jd+PUj3YOPPV0EHgs4nz70A+47P/i5+9p5P25rjhZ1nn7uheL+8R8LRqdPPtBddPWv3J2/fbDuseLH9nHpRz+9twhY8d9vmHaC2/wtGxSh6o7Zc13897YmW3IjdiANVY77IYAAAsNDgIA0PNaJWSKAgEigSkCyGDQyy27JXLaRPXye51P9ZWh+x0+WZeOKqeX55U8+445743ruXNtF5Kdru4myLNvD/t7kvkfOXzj6StuBlLv8ssxlH+/L82m2kygOSOFOpYHHPfL+mZd+z3Y5ZVl2Yo0pz+3fvz/2HZ+q3yZR0dE+DB61/47u5LOuKaJO/GEzHi7+8Bje/syLbyl2FPgYZfdtFn2aPVajHUitPphWfPq1m6cYkCzyjB07thajwqD03D+fK3Yf3XffH5pGIAtDL730UvE8fXyyHUjxnzBOlf28iutQA5J/jLKdO/G/xUGp1fziyNNqd1CzgBTHq0ZzafUYreZsP1cEpKqv8TgIxa9T+/kG665Vizrha/zO384r3gN+cdefm+5i9K9ve45hfIpN4rm0Y1Z2G1VAsmB01AHvdyefeVWxkyeOOq3mF98/vr1Fng3WWavYZRQHIbutxSf7Yz+P41U8l/C2dp/v/Ndh7qO7b+s63YVEQGq1yvwcAQQQGN4CBKThvX7MHgEEKgpUCUhb7Thh/97c3WfnIfmYlPflh1nYKYKNc/Ms3tgUttpx4meXZr1X5H0j140vgwsvYauFJ+em2X2LILTG4j3nL1jtJgtIFo5sPH/Z2pqrL97W/2/79/7I5J60GDUw1vSlLp+c9Sx9dkVcwhbvGLI5tPqv/vbzjd+4brEjwf74AGWXm8QBqWyXkV9Sf5nLlTfOGvRhs51L2Mounan461K7uTIghZewNbt8zR48voQtvH28K8hfsuajkUWfTTb5dzdnzmz32GOPug996MNu9qx7it1Kfmz7f203VLNA5HcpLVmypO2dU82cV0RAioPO/Bdz99Vv97qJ+450b9+y/tKxsrnF0Se+RC2+DC3+eXj5mn/s9V7rih1Nt/9mWekld6kEpKqv8bJoE74nxO8P4Wv813Pm1V0Oa2sRX4YW3r9ZIPLh6sUFi5PZgVQWYeJQ0+y10e7uI7+byYKSXeJml8mZrd+d5H9u423ypvXcN753S/97cRC3/OVtj/zlmSI4NXvsKu+bBKQqWtwWAQQQGH4CBKTht2bMGAEEOhAY6hlItZ0/zt22fLdQf8gJp9PqDKRGAcuPbwHpxUWr3VsWk8aMWbxRWZyykLW0p/cncUB6duHCDTd+3/F/64DL2YfLXd+3dd05I60Ckv9AuuoqI4uzPcJLzeIPhGUBKTyPJb5MzT+XsoAUP8/w8jg7P6WTP6qAFM7BnzP0+9/Pqe0SajbH+PZ+95A/PykOSH5Hko1p5yCFZyDFu5caBSQfsFI/A8mCzuvXz2qXm1UJSPEOIX/52gfHL49PFnt+fldf6blK/jylT08YVYtVNp8n/pa7hx7Pkz8DqeprvGzXYByQwvPJwtf435+dX7qj0UegePdSo4Bkj7fFxq9L7gwkC0gf+I+31i4Ls9deuwGpyu4j/z7hdxnZ3+2MuvgMJB+0/HtxeAaS35G06iqj3GvXXqM4q6rT3Uc2j/Vfu9ZLj/zyrH/PsuyZTt5zuS8CCCCAQJoCBKQ014VZIYDAChKosgNp0OViNqf+S8O+V3IJW/Hv7QSkskOxw4AUXrrmL2mzM5EsIIWX1NWI8vzIsoD0yPPPr/WOnU+e3wll1d0J8eUw/sPjnPseL85QCs828fNqdYhueMlblYAUz6UThxURkGw+cQRqNcfw9s12IMU7juJdRGWHc9tjNwpFqV/CNtQdSGXxpywgtQpSYcCKdxbZ5XHfmdE76CDt4boDyX5P4sPu7d987G22AykOSHa/8D3m+CM+WISh+E+jw7JTu4RtqDuQWl3qVnaWUngeku048mO88NLi2iVs4Y4jf8nbb+97rDhfKd5xZLuZ3v3Wt3QckcaOWe0ff7/7WxaQFrR6P+PnCCCAAALDT4CANPzWjBkjgEAHAu0GpIULV3sivFws3IHkL1vz0wijkf1bs0vY2tmBZAGp7FDtIiC57MxlPb2HxQeAr6hvYat6PspQdjMc8KFx7rOnzii+ZSn+E+9IICD1n1lku46anYFkTtuNe6+7+eYbat/K1iwCtQpEtpspHm+oL8MVcQnbUM5AKotH/jmV7Wg6+3u97hP7jRz0bWp2n/D27e6GSiUgVX2Nx+tuUfhbUya4q2+eVRys3+wMJLtc6vQT9ncXXXNH7RD+svcM/xitApEqEv+rz0Bqdf5Q2S6msh1L4UHYB+wxruFuqMlnXF4cwP3zX99X+4a4oRz4XfYewCVsQ31n5H4IIIDA8BAgIA2PdWKWCCAgEqgakJxzt9XtOHJuWnEJ2xovHzV/waoXPTVn2qIwIJWdRdTsDCQLPyPzUQfPXzD6Yn/ZmgUke7q1y+3y/HLbgWT/FkYt+3vx2Jl7qz9Dyc93gCvr9BDtVt/QFO8wis8tin8eLmPZN7bZDoTJZ1xZxKRm9y27hO3Kbx7r/vTgk7UPpq0utavyK6XYgWSXmG237XvchReeVzx0/C1q/hK0v/71ySIQtbp9s29hG7vmWsUh2n6sVucYxQHpmGM/5+Y9+EDdeUmjR48uvuEtxUO0W30LWxyLWh2yHe8aCs9IWvKyK8412me3kcU6lj12eLlb6juQqr7G49dN/Dpr9S1s8TcvxueihePHAWnm5ae4n975p7rXuP8Wx04uU1UFpFbfwhbvArLnOpTdR3a/eKyyHUjHH7GHu+KGe+q+hS3cgbTW2NXqvoVNsQOJgFTl/2fhtggggMDwEyAgDb81Y8YIINCBQJUzkMLb5i5/IsvdP5xz3y371jP7tjUffrYaP/EIl2UX2zTLvoUt/nY3uyzOn6vkv33N7hvsenIWkCxWxZfV2byW5vkedtB33XMTfQubzSM8k8j+ful1d9UOtS6LPLajYOK+76utUniOUThW2aVr/mwTf+f4DKT40plwjPhxG132MpRfH0VA8hFnzTXXqk3BDri+/rpri7/HAanV7e0+++y7n9tmm+2K+7/88svuhhuuq+048mcmjRgxovh5eAZSbBAHpHBcu20KZyBZiDnjgt66qZ909PJzh8Kfb7h+VndeURyQLAhN/9GyQb8K4XjhbcLx/CVuv78/r90/vJ/9Y3jIdnwAd6vnUeX3U/EtbEN5jYev07JzysLXYnyYfXwZ69xH/97wEOw4IK2o17gqIJmlDzt2JpH9sQOuP/2V6cX/LgtI4a6hO2bPrVv+duKSRSI7a87+lJ2BdNhHd6iNWXYG0obrvab4ueoMJAJSlVcwt0UAAQSGnwABafitGTNGAAEE2hXoeAdSuw+0st9OEZBWdqN2n1+nl7C1+zjdcDtVQOoGq2bPURmQsHQPL/rTxZt2uwPPHwEEEFhZBQhIK+vK8rwQQAAB5whIot8CApIIsvi2qFfcEXs/rBuwi0ciIGkWn4CkcbRR2IGks2QkBBBAIEUBAlKKq8KcEEAAAY0AAUnj6AhIIkgCkg7SOUdA0nASkDSOBCSdIyMhgAACqQoQkFJdGeaFAAIIdC5AQOrcsBiBgCSCJCDpIAlIMksCkoySHUg6SkZCAAEEkhQgICW5LEwKAQQQkAgQkCSMBCQRY3+M4xI2GSc7kDSUBCSNo43CJWw6S0ZCAAEEUhQgIKW4KswJAQQQ0AgQkDSO7EASORKQhJDsQJJhEpBklAQkHSUjIYAAAkkKEJCSXBYmhQACCEgECEgSRnYgiRiLYdiBpNNkB5LGkoCkcbRR2IGks2QkBBBAIEUBAlKKq8KcEEAAAY0AAUnjyA4kkSMBSQjJDiQZJgFJRklA0lEyEgIIIJCkAAEpyWVhUggggIBEgIAkYWQHkoixGIYdSDpNdiBpLAlIGkcbhR1IOktGQgABBFIUICCluCrMCQEEENAIEJA0juxAEjkSkISQ7ECSYRKQZJQEJB0lIyGAAAJJChCQklwWJoUAAghIBAhIEkZ2IIkYi2HYgaTTZAeSxpKApHG0UdiBpLNkJAQQQCBFAQJSiqvCnBBAAAGNAAFJ48gOJJEjAUkIyQ4kGSYBSUZJQNJRMhICCCCQpAABKcllYVIIIICARICAJGFkB5KIsRiGHUg6TXYgaSwJSBpHG4UdSDpLRkIAAQRSFCAgpbgqzAkBBBDQCBCQNI7sQBI5EpCEkOxAkmESkGSUBCQdJSMhgAACSQoQkJJcFiaFAAIISAQISBJGdiCJGIth2IGk02QHksaSgKRxtFHYgaSzZCQEEEAgRQECUoqrwpwQQAABjQABSePIDiSRIwFJCMkOJBkmAUlGSUDSUTISAgggkKQAASnJZWFSCCCAgESAgCRhZAeSiLEYhh1IOk12IGksCUgaRxuFHUg6S0ZCAAEEUhQgIKW4KswJAQQQ0AgQkDSO7EASORKQhJDsQJJhEpBklAQkHSUjIYAAAkkKEJCSXBYmhQACCEgECEgSRnYgiRiLYdiBpNNkB5LGkoCkcbRR2IGks2QkBBBAIEUBAlKKq8KcEEAAAY0AAUnjyA4kkSMBSQjJDiQZJgFJRklA0lEyEgIIIJCkAAEpyWVhUggggIBEgIAkYWQHkoixGIYdSDpNdiBpLAlIGkcbhR1IOktGQgABBFIUICCluCrMCQEEENAIEJA0juxAEjkSkISQ7ECSYRKQZJQEJB0lIyGAAAJJChCQklwWJoUAAghIBAhIEkZ2IIkYi2HYgaTTZAeSxpKApHG0UdiBpLNkJAQQQCBFAQJSiqvCnBBAAAGNAAFJ48gOJJEjAUkIyQ4kGSYBSUZJQNJRMhICCCCQpAABKcllYVIIIICARICAJGFkB5KIsRiGHUg6TXYgaSwJSBpHG4UdSDpLRkIAAQRSFCAgpbgqzAkBBBDQCBCQNI7sQBI5EpCEkOxAkmESkGSUBCQdJSMhgAACSQoQkJJcFiaFAAIISAQISBJGdiCJGIth2IGk02QHksaSgKRxtFHYgaSzZCQEEEAgRQECUoqrwpwQQAABjQABSePIDiSRIwFJCMkOJBkmAUlGSUDSUTISAgggkKQAASnJZWFSCCCAgESAgCRhZAeSiLEYhh1IOk12IGksCUgaRxuFHUg6S0ZCAAEEUhQgIKW4KswJAQQQ0AgQkDSO7EASORKQhJDsQJJhEpBklAQkHSUjIYAAAkkKEJCSXBYmhQACCEgECEgSRnYgiRiLYdiBpNNkB5LGkoCkcbRR2IGks2QkBBBAIEUBAlKKq8KcEEAAAY0AAUnjyA4kkSMBSQjJDiQZJgFJRklA0lEyEgIIIJCkAAEpyWVhUggggIBEgIAkYWQHkoixGIYdSDpNdiBpLAlIGkcbhR1IOktGQgABBFIUICCluCrMCQEEENAIEJA0juxAEjkSkISQ7ECSYRKQZJQEJB0lIyGAAAJJChCQklwWJoUAAghIBAhIEkZ2IIkYi2HYgaTTZAeSxpKApHG0UdiBpLNkJAQQQCBFAQJSiqvCnBBAAAGNAAFJ48gOJJEjAUkIyQ4kGSYBSUZJQNJRMhICCCCQpAABKcllYVIIIICARICAJGFkB5KIsRiGHUg6TXYgaSwJSBpHG4UdSDpLRkIAAQRSFCAgpbgqzAkBBBDQCGRrvvOYPs1Q3T1KX98yt3jx892NIHr2q4wc4d7xpnVFo3X3MK8sy93Dz/ES7/S3IHd5p0Nw/+UCD7/4uws2BQQBBBBAYOUUICCtnOvKs0IAAQRMgIAk+j0gIIkgnXMEJJ0lAUljSUDSOA6MQkCScjIYAgggkJYAASmt9WA2CCCAgFKAgCTSJCCJIAlIOkjnHAFJw0lA0jgSkKSODIYAAggkKUBASnJZmBQCCCAgESAgSRidIyCJIAlIOkgCksySgCSjtIHYgSTlZDAEEEAgLQECUlrrwWwQQAABpQABSaRJQBJBEpB0kAQkmSUBSUZJQJJSMhgCCCCQngABKb01YUYIIICASoCAJJIkIIkgCUg6SAKSzJKAJKMkIEkpGQwBBBBIT4CAlN6aMCMEEEBAJUBAEkkSkESQBCQdJAFJZklAklESkKSUDIYAAgikJ0BASm9NmBECCCCgEiAgiSQJSCJIApIOkoAksyQgySgJSFJKBkMAAQTSEyAgpbcmzAgBBBBQCRCQRJIEJBEkAUkHSUCSWRKQZJQEJCklgyGAAALpCRCQ0lsTZoQAAgioBAhIIkkCkgiSgKSDJCDJLAlIMkoCkpSSwRBAAIH0BAhI6a0JM0IAAQRUAgQkkSQBSQRJQNJBEpBklgQkGSUBSUrJYAgggEB6AgSk9NaEGSGAAAIqAQKSSJKAJIIkIOkgCUgySwKSjJKAJKVkMAQQQCA9AQJSemvCjBBAAAGVAAFJJElAEkESkHSQBCSZJQFJRklAklIyGAIIIJCeAAEpvTVhRggggIBKgIAkkiQgiSAJSDpIApLMkoAkoyQgSSkZDAEEEEhPgICU3powIwQQQEAlQEASSRKQRJAEJB0kAUlmSUCSURKQpJQMhgACCKQnQEBKb02YEQIIIKASICCJJAlIIkgCkg6SgCSzJCDJKAlIUkoGQwABBNITICCltybMCAEEEFAJEJBEkgQkESQBSQdJQJJZEpBklAQkKSWDIYAAAukJEJDSWxNmhAACCKgECEgiSQKSCJKApIMkIMksCUgySgKSlJLBEEAAgfQECEjprQkzQgABBFQCBCSRJAFJBElA0kESkGSWBCQZJQFJSslgCCCAQHoCBKT01oQZIYAAAioBApJIkoAkgiQg6SAJSDJLApKMkoAkpWQwBBBAID0BAlJ6a8KMEEAAAZUAAUkkSUASQRKQdJAEJJklAUlGSUCSUjIYAgggkJ4AASm9NWFGCCCAgEqAgCSSJCCJIAlIOkgCksySgCSjJCBJKRkMAQQQSE+AgJTemjAjBBBAQCVAQBJJEpBEkAQkHSQBSWZJQJJREpCklAyGAAIIpCdAQEpvTZgRAgggoBIgIIkkCUgiSAKSDpKAJLMkIMkoCUhSSgZDAAEE0hMgIKW3JswIAQQQUAkQkESSBCQRJAFJB0lAklkSkGSUBCQpJYMhgAAC6QkQkNJbE2aEAAIIqAQISCJJApIIkoCkgyQgySwJSDJKApKUksEQQACB9AQISOmtCTNCAAEEVAIEJJEkAUkESUDSQRKQZJYEJBklAUlKyWAIIIBAegIEpPTWhBkhgAACKgECkkiSgCSCJCDpIAlIMksCkoySgCSlZDAEEEAgPQECUnprwowQQAABlQABSSRJQBJBEpB0kAQkmSUBSUZJQJJSMhgCCCCQngABKb01YUYIIICASoCAJJIkIIkgCUg6SAKSzJKAJKMkIEkpGQwBBBBIT4CAlN6aMCMEEEBAJUBAEkkSkESQBCQdJAFJZklAklESkKSUDIYAAgikJ0BASm9NmBECCCCgEiAgiSQJSCJIApIOkoAksyQgySgJSFJKBkMAAQTSEyAgpbcmzAgBBBBQCRCQRJIEJBEkAUkHSUCSWRKQZJQEJCklgyGAAALpCRCQ0lsTZoQAAgioBAhIIkkCkgiSgKSDJCDJLAlIMkoCkpSSwRBAAIH0BAhI6a0JM0IAAQRUAgQkkSQBSQRJQNJBEpBklgQkGSUBSUrJYAgggEB6AgSk9NaEGSGAAAIqAQKSSJKAJIIkIOkgCUgySwKSjJKAJKVkMAQQQCA9AQJSemvCjBDoeoEtdpiwY5ZlU5f19O417/Yrnut6kKEDEJCGbld3TwKSCJKApIMkIMksCUgySgKSlJLBEEAAgfQECEjprQkzQiBJgc12OnidEX2jbsyybFxtgnl++fyFoz/51Jxpi5STXlEBacNtJq2+9pglF7osOyScb57nUx+YeelJyufQaKytxk88wjm3S+hW/FuWXRzep6+vb6e5d864o8M5SQLSgXtu58466SA3dszoYjqXXn+3++ypP2g4tVOO2ct94fDd3CqjRja8/axrv+y22Ph1xc/nPvp3N26/r9aN9+MLjnMbrLPWoH8P7+fvcPvsuW7vo88t/mr322m7LYr//dQz892nvnyJm3nvvA4ZnVMFpI/vPd59+7+OcmPHrFbM6XvX3OYmfemC0vm9/z1vdZf892fd69f/t9rPw9v/v+MOdP85aZ+a80sLF7vPfOUid9mPZxa3jx/r/of/6t625xfqHmva1452R+y/S/Fv8f3jx7/tnj+53Q8/tWPLVUaOcO9407odjbPN2zdzUyZPcOuus3ZtnBt+eo87/ZuXtxzX39dueOqZM9ycP/T/fpz8+UPch3d/b/G/Fy1a4s78ztXu1l/eW/z93NM/4979js3rxn7sL0+7j3/q68W/XfbdL7q3vGmDlnPxj9HuXFs9mVeW5e7h5/pa3azlz+01fmb0Gj+uxWv889FrPLz99cHr8KWFS9zkM650V900uzYPe4/w93+ld6n75iU/c6edf2PdPH9z7Zfd08+94PYZeG0X6zDlUDdxn+1rt7PX+NGC17gyIB2457jo/fKuFu+XH47eL8tvf8ox/be7+3cPu72PPqcwiB+r/7108Gt01rVTCkt/Pw9o/+7fh5e/Xz7Y8velxQ0efvF3F2za6SDcHwEEEEAgTQECUprrwqwQSE7AB6Q8z0+0sOFjTO7ck+r4ssIDknO33T/z0u/9K5AbBqQgKhXPvyebvjTP93ho5owHOphnxwFp/Labue9+9XA37/Gni0hjH/yOPWRnd97lvxz0ga//A01/bLru5/9TfGj61pRD3UF7bufODj4gWgSyP3E0sn+z2/sPiGVhqdV99/3Au9wJAx9Wm922qqkiIPkgM/fRvxUhxgLQ5w7f051zyU3u/5171aApWQA6cdK+7nNfvdj96jf3OYs9h+6zo/vvadcXt7e/b/SG9WpR5483ne3WGru6O/w/v1WMZfHJP1b82PZzu//+H9q+Ljr5SZTdvqpZo9srAtIHd97WTThwN/eN864pApCFGfu3H1zzC3fhjJsaTjUMT88+N78WkD45YU934D47uauuv724vwWjjd6wfu3n8d/DB4jnEo/lbxsGqpQCkr3GLxh4jVussdf4MYfs7M5v8hq32GSvcYtGFnXsNe4jkP3dXoc+GlkIWnON1Wqhp9X4YXyyOBwGJPvZX556vnhcP+8XFyx274kCdLXL4tsAACAASURBVNXfVVVAGr/t5sH75TnOos/y98sbBk3LB6Drfj4neL8cN/B+ufz2Ph5ZlO8P5ue4+LHiv9uD/fiCz9WCur+fn4T9bLM3b1BEdvtj7/NmWRagKnoSkCqCcXMEEEBgOAkQkIbTajFXBP6FAnFAsqnEMWTL8RPPyLLsRPtZ7vInfAAJdi9dnrv8+MxlG7lo91K8CyfP81n+ErZ491O4O6d4TOfemDu3ie2Ossfty/L9RvRlX7CdRuE8ajuQGgSkTcdP2HJklt1i82s2f3t+9twWLlztibodTXl+pA9T4ViFR55PXery6X78gX8rnuPIvlEfCXclNbT2u5Qiu9C9+BVZ/vPFa77zmI62J9iHvaP2H+9OPuvaYgdBHJTiX0nbAeQ/lNjOn/j2Foh23X6rljuDmu1Asscsi08WjPr/K3v/biR7rDAodfLyUQQkC0ZHH7KbO+H06cUuoaqRxu8ouubmu0t3LYVByJ6r7XQKb2uByf7YLiQb66yTD3MXXP6z0nj100umuNet+5pBO5Y6MfT3VQSkeB4WcSZ/+gB3252/a7oLyXYK/fP5F4q7x4Hotf+2Vm1HUaug1MyhbC423r57/of70Y13uoP2fX/LebbrrNiBZK/xI/cf704JXuNhUIrnYhHHXuN+508YoL5x8a11McruGwajX/92XvHzX9x9fxGBmv0p24HUai7tusW3UwUkCz3L3y9nDYo8g98vl0ecmfc+WHp7i0ynn7Cfu/rm2W7vXd81EPPPqe0+8vHJxrYdRf3vj/W7kOIdSHG4Wv5+uc1AgJ81VEq7HwGpEz3uiwACCCQuQEBKfIGYHgKpCDTageQGYoz9fGQ+6uD777i02P7gw45dqrXG2JdWLy5/c+4R+7v9vAgvA/eNd9yEO5AWvDR2UXhbH2byvvww2wllj+Oc28nHpuLvmTvIx6uBnzvbJdUsIMXPL5xT1rP02XD+dslevANr4P7Tl7p8sg9LfXk+rbZba42Xj5q/YNWL1h6z5KDSS9jiHUjBGVAW13LnJoXPMXNunsWq+GdR1Os4IJVFmGY7e+KA1P+hZvmOo/ASM/+7XXZJXLuXsPnL18rCVqvdUlVeW4qAVLbjJ4w6rebTaseSRZ8tNn59sQPJdizZ33d57/8pLpO7497764JRfPmbPXZ4iZvNa6t/f0NtSnaZkd/51GqerX6+IgJSo10/4VwsHtkfu+ws3lEU/sxuE0eg+BK28PK1+PnGu6HCuT35t2faCl2tDP3PFQEp3jFkY1u8sT9lO3vigBTe/j+nXjUoIPnL42zH0l1z5tVdKmf3bXQZWjsBqdk82zW026kCUv/7ZX2EaRR17HHDXUAWkPrfL5dHoDD0XHPLvXW7m/z97ZLdS6+/y/16zkNFaLrompnutPPrdzu1E5Ba7Zaq4ElAqoDFTRFAAIHhJkBAGm4rxnwR+BcJlJ2B1OycnjAC2ZQtwPjL3+zvA4GpiCBh5LGfhffN+0auO8pll/S6/HB/OVd4+/i+8a6o8O82dnwGkt/p1LNs5Nbhwd1hbFra0/uTeP4WssrmZWHH3z5zblp8qVxbZyAFO4zKopf59GTZpCefcce9cT1n221ql+SF4//51+est9H2xz/Wya9M2Y6hZgGpLNqEty/bJRRf4tb/waj8DKTwufizlq68aba75pbZxYcr29ngz2dKMSDtPv6dtcBjz6XdgNRqt1JZXPL/Zo9jZy6FgchiVjgXv7tp9h8fdmdc8KPi8refzvxdbaeTxajt3vbvpZe7Vf39Ugckf1naE3/9hzvu5G+XTscCULjDqCwg2c4kf/9mO5r8z+6f90Td41koOnT/Xd2oUSOdv0TNbnvcpI+66276dXFpXLs7pdo1VQUk2xUYniXULMyUXYIW3j4OTGFAevrZ+aW7ncouQ2sVkMrCV7tu8e2UAWnX7bce2GE5OAjFj1sWbXxA+r9Trxp4T/tz8Z5Wdomav3//a3z0wHly7Z2BFIctVUB6/fqvWXL/LadtmmXZX4e6HtwPAQQQQCBdAQJSumvDzBBISiDeoROHGx9+enp6bvcT93GmnYDkd9SUBaSRLjtzWU/vYf4b2QZ23Wxmu4qGFJBKLmHzUSY83NpHrkYBKbwcrbZYA5exxZew+djW6gykMWMWbxSGqUYHf9tlaj4g+Z1ONodw/FnXfznf+iOndXTAedUdSD7++IOsvYvfKRQHpEaXxLUTkGxsP95ZF99ad1aT/SzFgBSfOdROQPLx6IWXFpVeUuZ3E/3g+jtqwSe+RC0eIw5I5uV3MH3z+ze6z39ir7qA1OryuSpvVsqA5OPRgkVLapeflc0lPuTa38afg3T8sfsX/+QPxW4VeuIgFT5meN/n/vlCLSrF81Kcg6QKSOGZRTbPVjt7wnOKwte4nVfkL2nbcL3lB5z7g7LttuHlcvb3RiGoWUCKz12q8vtXdltlQKqyA6n//XL5OUWh5eU3/KbuMO5w3vZ+aj8Pdxz5wFR2jlHZIdrxAdw2vh143n+G3NAvYVt1lZFPPvObb1lAernTdeH+CCCAAALpCRCQ0lsTZoRAkgJxQGp2yZftFEp6B1KDgFR1B1IcthotXGgRn3dk92ln11QYifzjlO1OUl/CVvUMpNjAPkye++VD3dW3zC4O3Y7DkA9I4c6h/g9VrXcg2e3CILUynoE0lHhkLvF5S/Zv4SVuO263dd15TP7n/twjC1t/f/Z/awd0tzozqcqbliogtRuPyuZWdkh2szOQ4jGaBSS7rT9rKd4R1SpMVXG02yoCUtUzkFq9xuOf2/gH7LGdO+6rP3CvW29td9oJ+7mLi8us+r91zWJQvAPK/r1RQFLHI3ssVUCqegbSYMvNg/fL+svQyg7oDs9b6n/frD9TyY/f6FvYwse3/1iw3ds25hDtqi9Cbo8AAgh0mQABqcsWnKeLwFAFyg52Ds8JGpG79cIAE57NY4/Z7BK2+FvXwnON/BlI/tveGpyBVJxxZI/TTowJL/nyHrVL9AYuOys7Aym8BK/sW+iKy9oy99al2dJfhedBhc8vvlSubM7x2PE5R8XPS85UsrEGzotyAzupOj4DqdW3sPlvXZvz58drh1eHv2Px5W7hZWf+W9rKDrouC0j2WEd8bAe3+xFnFQ8R7zCKd0sNt29hCy8js29pG8pla96+0Vh+F1McpuIdRvE3vsXnKw31fcTupwhIrS5ba3SZmZ93HJCaHZpt95k0cU837dKbim98iyOQ3Xf77bZ2n/jsfxfD+0vZbv3lvYMO9E4xILX6FjZ/CZq9xsNvRPOWzXYrhZev+UOzw29lszEaHdhdFpCUl62Fv8OqgNTqW9j8rp/+98tzBr2Mmp2XFI8dj1V1B1L44KrL1wbG5AykTt4guS8CCCCQuAABKfEFYnoIpCJQFpB8/MgzN2XRK27fMaPcZPvms4E535rn+Wvs4Gf7e7OAZD+v+wa3PJ8aHozd6lvY7P6dBiQbo9W3sIUByW4fX17mv7kt/na20m+Cs2+IG/imubJdSf45O+dut+cWf0udG7hULpyDPY5z2c0uz18c8Mg6/RY2e54+EtkZG/YnPPS6LCBZuNli49cVt/WXroW/xxZ6Ju6zffFPdmnL2Zf8rLYbIfyZv49/PB+zwktj4gO4w0O67XBe+4pq+za4Tv8oDtG2OfhQY2cS2R874HrSly4o/nccfcoOurbb+bOM/CHZ8XPzY8b3D89AKpvLbff8qbbjyH4ejv/SwsWS849sXEVACs8bCp+/P9y6akCyMezw6w/v/t5iuEWLlrgzv3O1swhkf+JL4H77+wdr5x/5mLXuOssv2Wp0eVqKAcm/xs886aDiHB3/GvfBpywgWdwJX+NhWPK3t7H8pWt+t5GNHV/iNvfRv9cd1h1fHheOET6uX/eyx6j6elcFpH7LcXWXntkB1/5ctrKAZNGo/v1ycFjqd9t80CHaFn6+cPhubpVRI4unbJbhN7DFl8ctf7+9wYX3VVy6FpgTkKr+AnJ7BBBAYBgJEJCG0WIxVQQQQKCVQHg4uXNOEpBaPWY3/FwVkLrBqtVzVASkVo/RLT9XXMLWLVbNnqcyIOHpCEj8EiCAAAIrsQABaSVeXJ4aAgis/ALxYd15nk/1u7EISLr1JyDpLAlIOksCksaSgKRxHBiFgCTlZDAEEEAgLQECUlrrwWwQQAABpQA7kESaBCQRpOgSNt1shvdIBCTN+hGQNI4EJKkjgyGAAAJJChCQklwWJoUAAghIBAhIEkbnCEgiSAKSDlL0LWzSCQ3TwQhI0oVjB5KUk8EQQACBtAQISGmtB7NBAAEElAIEJJEmAUkESUDSQRKQZJYEJBmlDURAknIyGAIIIJCWAAEprfVgNggggIBSgIAk0iQgiSAJSDpIApLMkoAkoyQgSSkZDAEEEEhPgICU3powIwQQQEAlQEASSRKQRJAEJB0kAUlmSUCSURKQpJQMhgACCKQnQEBKb02YEQIIIKASICCJJAlIIkgCkg6SgCSzJCDJKAlIUkoGQwABBNITICCltybMCAEEEFAJEJBEkgQkESQBSQdJQJJZEpBklAQkKSWDIYAAAukJEJDSWxNmhAACCKgECEgiSQKSCJKApIMkIMksCUgySgKSlJLBEEAAgfQECEjprQkzQgABBFQCBCSRJAFJBElA0kESkGSWBCQZJQFJSslgCCCAQHoCBKT01oQZIYAAAioBApJIkoAkgiQg6SAJSDJLApKMkoAkpWQwBBBAID0BAlJ6a8KMEEAAAZUAAUkkSUASQRKQdJAEJJklAUlGSUCSUjIYAgggkJ4AASm9NWFGCCCAgEqAgCSSJCCJIAlIOkgCksySgCSjJCBJKRkMAQQQSE+AgJTemjAjBBBAQCVAQBJJEpBEkAQkHSQBSWZJQJJREpCklAyGAAIIpCdAQEpvTZgRAgggoBIgIIkkCUgiSAKSDpKAJLMkIMkoCUhSSgZDAAEE0hMgIKW3JswIAQQQUAkQkESSBCQRJAFJB0lAklkSkGSUBCQpJYMhgAAC6QkQkNJbE2aEAAIIqAQISCJJApIIkoCkgyQgySwJSDJKApKUksEQQACB9AQISOmtCTNCAAEEVAIEJJEkAUkESUDSQRKQZJYEJBklAUlKyWAIIIBAegIEpPTWhBkhgAACKgECkkiSgCSCJCDpIAlIMksCkoySgCSlZDAEEEAgPQECUnprwowQQAABlQABSSRJQBJBEpB0kAQkmSUBSUZJQJJSMhgCCCCQngABKb01YUYIIICASoCAJJIkIIkgCUg6SAKSzJKAJKMkIEkpGQwBBBBIT4CAlN6aMCMEEEBAJUBAEkkSkESQBCQdJAFJZklAklESkKSUDIYAAgikJ0BASm9NmBECCCCgEiAgiSQJSCJIApIOkoAksyQgySgJSFJKBkMAAQTSEyAgpbcmzAgBBBBQCRCQRJIEJBEkAUkHSUCSWRKQZJQEJCklgyGAAALpCRCQ0lsTZoQAAgioBAhIIkkCkgiSgKSDJCDJLAlIMkoCkpSSwRBAAIH0BAhI6a0JM0IAAQRUAgQkkSQBSQRJQNJBEpBklgQkGSUBSUrJYAgggEB6AgSk9NaEGSGAAAIqAQKSSJKAJIIkIOkgCUgySwKSjJKAJKVkMAQQQCA9AQJSemvCjBBAAAGVAAFJJElAEkESkHSQBCSZJQFJRklAklIyGAIIIJCeAAEpvTVhRggggIBKgIAkkiQgiSAJSDpIApLMkoAkoyQgSSkZDAEEEEhPgICU3powIwQQQEAlQEASSRKQRJAEJB0kAUlmSUCSURKQpJQMhgACCKQnQEBKb02YEQIIIKASICCJJAlIIkgCkg6SgCSzJCDJKAlIUkoGQwABBNITICCltybMCAEEEFAJEJBEkgQkESQBSQdJQJJZEpBklAQkKSWDIYAAAukJEJDSWxNmhAACCKgECEgiSQKSCJKApIMkIMksCUgySgKSlJLBEEAAgfQECEjprQkzQgABBFQCBCSRJAFJBElA0kESkGSWBCQZJQFJSslgCCCAQHoCBKT01oQZIYAAAioBApJIkoAkgiQg6SAJSDJLApKMkoAkpWQwBBBAID0BAlJ6a8KMEEAAAZUAAUkkSUASQRKQdJAEJJklAUlGSUCSUjIYAgggkJ4AASm9NWFGCCCAgEogW/MdR/epBuvmcfr6lroFC57pZgLZc1911Ai37Savl43XzQO9sjR3Dz6bdzOB5Ln3ByQcJZjOPfzi7y7YVDQWwyCAAAIIJCZAQEpsQZgOAgggIBQgIIkwCUgiSOccAUlnSUDSWBKQNI4DoxCQpJwMhgACCKQlQEBKaz2YDQIIIKAUICCJNAlIIkgCkg7SLmFjB5LEk4AkYfSDEJCknAyGAAIIpCVAQEprPZgNAgggoBQgIIk0CUgiSAKSDpKAJLMkIMkobSACkpSTwRBAAIG0BAhIaa0Hs0EAAQSUAgQkkSYBSQRJQNJBEpBklgQkGSUBSUrJYAgggEB6AgSk9NaEGSGAAAIqAQKSSJKAJIIkIOkgCUgySwKSjJKAJKVkMAQQQCA9AQJSemvCjBBAAAGVAAFJJElAEkESkHSQBCSZJQFJRklAklIyGAIIIJCeAAEpvTVhRggggIBKgIAkkiQgiSAJSDpIApLMkoAkoyQgSSkZDAEEEEhPgICU3powIwQQQEAlQEASSRKQRJAEJB0kAUlmSUCSURKQpJQMhgACCKQnQEBKb02YEQIIIKASICCJJAlIIkgCkg6SgCSzJCDJKAlIUkoGQwABBNITICCltybMCAEEEFAJEJBEkgQkESQBSQdJQJJZEpBklAQkKSWDIYAAAukJEJDSWxNmhAACCKgECEgiSQKSCJKApIMkIMksCUgySgKSlJLBEEAAgfQECEjprQkzQgABBFQCBCSRJAFJBElA0kESkGSWBCQZJQFJSslgCCCAQHoCBKT01oQZIYAAAioBApJIkoAkgiQg6SAJSDJLApKMkoAkpWQwBBBAID0BAlJ6a8KMEEAAAZUAAUkkSUASQRKQdJAEJJklAUlGSUCSUjIYAgggkJ4AASm9NWFGCCCAgEqAgCSSJCCJIAlIOkgCksySgCSjJCBJKRkMAQQQSE+AgJTemjAjBBBAQCVAQBJJEpBEkAQkHSQBSWZJQJJREpCklAyGAAIIpCdAQEpvTZgRAgggoBIgIIkkCUgiSAKSDpKAJLMkIMkoCUhSSgZDAAEE0hMgIKW3JswIAQQQUAkQkESSBCQRJAFJB0lAklkSkGSUBCQpJYMhgAAC6QkQkNJbE2aEAAIIqAQISCJJApIIkoCkgyQgySwJSDJKApKUksEQQACB9AQISOmtCTNCAAEEVAIEJJEkAUkESUDSQRKQZJYEJBklAUlKyWAIIIBAegIEpPTWhBkhgAACKgECkkiSgCSCJCDpIAlIMksCkoySgCSlZDAEEEAgPQECUnprwowQQAABlQABSSRJQBJBEpB0kAQkmSUBSUZJQJJSMhgCCCCQngABKb01YUYIIICASoCAJJIkIIkgCUg6SAKSzJKAJKMkIEkpGQwBBBBIT4CAlN6aMCMEEEBAJUBAEkkSkESQBCQdJAFJZklAklESkKSUDIYAAgikJ0BASm9NmBECCCCgEiAgiSQJSCJIApIOkoAksyQgySgJSFJKBkMAAQTSEyAgpbcmzAgBBBBQCRCQRJIEJBEkAUkHSUCSWRKQZJQEJCklgyGAAALpCRCQ0lsTZoQAAgioBAhIIkkCkgiSgKSDJCDJLAlIMkoCkpSSwRBAAIH0BAhI6a0JM0IAAQRUAgQkkSQBSQRJQNJBEpBklgQkGSUBSUrJYAgggEB6AgSk9NaEGSGAAAIqAQKSSJKAJIIkIOkgCUgySwKSjJKAJKVkMAQQQCA9AQJSemvCjBBAAAGVAAFJJElAEkESkHSQBCSZJQFJRklAklIyGAIIIJCeAAEpvTVhRggggIBKgIAkkiQgiSAJSDpIApLMkoAkoyQgSSkZDAEEEEhPgICU3powIwQQQEAlQEASSRKQRJAEJB0kAUlmSUCSURKQpJQMhgACCKQnQEBKb02YEQIIIKASICCJJAlIIkgCkg6SgCSzJCDJKAlIUkoGQwABBNITICCltybMCAEEEFAJEJBEkgQkESQBSQdJQJJZEpBklAQkKSWDIYAAAukJEJDSWxNmhAACCKgECEgiSQKSCJKApIMkIMksCUgySgKSlJLBEEAAgfQECEjprQkzQgCBBgJb7DBhxyzLpi7r6d1r3u1XPFd2sw23mbT62mOWXOicu+3+mZd+r8sxCUiiXwACkgiSgKSDJCDJLAlIMkoCkpSSwRBAAIH0BAhI6a0JM0Jg2AtsNX7iES7LLg6fSJ7nUx+YeelJnTy5VzMglT0HP/c8z2c1i1hVn2PZY/X19e00984Zd1QdK7q9JCAduOc4d9bJB7mxY0YXw1963V3us6f+oOHUTjnmw+4Ln9jNrTJq5KDbxz97aeESd8LpV7qrbprl4sfxD+Bvs8mb1qsb1//8qWfmu0996RI3894Hi3+yxzhq//Hu5LOuLcZV/FEFpAn77OS+85Wj3dg1ViumdfHVP3dHnfzthlNsdfuLTv+MO/KADxT3f2nBYvfp/7rAzbj+9uLvO7/3/7hLz/yCe/0Gry3+ftvdf3C7TphSe6xWY/sb+sdoNdd2nVcdNcJtu8nr27156e3e9bbN3JcmT3Drvnbt2s9v/Ok9buq5l7cc19/Xbvi1M2e4//njvOI+Z3/9M+7d79i8+N+LFi9x3zjvavfTX95b/H33nbd1xx97gFt9tf7XwG9//6D7wheXr9uRh+7pPr7/rm7UyP7f+XAu8c/Kxm856QY3eGVp7h58Nh/q3Qfd7zfXfsk9/dyLbp+jz2065oF7bufOPOnA5e8J19/tjjv1stp9zp3ycTdxn+37fy8XLnGTz7jKXXXT7OLv47fdzF3w1cPchuv1r93tsx+se7xWY19/wXFup+3618le+0d/ebqbeW//Gg71jzIgFe9jJwXvl9e38X55ePB+2eD2xXvn4bu5u3/3sNv76HNqT9X/u73fvtK71J19yc/caeffUEcx69op7unnXmh4P3/j4r32jP734w7+PPzi7y7YtIP7c1cEEEAAgYQFCEgJLw5TQ2C4ChRBxLld5i8c/cmn5kxbFOwKcv7fhtNzi5+Peu7x+EUo68mmL83zPR6aOeOBDh6v44A0ftvN3Xe/drib99jTxYcP+7By7Md3dudd9stBH1Jsnj4CXfezOUVk+taUQ91Be41zZ3+//0ON/f1NG7629kFm1g+nuDXXWK0uAIXP98cXfM5tsO5abtzHTi1lsPs//Wz/B6MwQIVhqgO/2l0VAckHnbmP/rUIOad+/hD3+U98xH3z+z9xU745OHy0un18/1/MONVtsfEb3MTJZ7tf3vMn9+db+wPH1h/8jPOx6Oqbf10Eq1Zj+yceBqqUApIFnUP3382dff41RQA68bhD3O67bOsuu+YX7uIf3NRwycPw9Ow/59cCkt1/5/HvrEWjGed/0Y0ZM7r4uf2xWPXEk/8oopEPQj+97d4iWPm49MuZvyv+Hs/Fbn/APju5q6+/venchvJ7qgpIYZSJg048Lx+A5j3+jyL8nHLMXu6YQ97vzr/8V+60828c9Hcbe7M3r18LPRap7M979vua87Houp//TxGgWo1tYWrfD7yrFqTCsYbi5++jCkjF++VXD3fzHg/eLw/Z2Z13eZP3y5MOctf9PHi/3HPcoAgURqLbZ8+tvX8W78dNxrf3z52226J4muH97O+t7tuBJwGpAzzuigACCKQuQEBKfYWYHwLDUKAsuJRdWmahpKenp9guEe/qqfuZy5+wmDIid+uFl7DFO3ds186Li1a7N76EbdPxE7YcmWW3ZC7bKB8Yy8LMZjsdvM6IvlE3Zll2ee7y4+3nLs8vjyNX/HxsvFEuu8Rlmf0n93P83O15DIw3zv53uIuo9vyz7JBiSfP8SH+JXTy+n1ee5yf6XUh1zzWa45bjJ56RZdmJtV+V5T9fvOY7ju7r5Fco3s0TB6V4bPvAstlbNqgFoVa3t6C0727b1HYhheNZEDr9hP3cRdfMLI1VjXYapboDyYLPMR/fwx3/9YuLXUJxxIktW93egtHr1v23IhDZnzAoPfT4U+4bXzzSnX/ZLbU4FQalVmP78Wy+5/3gZveFI/Z2Pj518vtk91XsQIrnEEecRnO0MPTc8y8UP97ojeuXBiL7WRh91vm3terikv3cxrE/E475erFzyY9lMctHqjA4pR6QvFc7O5AsGB25/w7ulLN+WOwqiqOPBaMN1lmzCET2JwxMj/zlGXfaCR9zF19zZxGb7E8YgVqNHc8vDkpD/d1UBaTS98sgKJW+X755A/epL/fvoIwDlN3evw9effNst/eu76rFKX/bX9z956Y7Qm2MRjuQmsWnoVo65whIHeBxVwQQQCB1AQJS6ivE/BAYhgKNduyE/77m6ou3DXfZ2M9y5zazy9ziHTgWbHp63JhsmRvjA1LeN3LdkS47c1lP72F2HlIRdTL31vkLVrspDEhxjAnHznqWPlsEH+cesWhk1GXnJ5UFJAtSLndX+svyajHKuWkWhopoNTC/BS+NXWTj5s49abcfuO30pS6fbCGrdAdScNbTgM0kf9lcEYycm2ePE/8sGqvjgFQWeGzXj/0p2xUUB6Tiw0vF2/tf+Sq7j8KXSaoByXbzHPCh/6i7zCyMOvFLvdXt4/uGu4ye+sfzg3Y3hTuUDvnIjk3nEscou+wu5YDUzi6fRtHH3MMdRvb3MEjZ38PdSfb3MBpNOHC3uoBkPw8fK76ELb48rpO3eNUOJD+HdgJSWbQJI1C8KyjcZWS7BcPdSva44Q6l/fbYtm6HURiY/nPq1cWlb37nk/0s3v00VEtVQCreLz+wTd1lYBZvivfL/QbvoizeudCgdgAAHa9JREFUL4OA5GOPv72/HM52KF1zy711u5viS+XsPsXlvAMxKrRo5xI20eVr9rAEpKH+InI/BBBAYBgIEJCGwSIxRQSGm0CjgFTsKsqySRZr1hqzpPi/qn2ACYPLiL5Rk8Of+ecfnoHUs2zk1mWXecU7neJzk8KfL+3p/YkFpHCnTxhn/OM22oHU6/LD/SVmjR6nL8+nLcvcM7ZjKbx9HIHqzowKdhg13LmVZZOefMYd98b1nB1WUjswPJzr3LvOfcMb3vP5/oOBhvjHPhDt+r6t6y4xaxaEyi5xa3T7ZpfDDXX3Uf+HyjTPQLIg9MHx76pdYmZzbRWQmt3e7vv3Z5+vnWsUB6Rwt5M9VhyQGo19xgXX1u1eii9/G+KvUu1u6h1I8Y6fsvlZ8LGdRLZjyP7Eu4biv4cB6ff3PVScf+QvUYvv/863bTroErUwIMXzCS+P8+cvDdX0XxWQdt1+q7qzh+KAFJ6jFAekcPeSPe84IDUa2wekX9x9f+28pRQD0q7bb10XcZoFpLLLyPzt/+/Uq4pg5HcYlV0eF5715n/+4oLFg2JVWUCKf+fsNsXlxCUBqsrv55tf/9plf7jha5tmWfZYlftxWwQQQACB4SFAQBoe68QsERhWAu3sQLKAVHfZVXAZmwUkv8MmfOJxpAkv6/KXkfndPj6qhNHKzmOy8Xy8UQckfzleOGe7jM0Ckr+Erm4hBy5jC73GjFm8URibBl365gfI88t9QLJIVXep28D5U988cdeXjzrtl0s7+eWpugPJHqs4d2Nc/7kb/s/ts5af22H/5g/TvvLGWaWXXzSLVK0ui0s5IA2HHUg/vPVud+KnPuZWWaX/QOjwj+IcJGVA8vFo4cIltThU9vtu0ebNb9pg0I/8OUj2g/hQ7t6lS2tnKtm5Rnvt/t66+z/+l6frgpQ/gNvfKD5o2/+77UjaZ8//cN++8Ee1Q7qH+hr9VwWk8Bwimzs7kPpXsOoOpNr75cA5RbX3y9lz3eU3/KbuMO6699PZc92sPzw66MsCyh7f7tdOQFK9b/b0ZI/+72/Ps4DU0eXTQ31NcD8EEEAAgRUrQEBasb6MjkBXCrRzBlLZTh+PZT+z/x1/a1uzb2Hz93lh4ehTw8vQXs0dSH53lQ9V/vmEu6vscrv4lyL2Cv9ut7XnE0Yif/+y3UnqS9iqnoEUPzeLPedOOdTZ+R3+m4FaxaNWB3U3OzfJHl/1QSh8LopDtNs5dyh8zFa3X9FnIPm5pLoDqd14VPYmHO84im9jkWe397/bTT3nitq3tIW3sSB13wOPlX7rm83rxM8d7H72q9+WHpo93ANSq3OKOANp+TdAlp1p1Oz/KCjeL798qLv6luXvl/728VhluzSLHaPRDqhXOyBxCVtX/p99PGkEEOgiAQJSFy02TxWBV0ugnW9hK/umsa12nPjZpVnvFfHlaXZbP3d/BpLdxv7N77xpFJDis4nKzkBSXMIWP47Nzc/bH+ztz0Cyn/kzm+6/Y8Y1jbz87eNzjopwtMbLR81fsOpFa49ZcpD/xjsfm+z/HTgIvOMzkFp9C5v/5rM59z1e9xXRfr3inUSt4lDxYafJmUmtdh+lHJBaffOZDzWz/zivuCyt1e1fjW9hM88UA1Kry9b8JWj3P/hE8c1p8Z9mAanVgdyt4lN8+doZUya5hx79Wy0mNbu8rep79KuxA8lfgjbnz08U37rW6pvS4svK+Ba25d/C5s8tmvPnBu+XTc5LKotR4WVn9rsTfgNc+LtUtgPpyrOPcX+c99da2G92qV3F30vOQKoIxs0RQACB4SRAQBpOq8VcERgmAvG3o9m08zyfWrajKLzsK7xN3eVpJd/CVhyiPfDNagXLwLlBQUSpnQvU6lvYFAHJHjf4VrfiW9jCb5aLL0ULvw2ubMeWH8u+fdncBpkOXP4WjmtjOpfd7PL8xQHrrNNvYbPn4SPR2DGjC+pLr7urdtlZWUCyALTFxq8rbhtfulZ2eVs4ZqvdRWWHdPuXRTxP+/e5j/699LDvqi8lxQ6kMMaMXWO1YgrhJWFxQGp1e/u5nat05AEfKMZ6acHiugO6fYB6/QavLX5+291/qJ2X1M7Y3ijFgBQfTO3n6i8rqxqQ/O1XX220Cy9d8+NaNPKXqIWXrvmfh5fIxZeuxZe/+cvmOj3/yB5bFZAs8uy03ea1l8UrvUvdNy/5efFNaXFA6n9P2M6dedKBrvaecP3dtXOJ7Od20PbEfbbv/71cuMRNPuOq4hvb7I8PUBuut3b/e8TsB4swtfx13HzscK52aPTRX57uZt47r+pLuu72qkO0+23G1V16dun10fvlSQe5MCBZuKm9X86uv9Q3nGRZQPL/5i2L97vgsO7i/Ta4PM7W9exLflZEI3uvnbjP+2oP0egA7iHAEpCGgMZdEEAAgeEiQEAaLivFPBFAAIE2BKJLAyUBqY2HXelvogpIKz1UG09QeQZSGw+3Ut9EFZBWaqQ2npwyILXxcCv7TQhIK/sK8/wQQKCrBQhIXb38PHkEEBjuAuHuKnsu0U4vApJogQlIIkjnHAFJZ0lA0lgSkDSOA6MQkKScDIYAAgikJUBASms9mA0CCCCgFCAgiTQJSCJIApIOUngJm3RSw3AwApJ00QhIUk4GQwABBNISICCltR7MBgEEEFAKEJBEmgQkESQBSQdJQJJZEpBklDYQAUnKyWAIIIBAWgIEpLTWg9kggAACSgECkkiTgCSCJCDpIAlIMksCkoySgCSlZDAEEEAgPQECUnprwowQQAABlQABSSRJQBJBEpB0kAQkmSUBSUZJQJJSMhgCCCCQngABKb01YUYIIICASoCAJJIkIIkgCUg6SAKSzJKAJKMkIEkpGQwBBBBIT4CAlN6aMCMEEEBAJUBAEkkSkESQBCQdJAFJZklAklESkKSUDIYAAgikJ0BASm9NmBECCCCgEiAgiSQJSCJIApIOkoAksyQgySgJSFJKBkMAAQTSEyAgpbcmzAgBBBBQCRCQRJIEJBEkAUkHSUCSWRKQZJQEJCklgyGAAALpCRCQ0lsTZoQAAgioBAhIIkkCkgiSgKSDJCDJLAlIMkoCkpSSwRBAAIH0BAhI6a0JM0IAAQRUAgQkkSQBSQRJQNJBEpBklgQkGSUBSUrJYAgggEB6AgSk9NaEGSGAAAIqAQKSSJKAJIIkIOkgCUgySwKSjJKAJKVkMAQQQCA9AQJSemvCjBBAAAGVAAFJJElAEkESkHSQBCSZJQFJRklAklIyGAIIIJCeAAEpvTVhRggggIBKgIAkkiQgiSAJSDpIApLMkoAkoyQgSSkZDAEEEEhPgICU3powIwQQQEAlQEASSRKQRJAEJB0kAUlmSUCSURKQpJQMhgACCKQnQEBKb02YEQIIIKASICCJJAlIIkgCkg6SgCSzJCDJKAlIUkoGQwABBNITICCltybMCAEEEFAJEJBEkgQkESQBSQdJQJJZEpBklAQkKSWDIYAAAukJEJDSWxNmhAACCKgECEgiSQKSCJKApIMkIMksCUgySgKSlJLBEEAAgfQECEjprQkzQgABBFQCBCSRJAFJBElA0kESkGSWBCQZJQFJSslgCCCAQHoCBKT01oQZIYAAAioBApJIkoAkgiQg6SAJSDJLApKMkoAkpWQwBBBAID0BAlJ6a8KMEEAAAZUAAUkkSUASQRKQdJAEJJklAUlGSUCSUjIYAgggkJ4AASm9NWFGCCCAgEqAgCSSJCCJIAlIOkgCksySgCSjJCBJKRkMAQQQSE+AgJTemjAjBBBAQCVAQBJJEpBEkAQkHSQBSWZJQJJREpCklAyGAAIIpCdAQEpvTZgRAgggoBIgIIkkCUgiSAKSDpKAJLMkIMkoCUhSSgZDAAEE0hMgIKW3JswIAQQQUAkQkESSBCQRJAFJB0lAklkSkGSUBCQpJYMhgAAC6QkQkNJbE2aEAAIIqAQISCJJApIIkoCkgyQgySwJSDJKApKUksEQQACB9AQISOmtCTNCAAEEVAIEJJEkAUkESUDSQRKQZJYEJBklAUlKyWAIIIBAegIEpPTWhBkhgAACKgECkkiSgCSCJCDpIAlIMksCkoySgCSlZDAEEEAgPQECUnprwowQQAABlQABSSRJQBJBEpB0kAQkmSUBSUZJQJJSMhgCCCCQngABKb01YUYIIICASoCAJJIkIIkgCUg6SAKSzJKAJKMkIEkpGQwBBBBIT4CAlN6aMCMEEEBAJUBAEkkSkESQBCQdJAFJZklAklESkKSUDIYAAgikJ0BASm9NmBECCCCgEiAgiSQJSCJIApIOkoAksyQgySgJSFJKBkMAAQTSEyAgpbcmzAgBBBBQCRCQRJIEJBEkAUkHSUCSWRKQZJQEJCklgyGAAALpCRCQ0lsTZoQAAgioBAhIIkkCkgiSgKSDJCDJLAlIMkoCkpSSwRBAAIH0BAhI6a0JM0IAAQRUAgQkkSQBSQRJQNJBEpBklgQkGSUBSUrJYAgggEB6AgSk9NaEGSGAAAIqAQKSSJKAJIIkIOkgCUgySwKSjJKAJKVkMAQQQCA9AQJSemvCjBBAAAEEEEAAAQQQQAABBBBAAIGkBAhISS0Hk0EAAQQQQAABBBBAAAEEEEAAAQTSEyAgpbcmzAgBBBBAAAEEEEAAAQQQQAABBBBISoCAlNRyMBkEEEDg1RfYdPyELUe57JJelx/+0MwZD7z6M+ARUxXgdyPVlemeeW2xw4Qdsyybuqynd695t1/xXPc8c54pAggggAAC6QkQkNJbE2aEAAIIvKoCKyISbDV+4hHOuV3mLxz9yafmTFv0qj6hBB7MPvT29PTc7vL8yPtnXvo9P6XCJcsuDv/d/Edm2S2Zyzbyt8vzfOoDMy89abOdDl5nRN+oG7MsG1f3tPL88la2/r55np84984ZdwyFZUX8bgxlHnafmoVzj4TPveaXu7v8v5e6BWa1dYgm09fXt1Mrqy3HTzzD7mbrM9TnYvdL5TVSZhE6xL+feZ7PajfmKH5/hmNAqr3+w1+Q4L1gw20mrb72mCUXuiw7xN+knd+98HXQyevaP6bqd7mT1wH3RQABBBAYXgIEpOG1XswWAQQQkAsoPuTFk0rlw7Ecq80Biw+QWfbfuXPPLevpPcx2TgxEjemZc+s4575rYaks8tiHy7XGLJmyrKf3THs4C0hD+bCoCEhtPt1X5WahX1+e/6cPPfYhOMuyt7s8f94Ckk2m+HDu3G118W7Hiaf05vl1tsuuk99P1YfuTuagBI/nUQSbnmz60jzfw6wGfpc38ZaFt3NvbBUwbY4r4r1F+dxX1Fhx9PIRLu/LD7Pf24Hf5ckvLBx9qgX22LzZvJSva9Xv8opyZFwEEEAAgfQECEjprQkzQgABBF5VAf8hL8+yOZlzx9iD+x0w9r8H/dfy4L+kl+xOmLrU5dPDHTXt7liId0KE/0U+/Fk4Xt19gh0m/jm5LLvMOXeOv48PMn5HT7v/1b/qggx86J7ksmyWy/MF9uF7YK5ruDy33URF3Gi1u6KTD4sDYeXE2tzz/Mhel99jlyvGLiP6Rk3Osqy4be7yJ3w8iANA8YEzy9bM8nwt2z0R3raqUdXb1wJSll+Su573v7Bg1cljxizeaGTW89nMubnmalHD/q3VJZlDjTeDdpYM/M7VopXfUbKCXiNVzdq5fWzR6neu1e+sf8xGu2x6smwT252YZ9kL9n5j7zUWS+t22gWv5fDxgtfv5bnLjy927bWxG68dB+VtYqOaRRQ1/WO2Mg/nVva6DmN02Xtb2XurjVnskvR/EnRUrgljIYAAAghoBAhIGkdGQQABBIatQHAJ0KnxrpgXF612r+3myJ17MrikavpSl09euHC1J+xnfXk+zf6revEhaY2Xj5q/YNWL1h6z5KAql7AVc3DZmX63ThEuMvfW+++YcY19+Mmdm+Qvm9l8pwnv7utzC0fkbr3wbJRwZ0R/WMhucbm70l9qFFwCNc2eZ/yYygWsBaRl+cluRHa6W5afnI/Ijs2W5ecVfx/4IOntw3mG86jywTKef9l9yx7PbjcyH3Xw/Xdc+i0bI3YMY0x/QHIH+cA01BAzFGsfkOx3b6TLDsvz/BaLEX15/oiPEhaQ1hj70upFjIgudQsfs5N5x7s2fBxY0a+RoZi1c5/SHUhNzhyqYle2A8nHjDDe2uvF5hrszrH1K16npQFpYG3tPmW7zdp53ivyNmU7kJpFzSo7tcpe183e2/K+kes2em9lB9KK/C1gbAQQQGDlFCAgrZzryrNCAAEE2hYo+/DiP1jYbqL4g89AYJi3tKf3JwMf1IsPep18QG90CUez/3Iff/gJn4fNJZ53o10BPoC1DdbGDX1AsqBRxLQs29/l+TXzF46+Mv7AW3YGkv9wrT4DqZ0PqqGTffgcFJCC83/C57miz7oKA1KxvlnPN3LnHrOdSHGwbHAGUu08KuUZSI1eP5lz0tdIG792Q7rJIIsmO1Ha+f0JJ9EwILU4Hy18bZcFpPCSTv9+FL8HDQlDdKd4p1qzXZitdie1E4abvbfZ/cNLEsPxCEiiBWcYBBBAoIsECEhdtNg8VQQQQKBMoNGHvNy5zeLL0Wr3H7hEJ44fPnxU2aXgxyy7TG3BS2MXhbuc4g8/9iHdf3AcFBiib5YrPdjWObciLmMLw0qxG2pgd5V/PvH5PHF8yzM3xXb5ZD1Ln1WegdQoADT6wJtqQIp3v7X6ffPPr5PfT79GZeEyPgS9uO0KeI2siHew0K7Z5X/xOT7tzKVKQIovzfKX0Q7XgOR3R5pTo9dwvHutHdOyHUit3tsaXQJMQGpHnNsggAACCIQCBCR+HxBAAIEuF2i1Aym8/KEZVfhBb2TfqI9UuYQtHtd/sLFDZhtdojKUHUg9WTapncN/O/2VaLQzp53dBuEHxL4RS/+8ogNS2aHJ/sNvqgHJDneOo1uz37fYvVVwarb+pQEpuPzy1XqNdPo7Whdugx1BZTZDiUc2frsBKT6Ye2XYgRReXlt2btRQ4pGZNgxIbb63hbYEJNWriHEQQACB7hEgIHXPWvNMEUAAgVKB+ENe+He/08Of71L7UJi5ty7Nlv4qPDsn/JDUs2zk1uEHqFb04Rkodtvwg018BtJWO07Yvzd39xVnIAXfFtXs7J7wg5c/W8X+LX7cVvNs9+ftBqQBsz3Cr4RvteOi3TmUxaqyD/Txh9vQezgGJH+wtl3a5i+ri593JwEpvm9ZCPBneClfI+2ue9XbtXo+VS9bCx+/LHaU2Yev99iz1esh1UvY4ve/8P3JjIZ6dlPZ6zo+Ayl8b/PrEX5rof2bved08jqo+nvG7RFAAAEEVg4BAtLKsY48CwQQQGDIAs3O4LFB429T8t+85eOSfRuX3S78Rq7wPu18C9ugOUTnsISXt1T5FrZelx8e7laJz8ZpZ25DgW03IJWd1RPOqZMzkPyHyNo3LQXfwha6lHxb1q15nr/GDi0fjgGp9uHcfyNa9LtpP+/kDKS6NWnwLWwr4jUylN/Ddu5TFhH8c3TO3W6Xibosuzgeq91LP0Nru0944HkY+PxlgGaX5e4fuXO/ssixsgSkIPy4hb3uzNVXcdcV3yIX/Am//bLZ2tVdsjZwqWSj97biEO0su6X2WMF7a9nv8oo+y6yd30lugwACCCCQrgABKd21YWYIIIAAAggggAACCCCAAAIIIIBAEgIEpCSWgUkggAACK7dAfEBu+GxX1C6glVu08S4ae97hbrCV3UH5/Mp249WNP7DbQ/mYw3ksXtf61Wu0O47Xtd6aERFAAAEEqgsQkKqbcQ8EEEAAAQQQQAABBBBAAAEEEECgqwQISF213DxZBBBAAAEEEEAAAQQQQAABBBBAoLoAAam6GfdAAAEEEEAAAQQQQAABBBBAAAEEukqAgNRVy82TRQABBBBAAAEEEEAAAQQQQAABBKoLEJCqm3EPBBBAAAEEEEAAAQQQQAABBBBAoKsECEhdtdw8WQQQQAABBBBAAAEEEEAAAQQQQKC6AAGpuhn3QAABBBBAAAEEEEAAAQQQQAABBLpKgIDUVcvNk0UAAQQQQAABBBBAAAEEEEAAAQSqCxCQqptxDwQQQAABBBBAAAEEEEAAAQQQQKCrBAhIXbXcPFkEEEAAAQQQQAABBBBAAAEEEECgugABqboZ90AAAQQQQAABBBBAAAEEEEAAAQS6SoCA1FXLzZNFAAEEEEAAAQQQQAABBBBAAAEEqgsQkKqbcQ8EEEAAAQQQQAABBBBAAAEEEECgqwQISF213DxZBBBAAAEEEEAAAQQQQAABBBBAoLoAAam6GfdAAAEEEEAAAQQQQAABBBBAAAEEukqAgNRVy82TRQABBBBAAAEEEEAAAQQQQAABBKoLEJCqm3EPBBBAAAEEEEAAAQQQQAABBBBAoKsECEhdtdw8WQQQQAABBBBAAAEEEEAAAQQQQKC6AAGpuhn3QAABBBBAAAEEEEAAAQQQQAABBLpKgIDUVcvNk0UAAQQQQAABBBBAAAEEEEAAAQSqCxCQqptxDwQQQAABBBBAAAEEEEAAAQQQQKCrBAhIXbXcPFkEEEAAAQQQQAABBBBAAAEEEECgugABqboZ90AAAQQQQAABBBBAAAEEEEAAAQS6SoCA1FXLzZNFAAEEEEAAAQQQQAABBBBAAAEEqgsQkKqbcQ8EEEAAAQQQQAABBBBAAAEEEECgqwQISF213DxZBBBAAAEEEEAAAQQQQAABBBBAoLoAAam6GfdAAAEEEEAAAQQQQAABBBBAAAEEukqAgNRVy82TRQABBBBAAAEEEEAAAQQQQAABBKoLEJCqm3EPBBBAAAEEEEAAAQQQQAABBBBAoKsECEhdtdw8WQQQQAABBBBAAAEEEEAAAQQQQKC6AAGpuhn3QAABBBBAAAEEEEAAAQQQQAABBLpKgIDUVcvNk0UAAQQQQAABBBBAAAEEEEAAAQSqCxCQqptxDwQQQAABBBBAAAEEEEAAAQQQQKCrBAhIXbXcPFkEEEAAAQQQQAABBBBAAAEEEECgugABqboZ90AAAQQQQAABBBBAAAEEEEAAAQS6SoCA1FXLzZNFAAEEEEAAAQQQQAABBBBAAAEEqgsQkKqbcQ8EEEAAAQQQQAABBBBAAAEEEECgqwQISF213DxZBBBAAAEEEEAAAQQQQAABBBBAoLoAAam6GfdAAAEEEEAAAQQQQAABBBBAAAEEukqAgNRVy82TRQABBBBAAAEEEEAAAQQQQAABBKoLEJCqm3EPBBBAAAEEEEAAAQQQQAABBBBAoKsECEhdtdw8WQQQQAABBBBAAAEEEEAAAQQQQKC6AAGpuhn3QAABBBBAAAEEEEAAAQQQQAABBLpKgIDUVcvNk0UAAQQQQAABBBBAAAEEEEAAAQSqCxCQqptxDwQQQAABBBBAAAEEEEAAAQQQQKCrBAhIXbXcPFkEEEAAAQQQQAABBBBAAAEEEECgugABqboZ90AAAQQQQAABBBBAAAEEEEAAAQS6SoCA1FXLzZNFAAEEEEAAAQQQQAABBBBAAAEEqgsQkKqbcQ8EEEAAAQQQQAABBBBAAAEEEECgqwQISF213DxZBBBAAAEEEEAAAQQQQAABBBBAoLoAAam6GfdAAAEEEEAAAQQQQAABBBBAAAEEukqAgNRVy82TRQABBBBAAAEEEEAAAQQQQAABBKoLEJCqm3EPBBBAAAEEEEAAAQQQQAABBBBAoKsECEhdtdw8WQQQQAABBBBAAAEEEEAAAQQQQKC6AAGpuhn3QAABBBBAAAEEEEAAAQQQQAABBLpKgIDUVcvNk0UAAQQQQAABBBBAAAEEEEAAAQSqCxCQqptxDwQQQAABBBBAAAEEEEAAAQQQQKCrBAhIXbXcPFkEEEAAAQQQQAABBBBAAAEEEECgugABqboZ90AAAQQQQAABBBBAAAEEEEAAAQS6SoCA1FXLzZNFAAEEEEAAAQQQQAABBBBAAAEEqgsQkKqbcQ8EEEAAAQQQQAABBBBAAAEEEECgqwQISF213DxZBBBAAAEEEEAAAQQQQAABBBBAoLoAAam6GfdAAAEEEEAAAQQQQAABBBBAAAEEukqAgNRVy82TRQABBBBAAAEEEEAAAQQQQAABBKoLEJCqm3EPBBBAAAEEEEAAAQQQQAABBBBAoKsE/j+uhcnSB87KoQAAAABJRU5ErkJggg==",
      "text/html": [
       "<div>                            <div id=\"3184208b-0dd9-4ea8-adbf-5e306fb145c6\" class=\"plotly-graph-div\" style=\"height:700px; width:700px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3184208b-0dd9-4ea8-adbf-5e306fb145c6\")) {                    Plotly.newPlot(                        \"3184208b-0dd9-4ea8-adbf-5e306fb145c6\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"texttemplate\":\"%{z:.5f}\",\"x\":[\"best_score\",\"MSE_train\",\"MSE_test\",\"R2_train\",\"R2_test\"],\"y\":[\"SVR\",\"LinearRgression\",\"Lasso\",\"Ridge\",\"ElasticNet\",\"RandomForestReg\",\"DecisionTreeReg\"],\"z\":[[0.911461879336937,1.647436412458598,3.54002271783259,0.9720168762802741,0.9237511758245543],[0.892717883233531,5.412207274011198,11.086145748693532,0.9080690067306242,0.7612146459633333],[0.893145985143321,5.508425038087426,10.2658101632541,0.9064346652921208,0.778883917830981],[0.8929728787192909,5.418000202580407,10.831227747481996,0.9079706088588606,0.7667053445838877],[0.893145985143321,5.508425038087426,10.2658101632541,0.9064346652921208,0.778883917830981],[0.9614997366230907,0.22865677280640953,2.405338966148683,0.9961160681441744,0.9481912172517045],[0.9277113732616256,4.4117647058823214e-05,2.4999486301369855,0.999999250623838,0.9461534123533341]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>model: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"model\"},\"automargin\":true},\"coloraxis\":{\"colorscale\":[[0.0,\"#00224e\"],[0.1111111111111111,\"#123570\"],[0.2222222222222222,\"#3b496c\"],[0.3333333333333333,\"#575d6d\"],[0.4444444444444444,\"#707173\"],[0.5555555555555556,\"#8a8678\"],[0.6666666666666666,\"#a59c74\"],[0.7777777777777778,\"#c3b369\"],[0.8888888888888888,\"#e1cc55\"],[1.0,\"#fee838\"]],\"showscale\":false},\"title\":{\"text\":\"Model Score: Enineerd Features, Rain adn Ws Removed\",\"x\":0.5},\"margin\":{\"t\":40,\"pad\":0,\"autoexpand\":true},\"font\":{\"size\":12},\"height\":700,\"width\":700,\"paper_bgcolor\":\"rgba(0,0,0,0)\",\"plot_bgcolor\":\"rgba(0,0,0,0)\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3184208b-0dd9-4ea8-adbf-5e306fb145c6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2=model_scores.set_index('model')\n",
    "\n",
    "######################################################\n",
    "\n",
    "fig = px.imshow(df2,text_auto='.5f',color_continuous_scale='Cividis',\n",
    "          title='Model Score: Enineerd Features, Rain adn Ws Removed')\n",
    "fig.update_coloraxes(showscale=False)\n",
    "fig.update_layout(margin=dict(t=40,pad=0),\n",
    "                  title_x=0.5,\n",
    "                  height=700,width=700,\n",
    "                  paper_bgcolor = \"rgba(0,0,0,0)\",\n",
    "                    plot_bgcolor = \"rgba(0,0,0,0)\",                  \n",
    "                    margin_autoexpand=True,\n",
    "                    font=dict(size = 12))\n",
    "\n",
    "fig.update_yaxes(automargin=True)\n",
    "\n",
    "\n",
    "fig.show()\n",
    "#######################\n",
    "pio.write_html(fig,file = '../Regression/tuned_models_raw4_4//model_scores.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875750f0-ad1d-4a54-9e4d-0b16e0a2350d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08dfd360-5a01-4ccb-a655-47267fcbf72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.84749672e-03, 2.04699508e-03, 1.02451693e-03, 7.81732273e-05,\n",
       "       9.17567749e-01, 7.74350686e-02])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtcReg_model.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f79c0aec-c128-4883-8a2e-fce9542ed528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "feature=%{x}<br>importance=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "green",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "ISI/FFMC",
          "ISI/DMC*BUI",
          "RH",
          "Temperature"
         ],
         "xaxis": "x",
         "y": [
          0.9172463182964187,
          0.07804485604859975,
          0.002953058845776607,
          0.0017557668092050922
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "feature=%{x}<br>importance=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "green",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "ISI/FFMC",
          "ISI/DMC*BUI",
          "RH",
          "Temperature"
         ],
         "xaxis": "x2",
         "y": [
          0.9151930936117114,
          0.07559707287752811,
          0.005458959046713483,
          0.0037508744640469675
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "DecisioinTreeReg",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "RandomForestReg",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "paper_bgcolor": "rgba(0, 0, 0, 0)",
        "plot_bgcolor": "rgba(0, 0, 0, 0)",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Feature Importance: Engineerd Features"
        },
        "width": 1100,
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          0.45
         ],
         "range": [
          -0.5,
          3.5
         ],
         "showgrid": false,
         "showline": false,
         "type": "category"
        },
        "xaxis2": {
         "anchor": "y2",
         "autorange": true,
         "domain": [
          0.55,
          1
         ],
         "range": [
          -0.5,
          3.5
         ],
         "showgrid": false,
         "showline": false,
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          0.9655224403120196
         ],
         "showgrid": false,
         "showline": false,
         "type": "linear"
        },
        "yaxis2": {
         "anchor": "x2",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          0.9633611511702226
         ],
         "showgrid": false,
         "showline": false,
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"5db99b0a-3b40-488b-b83e-9ae1265f8620\" class=\"plotly-graph-div\" style=\"height:500px; width:1100px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5db99b0a-3b40-488b-b83e-9ae1265f8620\")) {                    Plotly.newPlot(                        \"5db99b0a-3b40-488b-b83e-9ae1265f8620\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"feature=%{x}<br>importance=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"green\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"ISI/FFMC\",\"ISI/DMC*BUI\",\"RH\",\"Temperature\"],\"xaxis\":\"x\",\"y\":[0.9172463182964187,0.07804485604859975,0.002953058845776607,0.0017557668092050922],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"feature=%{x}<br>importance=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"green\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"ISI/FFMC\",\"ISI/DMC*BUI\",\"RH\",\"Temperature\"],\"xaxis\":\"x2\",\"y\":[0.9151930936117114,0.07559707287752811,0.005458959046713483,0.0037508744640469675],\"yaxis\":\"y2\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"showline\":false,\"showgrid\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"showline\":false,\"showgrid\":false},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"showline\":false,\"showgrid\":false},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"showline\":false,\"showgrid\":false},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"DecisioinTreeReg\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"RandomForestReg\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"height\":500,\"width\":1100,\"title\":{\"text\":\"Feature Importance: Engineerd Features\"},\"paper_bgcolor\":\"rgba(0,0,0,0)\",\"plot_bgcolor\":\"rgba(0,0,0,0)\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5db99b0a-3b40-488b-b83e-9ae1265f8620');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.subplots as sp\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "model = {\"DecisioinTreeReg\":dtcReg_model,'RandomForestReg':rfReg_model}\n",
    "# Define the number of rows and columns for the subplot grid\n",
    "num_rows = 1\n",
    "num_cols = 2\n",
    "\n",
    "# Create a subplot grid with the specified number of rows and columns\n",
    "fig = sp.make_subplots(rows=num_rows, cols=num_cols,subplot_titles=list(model.keys()))\n",
    "\n",
    "# Loop through each column in the dataframe and add a box plot to the subplot grid\n",
    "for idx, col_name in enumerate(model):\n",
    "    row_num = (idx // num_cols) + 1\n",
    "    col_num = (idx % num_cols) + 1\n",
    "    \n",
    "    ###### Feature Imortance Dataframe ###############\n",
    "    feature_importance = model.get(col_name).best_estimator_.feature_importances_\n",
    "\n",
    "    feature_importance_df = pd.DataFrame({'feature': X_train_scaled_df.columns,\n",
    "                                      'importance': feature_importance\n",
    "                                     }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    ############ Plotting Feature Importance ################\n",
    "    \n",
    "    fig.add_trace(px.bar(data_frame= feature_importance_df,x='feature',y='importance').data[0], row=row_num, col=col_num,)\n",
    "    \n",
    "    #########################################################\n",
    "    \n",
    "    # Set the title of the subplot grid\n",
    "    fig.update_layout(height=500,width=1100, title='Feature Importance: Engineerd Features',\n",
    "                      paper_bgcolor = \"rgba(0,0,0,0)\",\n",
    "                      plot_bgcolor = \"rgba(0,0,0,0)\",                  \n",
    "                     )\n",
    "    fig.update_traces(marker_color='green')\n",
    "# Show the plot\n",
    "#fig.show()\n",
    "###############################\n",
    "fig.update_yaxes(showline=False,showgrid=False)\n",
    "fig.update_xaxes(showline=False,showgrid=False)\n",
    "##########################################\n",
    "pio.write_html(fig,file = '../Regression/tuned_models_raw4_6//featureImportance.html',config= dict(displayModeBar = False))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d0d19-e0e8-4a07-aa2c-fb6fe701ddc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Scores Metrices For Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4a19a1c2-aeb8-43b0-9f66-488193f3ce93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>model: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.5f}",
         "type": "heatmap",
         "x": [
          "best_score",
          "MSE_train",
          "MSE_test",
          "R2_train",
          "R2_test"
         ],
         "xaxis": "x",
         "y": [
          "SVR",
          "LinearRgression",
          "Lasso",
          "Ridge",
          "ElasticNet",
          "RandomForestReg",
          "DecisionTreeReg"
         ],
         "yaxis": "y",
         "z": [
          [
           0.995883923955246,
           0.125605697357327,
           1.4036397586217768,
           0.9978664792507488,
           0.9697668942570108
          ],
          [
           0.9815453598635748,
           0.6595004716924717,
           3.40215792882341,
           0.9887978175345497,
           0.9267206562191836
          ],
          [
           0.9823542512371328,
           0.6686699854136154,
           3.4437925498983373,
           0.9886420654612266,
           0.9258238848832364
          ],
          [
           0.9817322996168696,
           0.6599087143976284,
           3.3776813653403206,
           0.988790883181248,
           0.9272478588204662
          ],
          [
           0.9823103780761084,
           0.6686699854136154,
           3.4437925498983373,
           0.9886420654612266,
           0.9258238848832364
          ],
          [
           0.9748262447567498,
           0.14038653649057,
           1.4575349063102845,
           0.9976154139914044,
           0.9686060424863964
          ],
          [
           0.9383666241083128,
           0.0087959136595814,
           3.964628398103802,
           0.9998505938448958,
           0.914605561109766
          ]
         ]
        },
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>model: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.5f}",
         "type": "heatmap",
         "x": [
          "best_score",
          "MSE_train",
          "MSE_test",
          "R2_train",
          "R2_test"
         ],
         "xaxis": "x2",
         "y": [
          "SVR",
          "LinearRgression",
          "Lasso",
          "Ridge",
          "ElasticNet",
          "RandomForestReg",
          "DecisionTreeReg"
         ],
         "yaxis": "y2",
         "z": [
          [
           0.911461879336937,
           1.647436412458598,
           3.54002271783259,
           0.972016876280274,
           0.9237511758245543
          ],
          [
           0.892717883233531,
           5.412207274011198,
           11.086145748693532,
           0.9080690067306242,
           0.7612146459633333
          ],
          [
           0.893145985143321,
           5.508425038087426,
           10.2658101632541,
           0.9064346652921208,
           0.778883917830981
          ],
          [
           0.8929728787192909,
           5.418000202580407,
           10.831227747481996,
           0.9079706088588606,
           0.7667053445838877
          ],
          [
           0.893145985143321,
           5.508425038087426,
           10.2658101632541,
           0.9064346652921208,
           0.778883917830981
          ],
          [
           0.9614997366230909,
           0.2286567728064095,
           2.405338966148683,
           0.9961160681441744,
           0.9481912172517044
          ],
          [
           0.9277113732616256,
           4.4117647058823214e-05,
           2.499948630136985,
           0.999999250623838,
           0.946153412353334
          ]
         ]
        },
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>model: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.5f}",
         "type": "heatmap",
         "x": [
          "best_score",
          "MSE_train",
          "MSE_test",
          "R2_train",
          "R2_test"
         ],
         "xaxis": "x3",
         "y": [
          "SVR",
          "LinearRgression",
          "Lasso",
          "Ridge",
          "ElasticNet",
          "RandomForestReg",
          "DecisionTreeReg"
         ],
         "yaxis": "y3",
         "z": [
          [
           0.9521393771798706,
           2.2872067165424577,
           4.517512018410414,
           0.9611498276731186,
           0.9026969578847408
          ],
          [
           0.953308653781826,
           1.9553258402459712,
           5.349180407968707,
           0.9667871096655422,
           0.8847835878692705
          ],
          [
           0.9545576036573694,
           2.063135165528707,
           4.999447345162541,
           0.9649558755950116,
           0.8923165154631856
          ],
          [
           0.9537065187763378,
           1.959108384281799,
           5.237792167738509,
           0.9667228599033484,
           0.887182787824045
          ],
          [
           0.9545576036573694,
           2.063135165528707,
           4.999447345162541,
           0.9649558755950116,
           0.8923165154631856
          ],
          [
           0.967620090027866,
           0.1779249879250743,
           1.885213181377557,
           0.996977791123053,
           0.959394246913732
          ],
          [
           0.929181369671958,
           7.930299771006265e-36,
           2.9932876712328764,
           1,
           0.935527344443116
          ]
         ]
        },
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>model: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.5f}",
         "type": "heatmap",
         "x": [
          "best_score",
          "MSE_train",
          "MSE_test",
          "R2_train",
          "R2_test"
         ],
         "xaxis": "x4",
         "y": [
          "SVR",
          "LinearRgression",
          "Lasso",
          "Ridge",
          "ElasticNet",
          "RandomForestReg",
          "DecisionTreeReg"
         ],
         "yaxis": "y4",
         "z": [
          [
           0.9466019476276968,
           1.3578494272762356,
           2.464038813579707,
           0.9769357601732718,
           0.9469268766802876
          ],
          [
           0.8935602037966055,
           5.422899606203896,
           11.139113389259297,
           0.907887388276438,
           0.7600737718406498
          ],
          [
           0.8936227956734164,
           5.423838596495702,
           11.04552727920888,
           0.9078714387191086,
           0.7620895303312809
          ],
          [
           0.8936700247267177,
           5.427902095984503,
           10.88918870359619,
           0.9078024166870168,
           0.7654569190499132
          ],
          [
           0.8936728404288742,
           5.428347388887423,
           10.8811639926382,
           0.9077948530042548,
           0.7656297639222956
          ],
          [
           0.964147277528188,
           0.186381997882357,
           2.2782485632876903,
           0.9968341415386782,
           0.9509286273065382
          ],
          [
           0.9386712852633072,
           0.008025816993464,
           3.0911261119567053,
           0.9998636745988,
           0.9334199946719488
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "['Temp', 'RH', 'Ws', 'Rain', 'FFMC', 'DMC', 'DC', 'ISI', 'BUI']",
          "x": 0.2375,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "['Temp', 'RH', 'Ws', 'Rain', 'ISI/FFMC', 'ISI/DMC*BUI']",
          "x": 0.7625,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "['Temp', 'RH', 'Ws', 'Rain', 'DC', 'ISI/FFMC', 'ISI/DMC*BUI']",
          "x": 0.2375,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.45,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "['Temp', 'RH', 'ISI/FFMC', 'ISI/DMC*BUI']",
          "x": 0.7625,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.45,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "coloraxis": {
         "colorscale": [
          [
           0,
           "#00224e"
          ],
          [
           0.1111111111111111,
           "#123570"
          ],
          [
           0.2222222222222222,
           "#3b496c"
          ],
          [
           0.3333333333333333,
           "#575d6d"
          ],
          [
           0.4444444444444444,
           "#707173"
          ],
          [
           0.5555555555555556,
           "#8a8678"
          ],
          [
           0.6666666666666666,
           "#a59c74"
          ],
          [
           0.7777777777777778,
           "#c3b369"
          ],
          [
           0.8888888888888888,
           "#e1cc55"
          ],
          [
           1,
           "#fee838"
          ]
         ],
         "showscale": false
        },
        "font": {
         "size": 12
        },
        "height": 1000,
        "margin": {
         "autoexpand": true,
         "pad": 0,
         "t": 40
        },
        "paper_bgcolor": "rgba(0, 0, 0, 0)",
        "plot_bgcolor": "rgba(0, 0, 0, 0)",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 5
         },
         "x": 0.5
        },
        "width": 1100,
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          0.475
         ],
         "matches": "x3",
         "range": [
          -0.5,
          4.5
         ],
         "showticklabels": false,
         "type": "category"
        },
        "xaxis2": {
         "anchor": "y2",
         "autorange": true,
         "domain": [
          0.525,
          1
         ],
         "matches": "x4",
         "range": [
          -0.5,
          4.5
         ],
         "showticklabels": false,
         "type": "category"
        },
        "xaxis3": {
         "anchor": "y3",
         "autorange": true,
         "domain": [
          0,
          0.475
         ],
         "range": [
          -0.5,
          4.5
         ],
         "type": "category"
        },
        "xaxis4": {
         "anchor": "y4",
         "autorange": true,
         "domain": [
          0.525,
          1
         ],
         "range": [
          -0.5,
          4.5
         ],
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "automargin": true,
         "autorange": true,
         "domain": [
          0.55,
          1
         ],
         "range": [
          -0.5,
          6.5
         ],
         "type": "category"
        },
        "yaxis2": {
         "anchor": "x2",
         "automargin": true,
         "autorange": true,
         "domain": [
          0.55,
          1
         ],
         "matches": "y",
         "range": [
          -0.5,
          6.5
         ],
         "showticklabels": false,
         "type": "category"
        },
        "yaxis3": {
         "anchor": "x3",
         "automargin": true,
         "autorange": true,
         "domain": [
          0,
          0.45
         ],
         "range": [
          -0.5,
          6.5
         ],
         "type": "category"
        },
        "yaxis4": {
         "anchor": "x4",
         "automargin": true,
         "autorange": true,
         "domain": [
          0,
          0.45
         ],
         "matches": "y3",
         "range": [
          -0.5,
          6.5
         ],
         "showticklabels": false,
         "type": "category"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"bb24937c-0088-4932-ad5c-f66147f14aa9\" class=\"plotly-graph-div\" style=\"height:1000px; width:1100px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bb24937c-0088-4932-ad5c-f66147f14aa9\")) {                    Plotly.newPlot(                        \"bb24937c-0088-4932-ad5c-f66147f14aa9\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"x: %{x}<br>model: %{y}<br>color: %{z}<extra></extra>\",\"name\":\"0\",\"texttemplate\":\"%{z:.5f}\",\"x\":[\"best_score\",\"MSE_train\",\"MSE_test\",\"R2_train\",\"R2_test\"],\"xaxis\":\"x\",\"y\":[\"SVR\",\"LinearRgression\",\"Lasso\",\"Ridge\",\"ElasticNet\",\"RandomForestReg\",\"DecisionTreeReg\"],\"yaxis\":\"y\",\"z\":[[0.995883923955246,0.125605697357327,1.4036397586217768,0.9978664792507488,0.9697668942570108],[0.9815453598635748,0.6595004716924717,3.40215792882341,0.9887978175345497,0.9267206562191836],[0.9823542512371328,0.6686699854136154,3.4437925498983373,0.9886420654612266,0.9258238848832364],[0.9817322996168696,0.6599087143976284,3.3776813653403206,0.988790883181248,0.9272478588204662],[0.9823103780761084,0.6686699854136154,3.4437925498983373,0.9886420654612266,0.9258238848832364],[0.9748262447567498,0.14038653649057,1.4575349063102845,0.9976154139914044,0.9686060424863964],[0.9383666241083128,0.0087959136595814,3.964628398103802,0.9998505938448958,0.914605561109766]],\"type\":\"heatmap\"},{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"x: %{x}<br>model: %{y}<br>color: %{z}<extra></extra>\",\"name\":\"0\",\"texttemplate\":\"%{z:.5f}\",\"x\":[\"best_score\",\"MSE_train\",\"MSE_test\",\"R2_train\",\"R2_test\"],\"xaxis\":\"x2\",\"y\":[\"SVR\",\"LinearRgression\",\"Lasso\",\"Ridge\",\"ElasticNet\",\"RandomForestReg\",\"DecisionTreeReg\"],\"yaxis\":\"y2\",\"z\":[[0.911461879336937,1.647436412458598,3.54002271783259,0.972016876280274,0.9237511758245543],[0.892717883233531,5.412207274011198,11.086145748693532,0.9080690067306242,0.7612146459633333],[0.893145985143321,5.508425038087426,10.2658101632541,0.9064346652921208,0.778883917830981],[0.8929728787192909,5.418000202580407,10.831227747481996,0.9079706088588606,0.7667053445838877],[0.893145985143321,5.508425038087426,10.2658101632541,0.9064346652921208,0.778883917830981],[0.9614997366230909,0.2286567728064095,2.405338966148683,0.9961160681441744,0.9481912172517044],[0.9277113732616256,4.4117647058823214e-05,2.499948630136985,0.999999250623838,0.946153412353334]],\"type\":\"heatmap\"},{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"x: %{x}<br>model: %{y}<br>color: %{z}<extra></extra>\",\"name\":\"0\",\"texttemplate\":\"%{z:.5f}\",\"x\":[\"best_score\",\"MSE_train\",\"MSE_test\",\"R2_train\",\"R2_test\"],\"xaxis\":\"x3\",\"y\":[\"SVR\",\"LinearRgression\",\"Lasso\",\"Ridge\",\"ElasticNet\",\"RandomForestReg\",\"DecisionTreeReg\"],\"yaxis\":\"y3\",\"z\":[[0.9521393771798706,2.2872067165424577,4.517512018410414,0.9611498276731186,0.9026969578847408],[0.953308653781826,1.9553258402459712,5.349180407968707,0.9667871096655422,0.8847835878692705],[0.9545576036573694,2.063135165528707,4.999447345162541,0.9649558755950116,0.8923165154631856],[0.9537065187763378,1.959108384281799,5.237792167738509,0.9667228599033484,0.887182787824045],[0.9545576036573694,2.063135165528707,4.999447345162541,0.9649558755950116,0.8923165154631856],[0.967620090027866,0.1779249879250743,1.885213181377557,0.996977791123053,0.959394246913732],[0.929181369671958,7.930299771006265e-36,2.9932876712328764,1.0,0.935527344443116]],\"type\":\"heatmap\"},{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"x: %{x}<br>model: %{y}<br>color: %{z}<extra></extra>\",\"name\":\"0\",\"texttemplate\":\"%{z:.5f}\",\"x\":[\"best_score\",\"MSE_train\",\"MSE_test\",\"R2_train\",\"R2_test\"],\"xaxis\":\"x4\",\"y\":[\"SVR\",\"LinearRgression\",\"Lasso\",\"Ridge\",\"ElasticNet\",\"RandomForestReg\",\"DecisionTreeReg\"],\"yaxis\":\"y4\",\"z\":[[0.9466019476276968,1.3578494272762356,2.464038813579707,0.9769357601732718,0.9469268766802876],[0.8935602037966055,5.422899606203896,11.139113389259297,0.907887388276438,0.7600737718406498],[0.8936227956734164,5.423838596495702,11.04552727920888,0.9078714387191086,0.7620895303312809],[0.8936700247267177,5.427902095984503,10.88918870359619,0.9078024166870168,0.7654569190499132],[0.8936728404288742,5.428347388887423,10.8811639926382,0.9077948530042548,0.7656297639222956],[0.964147277528188,0.186381997882357,2.2782485632876903,0.9968341415386782,0.9509286273065382],[0.9386712852633072,0.008025816993464,3.0911261119567053,0.9998636745988,0.9334199946719488]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.475],\"matches\":\"x3\",\"showticklabels\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.55,1.0],\"automargin\":true},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.525,1.0],\"matches\":\"x4\",\"showticklabels\":false},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.55,1.0],\"matches\":\"y\",\"showticklabels\":false,\"automargin\":true},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.475]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.45],\"automargin\":true},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.525,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.45],\"matches\":\"y3\",\"showticklabels\":false,\"automargin\":true},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"['Temp', 'RH', 'Ws', 'Rain', 'FFMC', 'DMC', 'DC', 'ISI', 'BUI']\",\"x\":0.2375,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"['Temp', 'RH', 'Ws', 'Rain', 'ISI/FFMC', 'ISI/DMC*BUI']\",\"x\":0.7625,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"['Temp', 'RH', 'Ws', 'Rain', 'DC', 'ISI/FFMC', 'ISI/DMC*BUI']\",\"x\":0.2375,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.45,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"['Temp', 'RH', 'ISI/FFMC', 'ISI/DMC*BUI']\",\"x\":0.7625,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.45,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"coloraxis\":{\"showscale\":false,\"colorscale\":[[0.0,\"#00224e\"],[0.1111111111111111,\"#123570\"],[0.2222222222222222,\"#3b496c\"],[0.3333333333333333,\"#575d6d\"],[0.4444444444444444,\"#707173\"],[0.5555555555555556,\"#8a8678\"],[0.6666666666666666,\"#a59c74\"],[0.7777777777777778,\"#c3b369\"],[0.8888888888888888,\"#e1cc55\"],[1.0,\"#fee838\"]]},\"margin\":{\"t\":40,\"pad\":0,\"autoexpand\":true},\"title\":{\"font\":{\"size\":5},\"x\":0.5},\"font\":{\"size\":12},\"height\":1000,\"width\":1100,\"paper_bgcolor\":\"rgba(0,0,0,0)\",\"plot_bgcolor\":\"rgba(0,0,0,0)\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('bb24937c-0088-4932-ad5c-f66147f14aa9');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.subplots as sp\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "df1 = pd.read_csv('../Regression/tuned_models_raw4_3/model_scores.csv',index_col='model')\n",
    "df2 = pd.read_csv('../Regression/tuned_models_raw4_4/model_scores.csv',index_col='model')\n",
    "df3 = pd.read_csv('../Regression/tuned_models_raw4_5/model_scores.csv',index_col='model')\n",
    "df4 = pd.read_csv('../Regression/tuned_models_raw4_6/model_scores.csv',index_col='model')\n",
    "#df2=model_scores.set_index('model')\n",
    "\n",
    "# Create a sample dataframe\n",
    "\n",
    "\n",
    "# Define the number of rows and columns for the subplot grid\n",
    "num_rows = 2\n",
    "num_cols = 2\n",
    "##########\n",
    "title1 = ['Temp', 'RH', 'Ws', 'Rain', 'FFMC', 'DMC', 'DC', 'ISI','BUI']\n",
    "title2 = ['Temp', 'RH', 'Ws', 'Rain', 'ISI/FFMC', 'ISI/DMC*BUI']\n",
    "title3 = ['Temp', 'RH', 'Ws', 'Rain', 'DC', 'ISI/FFMC', 'ISI/DMC*BUI']\n",
    "title4 = ['Temp', 'RH', 'ISI/FFMC', 'ISI/DMC*BUI']\n",
    "\n",
    "\n",
    "# Create a subplot grid with the specified number of rows and columns\n",
    "fig = sp.make_subplots(rows=num_rows, cols=num_cols,\n",
    "                       subplot_titles=[f\"{title1}\",f\"{title2}\",f\"{title3}\",f\"{title4}\"],\n",
    "                       shared_yaxes=True,\n",
    "                       shared_xaxes=True,\n",
    "                       vertical_spacing=0.1,\n",
    "                      horizontal_spacing=0.05)\n",
    "\n",
    "fig.add_trace(px.imshow(df1,text_auto='.5f',color_continuous_scale='Cividis', title='').data[0],row=1, col=1)\n",
    "fig.add_trace(px.imshow(df2,text_auto='.5f',color_continuous_scale='Cividis', title='').data[0],row=1, col=2)    \n",
    "fig.add_trace(px.imshow(df3,text_auto='.5f',color_continuous_scale='Cividis', title='').data[0],row=2, col=1)    \n",
    "fig.add_trace(px.imshow(df4,text_auto='.5f',color_continuous_scale='Cividis', title='').data[0],row=2, col=2)    \n",
    "\n",
    "\n",
    "\n",
    "# Set the title of the subplot grid\n",
    "fig.update_coloraxes(showscale=False)\n",
    "fig.update_layout(margin=dict(t=40,pad=0),\n",
    "                  title_x=0.5,\n",
    "                  title_font_size=5,\n",
    "                  coloraxis=dict(colorscale='Cividis'),\n",
    "                  height=1000,width=1100,\n",
    "                  paper_bgcolor = \"rgba(0,0,0,0)\",\n",
    "                    plot_bgcolor = \"rgba(0,0,0,0)\",                  \n",
    "                    margin_autoexpand=True,\n",
    "                    font=dict(size = 12))\n",
    "\n",
    "fig.update_yaxes(automargin=True)\n",
    "\n",
    "\n",
    "fig.show()\n",
    "pio.write_html(fig,file = '../Regression//model_scores.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147485e-1db6-4bc9-89e9-11f59c746815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c669f-0192-4af4-b7bd-c1feb7100dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a2e9ae-d6b3-4b65-93c3-d42624613511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce51303-89d6-4aeb-8c15-bd5386a2841e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
