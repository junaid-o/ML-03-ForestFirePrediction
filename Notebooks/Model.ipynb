{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15335b87-ba76-4307-9af0-0c04efcefdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import validation_curve, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import learning_curve, validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7bd65-baed-45e3-ac1b-e1c541316320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../DataSet/train_raw4_trans.csv')\n",
    "test = pd.read_csv('../DataSet/test_raw4_trans.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a053774-0143-4b15-a2bf-72e8a4ac5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c16e2-2d58-4fbd-9413-9fedcc9babbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c50ca7-980a-4ef7-a9d3-9a23adac5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['FWI','FWI/FFMC','(DMC/FWI)/ISI','FWI/BUI'],axis=1, inplace=True)\n",
    "test.drop(['FWI','FWI/FFMC','(DMC/FWI)/ISI','FWI/BUI'],axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c871b-b309-4781-9e64-332560153f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751838f4-e6ad-4034-b995-4f4a44b92214",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month_07'] = train['month_07'].astype('uint8')\n",
    "train['month_08'] = train['month_08'].astype('uint8')\n",
    "train['month_09'] = train['month_09'].astype('uint8')\n",
    "train['Classes_not fire'] = train['Classes_not fire'].astype('uint8')\n",
    "\n",
    "test['month_07'] = test['month_07'].astype('uint8')\n",
    "test['month_08'] = test['month_08'].astype('uint8')\n",
    "test['month_09'] = test['month_09'].astype('uint8')\n",
    "test['Classes_not fire'] = test['Classes_not fire'].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c8784c-e39b-4ac3-bad7-f7bf6bc88446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598b98f-a40a-46c3-a0bb-45974ffe99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73fc26-8203-407d-bb7b-1641c611c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Classes_not fire'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d4d81-9f46-4bc2-a4f0-027160740bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Classes_not fire'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc2e4a-8ae5-4489-8f4a-6f28ed3b6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,:-1]\n",
    "X_test = test.iloc[:,:-1]\n",
    "\n",
    "#X_test.head()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3773a69-9034-4c6c-b4e7-62e81114d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Classes_not fire']\n",
    "y_test = test[['Classes_not fire']]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ed864-99b9-4a0b-ac71-0010f38d65e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb4ded-1a16-41d2-abf4-253d95a22c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "svc = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "adaBoost = AdaBoostClassifier()\n",
    "#lgbm = LGBMClassifier()\n",
    "gbt = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5233dc-edbf-4ca7-b382-3608c1a48555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'LogisticRegression': lr,\n",
    "    'SVC': svc,\n",
    "    'KNeighbors': knn,\n",
    "    'RandomForest': rf,\n",
    "    'AdaBoost': adaBoost,\n",
    "    \n",
    "    'GradientBoostingTrees': gbt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e08c0-902b-44f4-8c14-8be2b5af314e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \n",
    "    'LogisticRegression':{'penalty':['elasticnet'],\n",
    "                          'solver':['saga'],\n",
    "                          'max_iter':[3000],\n",
    "                          'l1_ratio':[1,0.8,0.6,0.5,0.4,0.2,0],                          \n",
    "                          'C': [10e-3,10e-2,10e-1,1.0],\n",
    "                         'class_weight': ['balanced',None]},\n",
    "    \n",
    "    'SVC': {'C':[10e-3,10e-2,10e-1,1.0],\n",
    "           'kernel':['linear','rbf','sigmoid'],\n",
    "           'gamma':['scale','auto']},\n",
    "    \n",
    "    'KNeighbors': {'n_neighbors':[3,5,9,11,13,15],  # n_neighbors should always be odd numbers\n",
    "                     'weights': ['uniform','distance']},\n",
    "    \n",
    "    'RandomForest': {'n_estimators':[100,300],\n",
    "                    'criterion':['gini','log_loss'],\n",
    "                    'max_depth':[2,4,5,6,8,10,15,20],\n",
    "                    'class_weight': ['balanced',None]},\n",
    "    \n",
    "    'AdaBoost': {'n_estimators': [50,60,70,90,100,110],\n",
    "                'learning_rate': [10e-3,10e-2,10e-1,1.0]},\n",
    "    \n",
    "    'GradientBoostingTrees': {'loss': ['log_loss', 'exponential'],\n",
    "                             'learning_rate': [10e-3,10e-2,10e-1,1.0],\n",
    "                             'n_estimators': [100,200,250],\n",
    "                             'max_depth': [2,3,4,5,6,7,8,9]},\n",
    "    \n",
    "           \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ac2df-90dd-49f1-a2d2-770e90ec106e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf,parameters):\n",
    "    \n",
    "    gs = GridSearchCV(clf,param_grid=parameters, cv=5,refit='roc_auc', verbose=2, scoring=['f1','roc_auc']).fit(X_train, y_train)\n",
    "    #y_pred = gs.predict(X_test)    \n",
    "    \n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a37789-29f1-4eb4-a7c7-c535324c047a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuned_models = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    print(\"\\nFor \",name)\n",
    "    parameters = param_grid[name]\n",
    "    current_best_model = train_classifier(clf,parameters)\n",
    "    \n",
    "    ####### Saving Trainined MOdel #####################\n",
    "    \n",
    "    # create the directory if it does not exist\n",
    "    if not os.path.exists('../tuned_models_raw5_trans'):\n",
    "        os.makedirs('../tuned_models_raw5_trans')\n",
    "\n",
    "    filename = 'tuned_' + re.search(r'^[^\\(]+', str(current_best_model.best_estimator_))[0] + '_model.pkl'\n",
    "    filepath = os.path.join('../tuned_models_raw5_trans', filename)\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(current_best_model, file)\n",
    "            \n",
    "    ##############################################################################\n",
    "    \n",
    "    tuned_models.append(current_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a40e07-8764-4aaa-815e-1bbefa37bc16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuned_models;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeffc09a-f2a7-481b-895c-0bb0c5d2fa86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e2ae5b62-45e5-4e87-a4fc-49159ffe7345",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# create the directory if it does not exist\n",
    "if not os.path.exists('../tuned_models'):\n",
    "    os.makedirs('../tuned_models')\n",
    "\n",
    "for model in tuned_models:\n",
    "    filename = 'tuned_' + re.search(r'^[^\\(]+', str(model.best_estimator_))[0] + '_model.pkl'\n",
    "    filepath = os.path.join('../tuned_models', filename)\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792cb901-d4eb-4e6b-a0b2-95ec77ef70c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Import & Model Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd4e89-52d5-4006-91d9-e2f5edac11fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_model = pickle.load(open('../tuned_models_raw4_trans/tuned_SVC_model.pkl','rb'))\n",
    "AdaBoost_model = pickle.load(open('../tuned_models_raw4_trans/tuned_AdaBoostClassifier_model.pkl','rb'))\n",
    "GBDT_model = pickle.load(open('../tuned_models_raw4_trans/tuned_GradientBoostingClassifier_model.pkl','rb'))\n",
    "knn_model = pickle.load(open('../tuned_models_raw4_trans/tuned_KNeighborsClassifier_model.pkl','rb'))\n",
    "lr_model = pickle.load(open('../tuned_models_raw4_trans/tuned_LogisticRegression_model.pkl','rb'))\n",
    "RF_model = pickle.load(open('../tuned_models_raw4_trans/tuned_RandomForestClassifier_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a55e50-2f07-4bd6-80dd-8393436bcee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_model = pickle.load(open('../tuned_models_raw/tuned_SVC_model.pkl','rb'))\n",
    "svm_model.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47691825-7d72-477e-860e-9486ec5efbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_scores = pd.DataFrame({\n",
    "    'model': ['SVM','KNN','AdaBoost','GBDT','RF','LR'],\n",
    "    'balanced_accuracy_train': [balanced_accuracy_score(y_train,svm_model.predict(X_train)),\n",
    "                                balanced_accuracy_score(y_train,knn_model.predict(X_train)),\n",
    "                                balanced_accuracy_score(y_train,AdaBoost_model.predict(X_train)),\n",
    "                                balanced_accuracy_score(y_train,GBDT_model.predict(X_train)),\n",
    "                                balanced_accuracy_score(y_train,RF_model.predict(X_train)),\n",
    "                                balanced_accuracy_score(y_train,lr_model.predict(X_train)),\n",
    "                               ]})\n",
    "\n",
    "\n",
    "balanced_accuracy_test =  [balanced_accuracy_score(y_test,svm_model.predict(X_test)),\n",
    "                           balanced_accuracy_score(y_test,knn_model.predict(X_test)),\n",
    "                           balanced_accuracy_score(y_test,AdaBoost_model.predict(X_test)),\n",
    "                           balanced_accuracy_score(y_test,GBDT_model.predict(X_test)),\n",
    "                           balanced_accuracy_score(y_test,RF_model.predict(X_test)),\n",
    "                           balanced_accuracy_score(y_test,lr_model.predict(X_test)),                           \n",
    "                          ] \n",
    "\n",
    "f1_score_train = [f1_score(y_train,svm_model.predict(X_train)),\n",
    "                  \n",
    "                  f1_score(y_train,knn_model.predict(X_train)),\n",
    "                  f1_score(y_train,AdaBoost_model.predict(X_train)),\n",
    "                  f1_score(y_train,GBDT_model.predict(X_train)),\n",
    "                  f1_score(y_train,RF_model.predict(X_train)),\n",
    "                  f1_score(y_train,lr_model.predict(X_train)),\n",
    "                 ]\n",
    "\n",
    "\n",
    "f1_score_test = [f1_score(y_test,svm_model.predict(X_test)),\n",
    "                 \n",
    "                 f1_score(y_test,knn_model.predict(X_test)),\n",
    "                 f1_score(y_test,AdaBoost_model.predict(X_test)),\n",
    "                 f1_score(y_test,GBDT_model.predict(X_test)),\n",
    "                 f1_score(y_test,RF_model.predict(X_test)),\n",
    "                 f1_score(y_test,lr_model.predict(X_test)),\n",
    "                ]\n",
    "\n",
    "roc_auc_train =  [roc_auc_score(y_train,svm_model.predict(X_train)),\n",
    "                  \n",
    "                  roc_auc_score(y_train,knn_model.predict(X_train)),\n",
    "                  roc_auc_score(y_train,AdaBoost_model.predict(X_train)),\n",
    "                  roc_auc_score(y_train,GBDT_model.predict(X_train)),\n",
    "                  roc_auc_score(y_train,RF_model.predict(X_train)),\n",
    "                  roc_auc_score(y_train,lr_model.predict(X_train)),\n",
    "                 ]\n",
    "\n",
    "roc_auc_test = [roc_auc_score(y_test,svm_model.predict(X_test)),\n",
    "                \n",
    "                roc_auc_score(y_test,knn_model.predict(X_test)),\n",
    "                roc_auc_score(y_test,AdaBoost_model.predict(X_test)),\n",
    "                roc_auc_score(y_test,GBDT_model.predict(X_test)),\n",
    "                roc_auc_score(y_test,RF_model.predict(X_test)),\n",
    "                roc_auc_score(y_test,lr_model.predict(X_test)),\n",
    "                ] \n",
    "\n",
    "precision_train =  [precision_score(y_train,svm_model.predict(X_train)),\n",
    "                    \n",
    "                    precision_score(y_train,knn_model.predict(X_train)),\n",
    "                    precision_score(y_train,AdaBoost_model.predict(X_train)),\n",
    "                    precision_score(y_train,GBDT_model.predict(X_train)),\n",
    "                    precision_score(y_train,RF_model.predict(X_train)),\n",
    "                    precision_score(y_train,lr_model.predict(X_train)),\n",
    "                   ]\n",
    "\n",
    "precision_test = [precision_score(y_test,svm_model.predict(X_test)),\n",
    "                  \n",
    "                  precision_score(y_test,knn_model.predict(X_test)),\n",
    "                  precision_score(y_test,AdaBoost_model.predict(X_test)),\n",
    "                  precision_score(y_test,GBDT_model.predict(X_test)),\n",
    "                  precision_score(y_test,RF_model.predict(X_test)),\n",
    "                  precision_score(y_test,lr_model.predict(X_test)),\n",
    "                 ] \n",
    "\n",
    "\n",
    "accuracy_train =  [accuracy_score(y_train,svm_model.predict(X_train)),\n",
    "                   \n",
    "                   accuracy_score(y_train,knn_model.predict(X_train)),\n",
    "                   accuracy_score(y_train,AdaBoost_model.predict(X_train)),\n",
    "                   accuracy_score(y_train,GBDT_model.predict(X_train)),\n",
    "                   accuracy_score(y_train,RF_model.predict(X_train)),\n",
    "                   accuracy_score(y_train,lr_model.predict(X_train)),\n",
    "                 ]\n",
    "\n",
    "\n",
    "accuracy_test =  [accuracy_score(y_test,svm_model.predict(X_test)),\n",
    "                  accuracy_score(y_test,knn_model.predict(X_test)),\n",
    "                  accuracy_score(y_test,AdaBoost_model.predict(X_test)),\n",
    "                  accuracy_score(y_test,GBDT_model.predict(X_test)),\n",
    "                  accuracy_score(y_test,RF_model.predict(X_test)),\n",
    "                  accuracy_score(y_test,lr_model.predict(X_test)),\n",
    "                 ] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_score= [svm_model.best_score_, knn_model.best_score_, AdaBoost_model.best_score_,\n",
    "          GBDT_model.best_score_, RF_model.best_score_, lr_model.best_score_]\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "model_scores['balanced_accuracy_test'],model_scores['f1_train'],model_scores['f1_test'],model_scores['roc_auc_train'],model_scores['roc_auc_test'],model_scores['precision_train'],model_scores['precision_test'],model_scores['accuracy_train'],model_scores['accuracy_test'] = [balanced_accuracy_test,f1_score_train,f1_score_test,roc_auc_train,roc_auc_test, precision_train,precision_test,accuracy_train,accuracy_test]\n",
    "\n",
    "model_scores.insert(1,'best_score',best_score)\n",
    "\n",
    "##############################################################################\n",
    "model_scores.to_csv('../tuned_models_raw5_trans//model_scores.csv',index=False)\n",
    "########################\n",
    "\n",
    "model_scores.style.highlight_max(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9b593-1b76-482c-9417-dfbbb2f4515e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ff5a1-3d6a-4d51-87bb-33aaceb15f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "df  = pd.read_csv('../tuned_models_raw5_trans//model_scores.csv')\n",
    "#df = df.drop('Unnamed: 0', axis =1)\n",
    "df = df.set_index('model')\n",
    "df1 = df[['f1_train','roc_auc_train','balanced_accuracy_train','precision_train','accuracy_train']]\n",
    "df2 = df[['f1_test','roc_auc_test','balanced_accuracy_test','precision_test','accuracy_test']]\n",
    "\n",
    "#########################################################\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def multi_plot(df1,df2, title, addAll = True):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "\n",
    "    for column1 in df1.columns.to_list():\n",
    "        f1= fig.add_trace(\n",
    "            go.Bar(\n",
    "                x = df1.index,\n",
    "                y = df1[column1],\n",
    "                name = column1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for column2 in df2.columns.to_list():\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x = df2.index,\n",
    "                y = df2[column2],\n",
    "                name = column2\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    button_all = [dict(label = 'Train',\n",
    "                      method = 'update',\n",
    "                      args = [{'visible': df1.columns.isin(df1.columns),\n",
    "                               'title': 'All',\n",
    "                               'showlegend':True}]),\n",
    "                  dict(label = 'Select',\n",
    "                      method = 'update',\n",
    "                      args = [{'visible': df2.columns.isin(df2.columns),\n",
    "                               'title': 'All',\n",
    "                               'showlegend':True}]),\n",
    "                  \n",
    "                  ]\n",
    "                 \n",
    "                \n",
    "\n",
    "    def create_layout_button(column1):\n",
    "        return dict(label = column1,\n",
    "                    method = 'update',\n",
    "                    args = [{'visible': df1.columns.isin([column1]),\n",
    "                             'title': column1,\n",
    "                             'showlegend': True}])\n",
    "    \n",
    "    def create_layout_button2(column2):\n",
    "        return dict(label = column2,\n",
    "                    method = 'update',\n",
    "                    args = [{'visible': df2.columns.isin([column2]),\n",
    "                             'title': column2,\n",
    "                             'showlegend': True}]\n",
    "                   )\n",
    "    # Update remaining layout properties\n",
    "\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    " #           go.layout.Updatemenu(\n",
    " #           active = 0,\n",
    " #           buttons = ([button_all[0]] * addAll) + list(df1.columns.map(lambda column: create_layout_button(column))),\n",
    "                \n",
    "  #          direction=\"down\",\n",
    "  #          pad={\"r\": 10, \"t\": 10},\n",
    "  #          showactive=True,\n",
    "  #          x=-0.5,\n",
    "  #          xanchor=\"left\",\n",
    " #           y=1,\n",
    "  #          yanchor=\"top\"),\n",
    "            \n",
    "            \n",
    "            go.layout.Updatemenu(\n",
    "            active = 0,\n",
    "                visible=True,\n",
    "            buttons = ([button_all[1]] * addAll) + list(df2.columns.map(lambda column: create_layout_button2(column))),\n",
    "               \n",
    "            direction=\"right\",\n",
    "            pad={\"r\": 5, \"t\": 5,\"l\":5},\n",
    "            showactive=True,\n",
    "            x=-0.03,\n",
    "            xanchor=\"left\",\n",
    "            y=1.1,\n",
    "            yanchor=\"bottom\"),\n",
    "            \n",
    "            \n",
    "            \n",
    "        ],\n",
    "         yaxis_type=\"log\"       \n",
    "    )\n",
    "    # Update remaining layout properties\n",
    "    fig.update_layout(\n",
    "        title_text=title,\n",
    "        title_y=0.96,\n",
    "        \n",
    "        height=400,\n",
    "        #width = 1000,\n",
    "        showlegend=True,\n",
    "        legend=dict(yanchor=\"bottom\",\n",
    "                                  y=-0.5,\n",
    "                                  xanchor=\"center\",\n",
    "                                  x=0.5,\n",
    "                                  orientation='h'),\n",
    "        paper_bgcolor = \"rgba(0,0,0,0)\",\n",
    "        plot_bgcolor = \"rgba(0,0,0,0)\",\n",
    "        margin_autoexpand=True,\n",
    "        autosize=True,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    fig.show(scale=200, config= dict(displayModeBar = False))\n",
    "       \n",
    "    ############################################################\n",
    "    \n",
    "    # Writing and exporting interactive figure as html file \n",
    "    \n",
    "    f1.write_html('../tuned_models_raw5_trans/Model_Scores.html',config= dict(displayModeBar = False))\n",
    "        \n",
    "########################################################################################\n",
    "\n",
    "multi_plot(df1,df2, title=\"Model Scores\")  \n",
    "\n",
    "#https://towardsdatascience.com/how-to-create-an-interactive-dropdown-in-jupyter-322277f58a68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad0443-d9e0-492d-883c-a260da6ccf54",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed8feb-407b-404f-9e52-b65d1df47e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'LogisticRegression': lr_model,\n",
    "    'SVC': svm_model,\n",
    "    'KNeighbors': knn_model,\n",
    "    'RandomForest': RF_model,\n",
    "    'AdaBoost': AdaBoost_model,\n",
    "    \n",
    "    'GradientBoostingTrees': GBDT_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2178c-5af4-49b3-8f92-33b2868fc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \n",
    "    'LogisticRegression':{                         \n",
    "                          'max_iter':[100,1000,2000,3000],\n",
    "                          'l1_ratio':[1,0.8,0.6,0.5,0.4,0.2,0],                          \n",
    "                          'C': [10e-3,10e-2,10e-1,1.0,10,20,30],\n",
    "                         },\n",
    "    \n",
    "    'SVC': {'C':[10e-2,10e-1,1.0,10,20,30,40,70],\n",
    "           \n",
    "           \n",
    "           },\n",
    "    \n",
    "    'KNeighbors': {'n_neighbors':[3,5,9,11,13,15,19],  # n_neighbors should always be odd numbers\n",
    "                     \n",
    "                  },\n",
    "    \n",
    "    'RandomForest': {'n_estimators':[100,300,500],\n",
    "                    \n",
    "                    'max_depth':[2,4,5,6,7,8,10,15,20],\n",
    "                    \n",
    "                    },\n",
    "    \n",
    "    'AdaBoost': {'n_estimators': [50,70,90,100,110,140,170],\n",
    "                'learning_rate': [10e-3,10e-2,10e-1,1.0]\n",
    "                },\n",
    "    \n",
    "    'GradientBoostingTrees': {\n",
    "                             'learning_rate': [10e-3,10e-2,10e-1,1.0],\n",
    "                             'n_estimators': [100,200,400,600],\n",
    "                             'max_depth': [2,3,4,5,6,7,8,9,11,15,20]\n",
    "                             },\n",
    "          \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36101a-3ccc-4957-9247-961571f8a11e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(12, 12))\n",
    "fig.suptitle('Validation Curves for Different Classifiers:CV=3', fontsize=24, fontweight='bold', y=1.0)\n",
    "\n",
    "axes = axes.flatten()\n",
    "i = 0\n",
    "\n",
    "for j, (clf_name, clf) in enumerate(clfs.items()):\n",
    "    for k, (param_name,param_value) in enumerate(param_grid[clf_name].items()):\n",
    "        ax = axes[i]\n",
    "        i += 1\n",
    "        \n",
    "        train_scores, valid_scores = validation_curve(clf.best_estimator_,\n",
    "                                                      X_train, y_train,\n",
    "                                                      cv=3,\n",
    "                                                      param_name=param_name,\n",
    "                                                      param_range=param_value)\n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        valid_mean = np.mean(valid_scores, axis=1)\n",
    "        valid_std = np.std(valid_scores, axis=1)\n",
    "        ax.set_title(f'{clf_name} - {param_name}')\n",
    "        ax.set_xlabel(param_name)\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_ylim(0.0, 1.1)\n",
    "        ax.set_xscale('log') \n",
    "        lw = 2\n",
    "        \n",
    "        try:\n",
    "            ax.semilogx(param_value, train_mean, label='Training score', color='darkorange', lw=lw)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        ax.fill_between(param_value, train_mean - train_std, train_mean + train_std, alpha=0.2, color='darkorange', lw=lw)\n",
    "        \n",
    "        try:\n",
    "            ax.semilogx(param_value, valid_mean, label='Cross-validation score', color='navy', lw=lw)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        ax.fill_between(param_value, valid_mean - valid_std, valid_mean + valid_std, alpha=0.2, color='navy', lw=lw)\n",
    "        ax.legend(loc='best')\n",
    "        \n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "##########################################################\n",
    "\n",
    "#fig.figure.savefig(f'../AutoViz_Plots/ValidationCurve/{name}_{key}.svg',transparent=True,dpi=300)\n",
    "\n",
    "if not os.path.exists(f'../AutoViz_Plots/ValidationCurve_raw5_trans'):\n",
    "    os.makedirs(f'../AutoViz_Plots/ValidationCurve_raw5_trans')\n",
    "plt.savefig(f'../AutoViz_Plots/ValidationCurve_raw5_trans/ValidationCurve.svg',format='svg',dpi=600)\n",
    "#####################################################\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f30de47-26b2-4ce5-a1c8-e38cc15e4bf3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "############# ORIGINAL\n",
    "\n",
    "\n",
    "\n",
    "#for name, clf in {'SVC':svm_model, \"AdaBoost\":AdaBoost_model, \"GradientBoostingTrees\":GBDT_model,\"KNeighbors\":knn_model,\"LogisticRegression\":lr_model,\"RandomForest\":RF_model}.items():\n",
    "\n",
    "\n",
    "for name, clf in {'SVC':svm_model, \"AdaBoost\":AdaBoost_model, \"GradientBoostingTrees\":GBDT_model,\"KNeighbors\":knn_model,\"LogisticRegression\":lr_model}.items():\n",
    "    #print(\"\\nFor \",name)\n",
    "    \n",
    "    parameters = param_grid[name]\n",
    "    #print(parameters.keys())\n",
    "    \n",
    "    for key in parameters.keys():\n",
    "        #print(key)\n",
    "        #print(parameters[key])\n",
    "\n",
    "        param_name = key\n",
    "        param_range = parameters[key]\n",
    "        \n",
    "        # compute the training and validation scores for the given hyperparameter range\n",
    "        train_scores, valid_scores = validation_curve(clf.best_estimator_,\n",
    "                                                      X_train, y_train,\n",
    "                                                      cv=2,\n",
    "                                                      param_name=param_name,\n",
    "                                                      param_range=param_range)\n",
    "\n",
    "\n",
    "        # print the mean training and validation scores for each hyperparameter value\n",
    "\n",
    "        #print('Training scores:\\n', np.mean(train_scores, axis=1))\n",
    "        #print('Validation scores:\\n', np.mean(valid_scores, axis=1))\n",
    "\n",
    "        ###############################################################\n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        valid_mean = np.mean(valid_scores, axis=1)\n",
    "        valid_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "        # plot the validation curve\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.title(f'Validation Curve: {clf.best_estimator_}')\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel('Score')\n",
    "        plt.ylim(0.0, 1.1)\n",
    "        lw = 2\n",
    "\n",
    "        try:\n",
    "            plt.semilogx(param_range, train_mean, label='Training score',\n",
    "                         color='darkorange', lw=lw)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        plt.fill_between(param_range, train_mean - train_std,\n",
    "                         train_mean + train_std, alpha=0.2,\n",
    "                         color='darkorange', lw=lw)\n",
    "        try:\n",
    "            plt.semilogx(param_range, valid_mean, label='Cross-validation score',\n",
    "                         color='navy', lw=lw)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        plt.fill_between(param_range, valid_mean - valid_std,\n",
    "                         valid_mean + valid_std, alpha=0.2,\n",
    "                         color='navy', lw=lw)\n",
    "\n",
    "\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "        plt.show()        \n",
    "        #fig.figure.savefig(f'../AutoViz_Plots/ValidationCurve/{name}_{key}.svg',transparent=True,dpi=300)\n",
    "        \n",
    "        if not os.path.exists(f'../AutoViz_Plots/ValidationCurve_regenerated/{name}'):\n",
    "            os.makedirs(f'../AutoViz_Plots/ValidationCurve_regenerated/{name}')\n",
    "        plt.savefig(f'../AutoViz_Plots/ValidationCurve_regenerated/{name}/{key}.svg',format='svg',dpi=400)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ae4ab1d-f630-43dc-b5bd-0c5dc355ac60",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#    'RandomForest': {'n_estimators':[100],\n",
    "#                    'criterion':['gini','log_loss'],\n",
    "#                    'max_depth':[2,3,4,5,6,7,8,9,10,12,14,15,18],\n",
    "#                    'class_weight': ['balanced',None]},\n",
    "\n",
    "param_name='max_depth'\n",
    "param_range=[2,3,4,5,6,7,8,9,10,15]\n",
    "try:\n",
    "    # compute the training and validation scores for the given hyperparameter range\n",
    "    train_scores, valid_scores = validation_curve(\n",
    "        RF_model.best_estimator_, X_train, y_train, cv=5, param_name=param_name, param_range=param_range)\n",
    "except:\n",
    "    pass\n",
    "# print the mean training and validation scores for each hyperparameter value\n",
    "print('Training scores:\\n', np.mean(train_scores, axis=1))\n",
    "print('Validation scores:\\n', np.mean(valid_scores, axis=1))\n",
    "###############################################################\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "valid_mean = np.mean(valid_scores, axis=1)\n",
    "valid_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "# plot the validation curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Validation Curve')\n",
    "plt.xlabel(param_name)\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "\n",
    "\n",
    "plt.semilogx(param_range, train_mean, label='Training score',\n",
    "             color='darkorange', lw=lw)\n",
    "\n",
    "\n",
    "plt.fill_between(param_range, train_mean - train_std,\n",
    "                 train_mean + train_std, alpha=0.2,\n",
    "                 color='darkorange', lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, valid_mean, label='Cross-validation score',\n",
    "             color='navy', lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, valid_mean - valid_std,\n",
    "                 valid_mean + valid_std, alpha=0.2,\n",
    "                 color='navy', lw=lw)\n",
    "\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b015cd-cadf-401f-991f-9067e8302bf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Learning Curve\n",
    "\n",
    "In a classification problem, the learning curve shows the performance of a model on the training set and the validation set over increasing numbers of training samples. It shows how the performance of the model changes as the training set size increases. The performance metric used for classification learning curves is usually accuracy or F1 score.\n",
    "\n",
    "In a regression problem, the learning curve shows the performance of a model on the training set and the validation set over increasing numbers of training samples. It shows how the performance of the model changes as the training set size increases. The performance metric used for regression learning curves is usually mean squared error (MSE) or R-squared."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c29b09e5-d0f5-4c7b-b46e-8a9d9cb64868",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "\n",
    "# generate random classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=5, n_redundant=0, random_state=42)\n",
    "\n",
    "# define estimator\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "# define parameter grid to be searched\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# initialize GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=2, n_jobs=-1)\n",
    "\n",
    "# split dataset into training and test data\n",
    "train_sizes, train_scores, test_scores = learning_curve(grid_search, X, y, cv=2, train_sizes=np.linspace(0.1, 1.0, 4))\n",
    "\n",
    "# calculate mean and standard deviation of training and test scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# plot learning curve\n",
    "plt.figure()\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training examples')\n",
    "plt.ylabel('Score')\n",
    "plt.grid()\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='r')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='g')\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "\n",
    "if not os.path.exists('../AutoViz_Plots/Training'):\n",
    "    os.makedirs('../AutoViz_Plots/Training')    \n",
    "\n",
    "    plt.savefig('../AutoViz_Plots/Training/LearningCurve.svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03513d4b-7149-48a1-9b40-ce95039e2992",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "############## LEARNING CURVE #####################\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "#################################################\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))\n",
    "fig.suptitle('Learning Curves: CV = 3, train_size = np.linspace(0.1, 1.0, 4)', fontsize=24, fontweight='bold', y=1.0)\n",
    "axes = axes.flatten()\n",
    "i = 0\n",
    "###################################################\n",
    "\n",
    "\n",
    "#for name, clf in {'SVM':svm_model, \"AdaBoost\":AdaBoost_model, \"GBDT\":GBDT_model,\"KNN\":knn_model,\"LogReg\":lr_model,\"RF\":RF_model}.items():\n",
    "model = {'SVM':svm_model, \"AdaBoost\":AdaBoost_model, \"GBDT\":GBDT_model,\"KNN\":knn_model,\"LogReg\":lr_model,\"RF\":RF_model}\n",
    "\n",
    "\n",
    "for name, clf in model.items():\n",
    "    print(\"\\nFor \",name)\n",
    "    #parameters = param_grid[name]\n",
    "    #gs = grid_search(clf,parameters)\n",
    "    \n",
    "    ax = axes[i]\n",
    "    i +=1\n",
    "   \n",
    "    # split dataset into training and test data\n",
    "    train_sizes, train_scores, test_scores = learning_curve(clf, X_train, y_train,\n",
    "                                                            cv=3,\n",
    "                                                            verbose=0,\n",
    "                                                            random_state=100,\n",
    "                                                            #scoring=scoring,\n",
    "                                                            train_sizes=np.linspace(0.1, 1.0, 3),)\n",
    "    \n",
    "    # calculate mean and standard deviation of training and test scores\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # plot learning curve\n",
    "    #plt.figure()\n",
    "    ax.set_title(f'Learning Curve: {name}')\n",
    "    ax.set_xlabel('Training examples')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.grid()\n",
    "    ax.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='r')\n",
    "    ax.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='g')\n",
    "    ax.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "    ax.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n",
    "    \n",
    "    ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()    \n",
    "    \n",
    "if not os.path.exists('../AutoViz_Plots/LearningCurve_raw5_trans'):\n",
    "    os.makedirs('../AutoViz_Plots/LearningCurve_raw5_trans')\n",
    "plt.savefig(f'../AutoViz_Plots/LearningCurve_raw5_trans/LearningCurve.svg',format='svg',dpi=500)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac763d-e97a-4c37-a492-902c35a8b3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8935176-f830-41a3-a932-35018450fca7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Complexity Aanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546655e-6c64-4bea-80cc-4a838f5539c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "#################################################\n",
    "fig, axes = plt.subplots(nrows=6, ncols=3, figsize=(10, 15))\n",
    "fig.suptitle(' Scalability & Performance: cv=3 for 3 equal parts of dataset', fontsize=24, fontweight='bold', y=1.0)\n",
    "axes = axes.flatten()\n",
    "i = 0\n",
    "###################################################\n",
    "\n",
    "\n",
    "#for name, clf in {'SVM':svm_model, \"AdaBoost\":AdaBoost_model, \"GBDT\":GBDT_model,\"KNN\":knn_model,\"LogReg\":lr_model,\"RF\":RF_model}.items():\n",
    "model = {'SVM':svm_model, \"AdaBoost\":AdaBoost_model, \"GBDT\":GBDT_model,\"KNN\":knn_model,\"LogReg\":lr_model,\"RF\":RF_model}\n",
    "\n",
    "\n",
    "for name, clf in model.items():\n",
    "    print(\"\\nFor \",name)\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax2 = axes[i+1]\n",
    "    ax3 = axes[i+2]\n",
    "    i +=3\n",
    "   \n",
    "    # split dataset into training and test data\n",
    "    train_sizes, train_scores, test_scores, fit_time, score_time = learning_curve(clf, X_train, y_train,\n",
    "                                                            cv=3,\n",
    "                                                            verbose=0,\n",
    "                                                            random_state=100,\n",
    "                                                            #scoring=scoring,\n",
    "                                                            train_sizes=np.linspace(0.1, 1.0, 3),\n",
    "                                                           return_times=True)\n",
    "    \n",
    "    # calculate mean and standard deviation of training and test scores\n",
    "    fit_time_mean = np.mean(fit_time, axis=1)\n",
    "    fit_time_std = np.std(fit_time, axis=1)\n",
    "    \n",
    "    score_time_mean = np.mean(score_time, axis=1)\n",
    "    score_time_std = np.std(score_time, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "\n",
    "    # plot learning curve\n",
    "    #plt.figure()\n",
    "    ax.set_title(f'Scalability For: {name}')\n",
    "    ax2.set_title(f'Scalability For: {name}')\n",
    "    ax3.set_title(f'Performance of: {name}')\n",
    "    \n",
    "    ax.set_xlabel('Training examples')\n",
    "    ax2.set_xlabel('Training examples')\n",
    "    ax3.set_xlabel('Fit Time')\n",
    "    \n",
    "    ax.set_ylabel('Fit Time')\n",
    "    ax2.set_ylabel('Score Time')\n",
    "    ax3.set_ylabel('Test Score')\n",
    "    \n",
    "    ax.grid()\n",
    "    ax2.grid()\n",
    "    ax3.grid()\n",
    "    \n",
    "    ax.fill_between(train_sizes, fit_time_mean - fit_time_std, fit_time_mean + fit_time_std, alpha=0.1, color='r')\n",
    "    ax2.fill_between(train_sizes, score_time_mean - score_time_std, score_time_mean + score_time_std, alpha=0.1, color='g')\n",
    "    ax3.fill_between(fit_time_mean, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='b')\n",
    "    \n",
    "    ax.plot(train_sizes, fit_time_mean, 'o-', color='r', label='Fit Time')\n",
    "    ax2.plot(train_sizes, score_time_mean, 'o-', color='g', label='Score Time')\n",
    "    ax3.plot(fit_time_mean, test_scores_mean, 'o-', color='b', label='Fit Time vs score')\n",
    "    \n",
    "    #ax.legend(loc='best')\n",
    "    #ax2.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()    \n",
    "    \n",
    "if not os.path.exists('../AutoViz_Plots/ScalabilityPerformance_raw5_trans'):\n",
    "    os.makedirs('../AutoViz_Plots/ScalabilityPerformance_raw5_trans')\n",
    "plt.savefig(f'../AutoViz_Plots/ScalabilityPerformance_raw5_trans/ScalabilityPerformance.svg',format='svg',dpi=600)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556adbb5-f287-4f08-ba5f-a4d558f2aedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b997918c-fb10-4d90-b46f-775d205fcbdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ROC UC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31254e2-a6a6-4985-9aa6-7c9ab72ab4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "raw",
   "id": "710c205a-a4c4-4647-bdf8-6e24703b2309",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "y_predictions = AdaBoost_model.best_estimator_.decision_function(X_test)\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_true= y_test,y_pred= y_predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c98f9c7b-e34e-4be5-9b45-9001867e1146",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#y_predictions = AdaBoost_model.best_estimator_.decision_function(X_test)\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "#ax =ax.flatten()\n",
    "roc_display = RocCurveDisplay.from_estimator(AdaBoost_model.best_estimator_,X=X_test, y= y_test, ax=ax)\n",
    "#ax[2].grid()\n",
    "\n",
    "\n",
    "#roc_display.plot(ax=ax)\n",
    "#plt.show(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4d973-0dbb-4da9-af20-1e1adf22ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(13, 8),sharex=True, sharey=True, squeeze=True)\n",
    "fig.suptitle('ROC Curve: Without Transformation', fontsize=22, fontweight='bold', y=1)\n",
    "axes = axes.flatten()\n",
    "i = 0\n",
    "###################################################\n",
    "\n",
    "\n",
    "#for name, clf in {'SVM':svm_model, \"AdaBoost\":AdaBoost_model, \"GBDT\":GBDT_model,\"KNN\":knn_model,\"LogReg\":lr_model,\"RF\":RF_model}.items():\n",
    "model = {'SVM':svm_model, \"AdaBoost\":AdaBoost_model, \"GBDT\":GBDT_model,\"KNN\":knn_model,\"LogReg\":lr_model,\"RF\":RF_model}\n",
    "\n",
    "\n",
    "for name, clf in model.items():\n",
    "    #print(\"\\nFor \",name)\n",
    "    \n",
    "    ax = axes[i]\n",
    "    \n",
    "    roc_display = RocCurveDisplay.from_estimator(clf.best_estimator_,X=X_test, y= y_test, ax=ax,alpha=1,color='b')\n",
    "    ax.set_title(name)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(color='k',alpha=0.1)\n",
    "    \n",
    "    i +=1\n",
    "plt.tight_layout()    \n",
    "\n",
    "#################################\n",
    "if not os.path.exists('../AutoViz_Plots/ROC_Curve_raw4_trans'):\n",
    "    os.makedirs('../AutoViz_Plots/ROC_Curve_raw4_trans')\n",
    "plt.savefig(f'../AutoViz_Plots/ROC_Curve_raw4_trans/ROC_Curve.svg',format='svg',dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841ab6b-b0e4-4f46-9798-cb67f4f501b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Confusion Metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ce263-e107-4863-badd-4bc117d26940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5de5f1e-0b10-49c3-aa1b-b7264202e5e4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "fig, axes = plt.subplots(nrows=2,ncols=3,figsize=(12,8))\n",
    "ax = axes.flatten()\n",
    "ax = ax[1]\n",
    "ConfusionMatrixDisplay.from_estimator(estimator= RF_model, X= X_test, y= y_test, ax= ax,colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f38c5-bea8-4cb7-9659-7fe5af7ca617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), squeeze=True)\n",
    "fig.suptitle('Confusion Metrix: With Transformation', fontsize=22, fontweight='bold', y=1)\n",
    "axes = axes.flatten()\n",
    "i = 0\n",
    "###################################################\n",
    "\n",
    "\n",
    "#for name, clf in {'SVM':svm_model, \"AdaBoost\":AdaBoost_model, \"GBDT\":GBDT_model,\"KNN\":knn_model,\"LogReg\":lr_model,\"RF\":RF_model}.items():\n",
    "model = {'SVM':svm_model, \"AdaBoost\":AdaBoost_model, \"GBDT\":GBDT_model,\"KNN\":knn_model,\"LogReg\":lr_model,\"RF\":RF_model}\n",
    "\n",
    "\n",
    "for name, clf in model.items():\n",
    "    #print(\"\\nFor \",name)\n",
    "    \n",
    "    ax = axes[i]\n",
    "    \n",
    "    confusionMetrix = ConfusionMatrixDisplay.from_estimator(clf.best_estimator_, X=X_test, y= y_test, ax=ax, colorbar=False)\n",
    "    ax.set_title(name)\n",
    "    \n",
    "    i +=1\n",
    "\n",
    "plt.tight_layout()    \n",
    "\n",
    "#################################\n",
    "if not os.path.exists('../AutoViz_Plots/ConfusionMetrix_raw4_trans'):\n",
    "    os.makedirs('../AutoViz_Plots/ConfusionMetrix_raw4_trans')\n",
    "plt.savefig(f'../AutoViz_Plots/ConfusionMetrix_raw4_trans/ConfusionMetrix_raw4_trans.svg',format='svg',dpi=600)\n",
    "########\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffc90e-6d23-462c-bf72-1fab6a9fa478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dfda5df-400a-4dc8-9faf-7467fcd8a4dc",
   "metadata": {},
   "source": [
    "# <center>Conclusions: Classifiaction Problem</center>\n",
    "\n",
    "- FWI is calculated from FFMC, DMC, ISI, BUI and these features hss very strong correlation reaching to 9 or more so decided to go with following strategie:\n",
    "\n",
    "    - Selected Temperature, Rain, RH, DC and FWI and month\n",
    "    - I understand standardization and some transformation like log(x+1) transformation is need for FWI and DC\n",
    "    - I trained the model with standardization & transfromation, with only standardization, without standardization or transformation\n",
    "    - Original features can't be accomodated because of high correlaion. Since FWI is calculated from other features so including those features and excluding the FWI will only complicate the model and there will be no improvement in perfromance. I also perfromed feature engineering so that I can include other features.\n",
    "    - The generated features include: FWI/FFMC,  (DMC/FWi)/ISI, FWI/BUI\n",
    "    - I trained the model with these features following same strategie i.e with and without transformation.\n",
    "    - The best perfroming models in terms of F1, roc_auc, precision, balanced accuracy etc are ONly the  model withoutn any transfromation and standardisaion with features DC and FWI. However the second best model was with new features with standardization and transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a0aff-cd54-4089-921a-26e119d85a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
